---
title: "Computer Vision 고전 이론 1"
escerpt: "Computer Vision 고전 이론 1"

categories:
  - Vision
tags:
  - [AI, Vision]

toc: true
toc_sticky: true

breadcrumbs: true

date: 2023-10-06
last_modified_at: 2023-10-08

comments: true
 

---

# 1. Local Image Features
: 이미지에 대해서 feature를 어떻게 뽑을것인지, feature engineering이나 어떻게 학습할것인지

- image에서 ROI(Region of interest, 흥미로운부분)부분을 말한다.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/cf5a6252-5c7e-40f9-971c-931499e7a607)

  - local feature는 image representation을 만드는데 사용된다.
  - local feature들의 aggeregation(집합) descriptor이다.

  - image representation은 object appearance modeling이 가능하다.
    - local feature를 사용하면 object가 조금 가려져 있더라도 일부분만 가지고도 전체를 찾아낼수도 있다.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/cad7a288-746c-497d-97b0-797580ae8eff)

  - local feature들은 여러장의 multiple view사이에서 match를 찾아낼수도 있다  

## 1-1. 좋은 local feature란?

- 1) saliency : feature는 image에서 ROI part를 잡고있어야 한다.
- 2) locality : feature는 image보다 small area를 가지고 있어야 한다.
- 3) Repeatability : 이미지가 회전하거나 변하더라도 같은 feature라면 같은 descriptor를 만들어내야 한다. photometirc(조도변화)에도 일관성있게 뽑혀야 한다.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/7b039d52-8f3d-4646-b472-76790a57e6af)

  - 즉 애매하지 않은게 뽑히는게 좋은 local feature이다.
  - **좋은 local feature = Interest point = keypoint**
    - consistent(일관된) reproducible(재생할 수 있는)
    - rich information, well-defined position
    - blob : 이미지 내에서 주변보다 더 밝거나 어두운 영역

# 2. Convolution
: 여기서 image processing이 어떻게 쓰였는지

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/77beb7d1-44c6-45e7-9bef-a532befc2ead)

  - conv란 미리 정해져있는 convolution kernel이 image에 각 pixel들과 곱해지면서 output of convolution을 만들어내는 연산이다.
  - 즉, convolution은 matrix multiplication 후에 summation을 통해 위치값의 결과를 만들어 내는 operation이다.

  - 성질
    - 교환법칙성립(Commutative)
    - 결합법칙성립(Associative)
    - 분배법칙성립(Distributive)
      - 가능한 이유는 convolution 연산이 linear operation이기 때문에 가능.
    - convolution은 linear filtering이다.  input의 linear combination으로 conv output을 만들수 있기 때문에.
  
  - convolution kernel을 이용하여 smoothed, sharpened, gradient(x 또는 y축 방향으로) 등 가능

    - smoothing filter
    ![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/ee386e78-7087-42f8-9554-91e07572fd86)

      - bilinear filter를 활용 (주변의 값들을 이용해서 가운데 값을 보간한다.) 해서 conv kernel 통과시킴. 
      - avarage filter를 통과시키면 흐릿하게 image가 나옴.
      - gaussian filter를 통과시키면 주변에 조금더 큰 영역에 대해서 값을 가져와서 merge하게 된다.
      - 장점) 주변의 noise값들을 reduction해서 조금더 깔끔한 이미지가 나오고 noise에 insensitive(무감각한) 이미지를 만들어 낼수 있다

    - Gaussian filter
    : Noise reduction by smoothing

    ![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/43cbde94-7616-4bc5-9d91-8a79c880c7d0)

      - 2차원 가우시안필터
        - x,y값에 대해서 중심부로 갈수록 값이 커짐.
      - size는 x,y의 kernel사이즈이며, sigma가 커질수록 noise가 많이 제거 된다. 대신 image가 blur처리 된다.

    - Gradient Filters
    : 어느방향으로 (x or y 축) 많이 받았는지에 따라 다름 

    ![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/1e801004-7728-48f0-a2d9-5d60303e48ad)

      - horizontal filter 사용하면 x방향으로 변화가 큰 위치에 대해 detect하게 된다.(x방향으로 변화가 더 큰게 더 값이 크게 나오니깐)즉, 세로선이 더 검출이 잘된다.
      - gradient filter를 사용해서 이미지의 gradient를 구할수 있고, gradient 방향의 x,y방향을 합쳐서 탄젠트를 적용하면 orientation도 구할수 있다(방향도 구할수 있다)

  
## 2-1. padding
: 이미지 필터링에서 boundary를 없애주기 위해 주로 사용한다.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/392d2c94-a361-4b14-9494-3075d5f872e8)

  - zero padding : original image에서 0을 패딩으로 채운것. 이러면 input feature 같은 size가 output feature로 나온다. 단점은 0로 채워져있기 때문에 boundary factor를 피할수 없다.
  - warp padding
  - clamp padding : 가운데 있는 pixel값들을 그대로 이미지 끝부분에 적용시킨 패딩
  - mirror padding : 이미지에서 반을 접어서 padding된 영역에 대해서 값들을  펼쳐서 데칼코마니 처럼 적용시킨것.

# 3. Edge and Corner
: 이미지 filter중에서 image의 edge와 corner를 어떻게 검출하는지

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/c322740c-d404-4de8-a2f1-844ecbcce819)
  - edge란? 
    - 점들의 집합.(= 선)
    - 구분된 region의 boundary.(선으로 구분하니깐)

  - 선은 이미지에서 어떤 조건이 있어야 하는가?
    - pixel intensity가 갑자기 변해야 한다. ( = gradient magnitudes가 크게 작용해야 한다.)

  - edge는 무엇으로 만드나?
    - 질감
    - 깊이의 차이
    - 방향성이 달라질수 있다

## 3-1. Edge Detection Process

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/33bc47b8-6e68-4930-9382-32ef74e0d22a)

  - input image를 smoothing한 후 그 image에 대해서 gradient magnitude를 계산한다. x와y방향에 대해 gradient를 구한 후 gradient map에 제곱해서 더한후 루트씌워서 gradient의 크기값을 visualization했을 때 흰색(흰색이 높은 value이다.)이 보이게 나온다.이걸 non-nax suppression(NMS) 후 thresholding하여 주변값에 대해서 작은값들은 없애버리면 edge들이 나오게 된다.이것이 edge detection process이다.
    - NMS후 thresholding하는 이유는? edge도 아닌데 먼가 image상에 존재하는 부분들을 제거하기 위해서이다.

### 3-1-1. edge detection
: gradient image를 활용해서 진행한다. denoing을 활용(smooting을 사용한 convolution)과, edge detection(gradient filter를 활용)

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/6ddedb0f-450e-48f3-88d2-65466e4b24e0)

  - incoding x = Gaussian에 x,y방향으로의 Derivative(파생) 을 incoding 에 적용하면 구할수 있다.
  - x방향으로 편미분한것을 2차원 으로 보면 x방향으로 gradient 필터가 있다고 해석 할수 있다. (색깔이 급격하게 변하는 부분이 x축방향으로 생긴다)
  - output으로 나온 결과는 양수,음수범위 모두 될수 있다.(양수,음수는 방향성을 나타낸다.)

## 3-2. Corners
: corners는 영역들이 합류되는 부분, 즉 edge들이 모이는 부분을 corners라고 할 수 있다.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/ac629e32-df69-400e-8696-09898dfa8e08)

  - corner는 match하기에 좋은 local feature이다.
  - match는 컴퓨터 비전에서 가장 고전적인 task이다. 
  - 2장의 image에서 corner가 얼마나 다른지만 판단해서 match를 쉽게 할수도 있다. corner의 sparse(희박한)한 match를 통해서 3차원 정보를 복원하기도 쉽다. 

### 3-2-1. Harris Corner Detection
: corner를 찾는 가장 대표적인 알고리즘

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/6c854114-b193-485e-b8c3-fe8cb7af440c)


  - corner : 모든방향으로 중요한 변화가 있는것
  - edge : pixel값이 한 방향으로만 변화가 있는것
  - flat : pixel 값이 어느 방향으로든 변화가 없는것.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/a854e2e4-1c67-4aea-8222-92dd8557948c)

  - u,v라는 위치에 대해서 이동된 위치와 비교하고있는 위치의 차이의 제곱(intensity, magnitude를 말함) 이 얼마나 큰지 정의.
  - 이것도 convolution 처럼 window function이 있어서 window funcion이 돌아다니면서 pixel의 중요값들이 얼마나 변하는지를 알고있는 refresention이다.

  - gaussian weights를 주면 보고있는 위치에 대해서 주변값들의 weight들을 낮춰줄수 있다. 즉, **gaussian weight를 쓰면서 noise에 대해서 robust(강건성)하게 된다.**

  - u,v가 주변과 비슷한값을 갖게 되면 0을 갖게된다. 
  - 주변과 구분되는 patch를 가지게 되면 해당 값이 커지게 된다.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/8f1b0abd-60bb-4b0b-9035-860561a0b6b3)

  - unit vector : image space에서 0,1,2,3,4 이렇게 되어있는데 -1~1사이로 옮겨진것
  - unit vector는 eigenvector로 표현가능 : 벡터에 스칼라값을 곱한 (a1과 a2를 곱한)것으로 표현 가능.
  - corner point라면 image에서 u,v 위치는 unit vector값과 같은 값을 가져야 한다. 왜냐하면 주변의 값들에 대해서 많이 변화된것이기 때문에. 즉, min E(u,v)했을때 가장 큰값이 corner라고 할수 있다. 
  - γ₂(람다2) : eigenvalue중에 더 작은 eigenvalue라는걸 말한다.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/43dcc5f7-d651-4ad2-b1ea-7b724442f288)

  - input patch가 flat하다고 하면, x,y 에 대해 derivate(미분) 하면 noise값이 나온다
  - x방향으로 linear 한 edge가 있다고 가정하면 x-derivate하면 x방향에 위치에 대해서 window function을 통과시켰을때 가운데 줄에 intensity가 높게 나온다.반면에 y방향으로는 edge가 없으니 intensity가 낮게 나온다.
  - 분포(distribution)에 대해 plot하게 되면 flat한 region에 대해서는 모두 작은 intensity를 갖게 된다. 하지만 linear edge같은경우, x방향으로 큰 intensity를 갖는다. corner는 x,y방향으로 모두 큰 intensity(세기)를 갖게 된다.
 
![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/dac88419-8626-47ad-aa88-1faa939339b4)

  - 두개의 eigenvalue는 corner의 shape과 size를 결정하게 된다.
  - 아무것도 없는경우 작은범위.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/9c74422f-13a2-4f3b-8912-a440e7f73e13)

  - 다음과 같이 eigenvalue값의 분포에 따라, edge인지 corner인지 flat인지 판단할 수 있습니다.
  - 하지만 eigenvalue를 직접 계산하는 것은 복잡한 일이기 때문에, 다음과 같은 공식을 이용해 corner인지, edge인지, flat인지를 판단합니다.
    - determination와 trace값을 통해서 판단
    - R=det(H)−k(trace(H))²
    - 1) R>0 (eigenvalue가 모두 0보다 클때): corner
    - 2) R<0 (y방향으로 큰 eigenvalue가질때) : y방향 edge
    - 3) R<0 (x방향으로 큰 eigenvalue가질때) : x방향 edge
    - 4) R≈0 : flat

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/bdc83aaf-0f0a-4a49-bf24-c2ad585244ac)

  - 조도변화가 rotation으로 있는 image를 사용할떄, corner response map사용하면 빛같은 noise까지 잡히게 되고, 이것을 큰값에 대해 Thresholding 하게된다. 그것을 주변값에 비해 더 큰값을 찾게되는 Non-max suppression 하게 되면 아래결과값이 나온다.

### 3-3. Edge detection algorithm
- 1차 미분
- 2차 미분 : Laplacian filter
- sobel edge
- Laplacian edge
- canny edge


# 4. Blob
: blob이란 이미지의 영역을 말하며, 주변보다 밝거나 어두운영역을 말함

## 4-1. blot detection 절차

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/3536432b-fafe-4e4d-afef-899fc26704a9)
  - 1) image를 smoothing진행
  - 2) LoG(Laplacian of Gaussian) or difference of Gaussian 적용
  - 3) optimal scale과 orientation parameter 찾기
  - 위 이미지에서 동그라미로 표시된게 blob 부분이다.

### 4-1-1. edge detection 다시보기

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/3bcc3c5b-80c2-4c2b-b7c4-4547a1a1cdc1)

  - edge detection을 보면 DoG(Deriavative of Gaussian)를 적용시킬때 response가 가장 큰 부분을 edge라고 표현함.

### 4-1-2. blob detection

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/81f42bc3-f6ac-4c51-90d5-31b88804621f)

  - 이때 사용하는 operator는 LoG(Laplacian of Gaussian)이며, 이를 적용시킬때 response가 가장 큰 region을 blob라고 표현함

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/10d0d9d4-5206-4a0c-abe4-3efcb1479f5c)

  - Laplace operator는 2개의 gradient vector operator의 내적으로 구해진다.

## 4-2. Laplacians for Blobs with Different Size
: 모든 blob의 사이즈는 다르기 때문에 적용되는 Laplacian을 찾아줘야 한다

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/c14643d3-7dac-49f7-a153-5bbedef1ad63)

  - 서로다른 시그날에 대해서 적절한 Laplacian의 magnitude를 찾아줘야 한다.
  - blob의 center에서는 Laplacian 값이 maximize가 된다 
  - optimal scale은 Laplacian 값이 maximize되는 곳이다.

## 4-3. scale selection

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/fa3205ff-3332-4790-8002-74066c0b2de0)

  - Laplacian 그 blob의 반지름의 루트 1/2값이 best scale값이다

## 4-4. scale normalization이 필요한 이유

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/9eb9dee6-2f79-46c3-b0ce-358e3ac783d6)

  - Laplacian의 magnitude는 scale에 따라 달라진다.
  - "시그마"값이 작으면 반지름 값이 작기때문에 magnitude를 알기 어렵다. 

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/47a2042c-2fbf-4c31-ba8c-455e9bff581f)

  - 즉, Laplacian of Gaussian filter를 image에 돌리게 되면 다양한 size의 blob이 detection하게 된다. 
  - keypoint로 나오는게 아니라 scale을 알고있는 blob들의 모음집으로 나오게 된다.
  - **결국 scale Invariant한 local featrue를 뽑을때 중요한 컨셉으로 작용한다.**

# 5. Scale-Invariant Feature Transform (SIFT)
keypoint와 descriptor를 뽑아내는 알고리즘
# 6. Model fitting
SIFT를 사용해서 이미지 2장사이의 관계를 알아내는 model fitting 기법
# 7. RANSAC
model fitting 대표 예1
# 8. Hough Transform
model fitting 대표 예2
# 9. Image Representation with Local Features
image representation에서 local feature를 어떻게 나타낼것인지, global한 정보나, local한 정보를 어떻게 나타낼것인지
# 10. Classification Models
application의 classification의 기초에 대한것 알아보기


# Deep learning
# Representation learning
# Object detection & segmentation
# Video
# Multiview geometry
# 3D Vision
# Generative models and graphics


---


[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}