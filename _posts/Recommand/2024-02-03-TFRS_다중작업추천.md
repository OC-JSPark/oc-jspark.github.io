---
title: "TFRS_다중작업추천"
escerpt: "TFRS_다중작업추천"

categories:
  - Recommand
tags:
  - [AI, Recommand, TFRS]

toc: true
toc_sticky: true

breadcrumbs: true

date: 2024-02-03
last_modified_at: 2024-02-03

comments: true
  

---

## 1.TFRS : multi-task recommenders & DCN

- multi-task recommenders
  - (구매 명세, 자동차 광고, 페이지 뷰, 이미지 클릭 등) 서로 다른 종류의 사용자 행태 데이터가 있다면 각각을 위한 모델 생성 필요.
  - 구매 명세와 페이지 뷰는 별개의 모델에 인풋으로써 제공되어야 함.
  - 최종 결과물을 종합할 수도 있겠지만 근본적으로는 독립된 행태를 다루는 독립된 모델들.

- [TFRS multi-task 예시](https://www.tensorflow.org/recommenders/examples/multitask?hl=ko)

Solution으로 joing model과 DCN이 있다.


### 1-1. 합동모델(joint model)
- 독립된 각각의 모델보다 합동모델이 나을수 있다.
- ex) 구매데이터가 희소할때, 페이지뷰는 많을수 있다. 즉, 각 데이터의 희소정도가 다를 떄 합동모델 내에선 희소한 데이터가 덜 희소한 데이터로부터 도움을 받을 수 있다. 이를 위해선 다수의 objective와 손실함수가 필요하다.
- (solution) 전이 학습 개념을 통해 데이터가 풍부한 쪽 작업의 표현을 학습해서 이를 희소한 쪽 작업에 전이시키기


### 1-2. DCN(deep & cross networks,심층 교차 네트워크)
- [TFRS : DCN 예시](https://www.tensorflow.org/recommenders/examples/dcn?hl=ko)
- 단순한 일대일 대응의 추천이, 때로는 충분하지 않다는 인식에서 출발함.
- 그래서 교차 특성 관계에 주목
  - 교차 특성 관계 찾기 어려움.
  - 하지만 새로운 결합들이 새로운 맥락제공 가능하기에 시도할 만하다.
- ex) 과일과 요리에 관심 있는 사람은 블렌더에 관심이 있다는 것. 각각의 정보만으로 블렌더가 필요한지 알수 없지만 둘을 합치면 블렌더를 떠올릴수 있음. 이를 통해 새로운 맥락 제공 가능.


#### 1-2-1. Cross Network

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/8b379ebb-620f-4727-94bb-308c98ee6e81)

  - 별개의 교차 네트워크들이 각 층에서 특성 교차를 적용.
  - 수학적으로 모든 교차층은 위 그림 처럼 생김.
  - 이들을 쌓을수록 교차 네트워크에서 얻는 다항식 차수도 증가하고 교차 네트워크 층을 더 많이 추가할수록 교차 특성 정보를 얻을 수 있는 조합의 개수가 증가함.

#### 1-2-2. Deep Network

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/4b36e63a-8164-4a4b-9f3f-6580b31138d6)

  - 다층 퍼셉트론(MLP)과 짝지은 후 심층 네트워크를 교차 네트워크와 합치면 심층교차네트워크(DCN)를 얻음.
  - 그렇게 하는 데에 두 가지 방법이 있음.
    - 위 그림에선, 쌓은 교차 네트워크가 심층 네트워크로 제공되고 있고 교차 네트워크와 심층 네트워크를 병렬적으로 작동하게 만든 후 아웃풋들을 합치는 것도 가능.
    1. Stacked
    2. in parallel
      
  - TFRS에서는 tfrs.layers.dcn.Cross()를 통해 자동적으로 구현 가능.



## 2. 실제 real data에서 추천시스템 적용방법은?( big scale data)

- [논문 : Accelerating Large-Scale Inference with Anisotropic Vector Quantization](https://arxiv.org/abs/1908.10396)
  
1. 검색 단계의 결과물에 대한 접근을 최적화하기
  - (solution) approximate nearest neighbor search(ANN)
    - 검색단계와 랭킹 단계에서의 인터페이스를 최적화하기
    - ScaNN이란 package로 tensorflow에 포함됨
    - tfrs.layers.factorized_top_k.ScaNN이 그 코드인데 검색 모델의 아웃풋에 신속하게 접근하게 하고 보통 10배는 빨라지지만, 결과가 근사치라서 approximate(근사)가 붙음

2. 운영환경에 적용하는 방법
  - 모델의 아웃풋을 서비스에 실시간에 어떻게 적용시킬것인가?
    - (solution) keras에선 어떤 TFRS든 saved model format으로 내보낼수 있다.(TFRS는 keras에서 만든거니깐.) 그러니 keras의 tensorflow serving 기능을 통해 saved model 제공가능.
    - 텐서플로 모델의 실제 적용을 위해 구글에서 제공하는 아키텍처로 AWS의 sagemaker와도 유사.
    - 검색 샘플의 끝부분을 보면 해당 saved model을 생성하고 텐서플로로 보내 활용하는 예시가 있는데 그 작동 과정을 보고 싶으면 간편하게 할 수 있음.



---


[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}