---
title: "컨텐츠 관련 필터링"
escerpt: "컨텐츠 관련 필터링"

categories:
  - Recommand
tags:
  - [AI, Recommand, filtering]

toc: true
toc_sticky: true

breadcrumbs: true

date: 2024-01-16
last_modified_at: 2024-01-16

comments: true
  

---

컨텐츠 기반 추천의 주요 아이디어는, 항목 속성을 기반으로 추천하는것.

## 1. Contents-based filtering 권장사항
  - ex) movielens dataset
  - dataset 특징 check
    1. 각각의 영화가 어떤 장르에 속하는지 쓰여있다. 
    2. 사용자가 SF를 좋아하면 SF영화를 추천하는것이 합리적이다. 
    3. movielens dataset은 영화개봉일을 영화제목에 넣는다. 즉 SF추천할때 조금범위를 좁혀서 사용자가 좋아했던 영화와 비슷한 시기에 개봉한 영화를 추천할 수 있다.
    4. movielens data를 IMDB의 dataset과 묶어서 영화감독, 출연배우, 평점 등의 정보를 얻을수 있다.

## 2. 두장르의 영화사이에서 유사성을 어떻게 측정하는가?
### 2-1. cosine similarity

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/f1b25c72-726c-4c44-a86e-f65f75f07938)

  - 콘텐츠 정보에 기반한 방식뿐만 아니라 다른 추천 시스템 방식들에도 적용가능. 
  - ex) 모든 영화는 두 종류의 장르로 나뉜다고 가정해보자. 
    - 0값의 의미는 장르가 없다는 것. 장르가 있으면 1로 표시.
    - 그래프의 위치들을 벡터값으로 생각할수 있다. 그래프 시작점에서 두영화에 선을 그리면  두 벡터사이에 각도가 생긴다. 
    - 각도가 말해주는것은 두 영화의 장르가 얼마나 유사한지이다. 
    - 현재 각도(쎄타) 45도 값은 유사성 메트릭으로 유용한 정보는 아니다. 
    - 0과 1사이의 값으로 측정해서,  0은 유사성이 전혀 없는것, 1은 가장 유사한것으로 이해하고 싶은것.
    - 해당각도를 cosine으로 계산해보자. 쎄타가 90도에 가까워지면 0이 된다는것.
    - 0도에 가까워지면 1이 된다는것. 45도 각도의 cosine값은 약 0.7이다. 
    - 즉 두 영화의 유사성 점수는 0.7이라고 할수 있다. 두영화는 코미디 장르라는 공통점이 있기 때문에.

  - ex2) 토이스토리와 몬티파이튼과성배 2개의 영화의 세타값을 얼마인가?
    - 쎄타값이 완전히 같다. 
    - 그러므로 0도이다. 
    - 즉, cosine(0) = 1이다. 장르만 봤을때 두 영화가 정확히 일치하기 때문. 완벽히 같다는 의미의 1.0값이 나옴.

  - 영화장르에서는 여타의 유사성중에 **코사인 유사성**이 가장 좋은 방법이다.

  - 주의) **유사성을 계산하는 요인의 수가 증가함에 따라 matrix 차원이 증가/감소한다는것!**



#### 2-1-1. convert genres to dimensions
![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/8ccdb4d6-314f-4e0c-befa-ec0074965aa7)

  - 장르를 18개로 늘렸을때는 어떻게 하지? 
    - 하나의 장르를 하나의 차원으로 생각해야 한다. 
    - 즉, 18개 차원의 영화들 사이의 각도를 찾아야 한다. 
    - 각 차원은 장르를 의미. 
    - 간단히 각 영화를 18개의 장르마다 숫자로 표시하면 된다. 
    - 0은 포함하지 않는 장르에 표시하고 1은 포함하는 장르에 표시한다. 

#### 2-1-2. multi-dimensional cosines

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/101236bd-02a7-49da-b1ab-5b6fcca7f036)

  - 다차원에 존재하는 벡터값 사이의 코사인값을 어떻게 계산할것인가?
    - 차원의 개수와 상관없이 코사인 유사성 값을 계산하는 방법.
    - ex) 코사인 유사성을 계산하고 싶은 두 영화를 골라보자. 
      - 각각 X,Y라고 하자. 
      - 분자 : X와 Y값의 곱을 1차원에서 합했음. 여기서 18개의 차원이 차례로 적용됨. 하지만 그중에서도 차원에 정보가 있는 영화들만 해당할것.
      
      - 액션장르의 차원부터 보면, 액션차원에 있는 X와Y의 값을 곱해서 나온 값을 액션 차원에서 합해줌. 그런식으로 쭉 진행.
      - 분모 : X가 가진 모든 장르의 차원들을 제곱해서 합했음. Y가 가진 모든 장르의 차원들도 제곱해서 합함. 그리고 각각 나온 값들을 루트씌움. 각 X,Y값을 합한값을 구한뒤에 X와Y장르의 각 제곱값의 합을 각각 루트씌워서 다시 곱한 값으로 나누면 코사인 유사성 점수가 나옴.
    
    - 두개의 영화ID가 입력되고 18개의 장르 차원에서 영화의 좌표를 알려주는 사전기능이 있음. 그리고 각 차원을 차례대로 적용한 뒤 X,Y의 장르 값을 추출해서 X의 제곱값과  Y의 제곱값과 X와Y의 곱을 계속 더함. 즉, 코사인 유사성을 구하려면 값을 차례로 잘 나열만 하면됨.
    - 위 예에선, 방정식을 간소화함.제곱근을 없앰으로써 더 효율적인 방식이 됨.

  ```
  def computeGenreSimilarity(self, movie1, movie2, genres):
    genres1 = genres[movie1]
    genres2 = genres[movie2]
    sumxx, sumxy, sumyy = 0,0,0
    for i in range(len(genres1)):
      x = genres1[i]
      y = genres2[i]
      sumxx += x * x
      sumyy += y * y
      sumxy += x * y

    return sumxy/math.sqrt(sumxx*sumyy)
  ```

### 2-2. 유클리드거리(Euclidean distance) 
![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/a74b1419-9ee4-4450-9af1-3cf8b0f767fb)

  - 유사성측정하는것으로 유클리드거리도 있다. 
  - 표시한 각 지점의 실제 거리를 측정하는것. 
### 2-3. 피어슨 상관관계
- 코사인 유사성과 비슷한데 평균값으로 계산을 한다는 점이 다르다. 



## 3. K-nearest-Neighbors 및 콘텐츠 녹화

## 3. 출시 연도에만 기반한 유사점?

- 데이터의 특징
  - 영화의 개봉일을 movielens dataset에서 추출하는건 어렵지만 모든 영화제목에 이 데이터가 나와있다.

- 개봉일만 가지고 유사성 점수를 어떻게 매길까?
  - 개봉일만 가지고 두 영화가 서로 완전히 다르다는 기준을 거리로 얼마만큼 둬야 할까? 
    10년을 기준으로 보자. 70년대와 80년대 영화는 다르다는 아이디어로!

```
def computeYearSimilarity(self, movie1, movie2, years):
  deff = abs(years[movie1] - years[movie2])
  sim = math.exp(-diff / 10.0)
  return sim
```

  - 지수함수

  ![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/5cc922d5-721a-4908-9909-252b51eaad0d)

    - 오른쪽을 보면 개봉일의 절댓값은 양수가 된다. 개봉일 값의 차이가 0 이라면 y축에 있는 유사성 점수는 1이 된다.  
    - 유사성 점수가 기하급수적으로 낮아지는데 개봉일 값의 차이가 10에 가까워질수록 점수가 작아지고 20에서는 거의 0에 가깝다.
    - 그렇다면 어떻게 **영화들의 유사성 점수를 실제 평가 예측**으로 바꿀수 있을까?


## 4. 속성기반으로 영화간의 유사점(장르,시간)을 실제 등급 예측으로 전환하는 방법은?

### 4-1. K Nearest Neighbors(KNN)
관심분야와 가까운 항목을 N개 성택하는것.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/1cce0c2d-b871-461d-a55b-6f3e03c963d8)

  - **k-nearest-neighbors**
    - 평가를 예측하고 싶어하는 영화와 사용자들이 평가한 영화간의 콘텐츠 유사성을 측정.
    - K : 평가를 예측하고 싶은 영화와 비슷한 몇가지 영화를 고르는것.(얼마나 비슷한지는 마음대로 정하기)
    - 평가를 예측하려는 영화와 콘텐츠 유사성 점수가 높은 영화들을 비슷한 영화라고 정의.(일단, 40개의 영화를 골랐다고 가정)
    - 이 영화들은 평가하려는 영화, 장르, 개봉일이 비슷.
    - 이것이 k-nearest-neighbors이다. 
  - step1) 관심을 두는 항목과 가까운 몇가지 항목을 골라서 neighbors라고 부른다. 
  - step2) 그리고 neighbors의 특징을 토대로 그 항목을 예측하는것. 
  - step3) 그래서 40개로 추린, 제일 비슷한 영화들을 실제 평가 예측으로 바꾸려면, 평가를 예측하려는 영화를 기준으로 유사성 점수의 가중 평균을 낸 뒤, 사용자들이 내린 평가대로 가중치를 주면 된다. 
  - step4) 그리고 rating prediction하면 끝.


```
## U : user, 사용자를 의미
## I : item, 항목을 의미
## 이를 이용해서 평가를 예측하는것. 
## neighbors라는 이름의 목록을 시작으로 사용자가 평가한 모든 영화를 거친 뒤  
## 평가 예측을 하려는 영화와 각 영화들 간의 콘텐츠 유사성 점수를 매김.

# build up similarity scores between this item everything the user rated 
neighbors = []
for rating in self.trainset.ur[u]:
    ##  유사성 점수를 미리 계산. 
    genreSimilarity = self.similarities[i, rating[0]] 
    neighbors.append((genreSimilarity, rating[1]))

## heapq.nlargest를 이용해서 유사성 점수가 높은 순서대로 우선순위 목록으로 정렬
# Extract the top-k most-similar ratings
k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[0])

## 우선순위에 든 영화들의 가중 평균을 계산해서 사용자가 내린 평가대로 가중치를 준다. 
## 만약 여기에 다뤄야 할 데이터가 있다면 사용자와 항목의 평가 예측으로 반환.
# Compute average sim score of K neighbors weighted by user ratings
simTotal = weightedSum = 0
for (simScore, rating) in k_neighbors:
    if (simScore > 0):
        simTotal += simScore
        weightedSum += simScore * rating
if (simTotal == 0):
    raise predictionImpossible('No neighbors')
  
predictedRating = weightedSum / simTotal

return predictedRating
```


## 5. 내재적 평가 데이터를 어떻게 평가로 나타낼것인가?

### 5-1. implicit ratings
: 내재적 평가(암시적 등급 사용)

- 의미 1) 겉으로 별점 5개를 주는게 아니고 좋고 싫음 표현하는것도 아님.
- 의미 2) 어떤 링크를 클릭하거나 어떤 물품을 사는 행위임.

- 내재적 평가와 외재적 평가를 어떻게 다룰것인가?
  1. 각 방식의 데이터의 쓰임과 유용성이 서로 다름.
  2. 내재적 데이터 : 강력한 도구가 될수 있음. 
    - 왜냐면 웹사이트 위젯에 반응해주거나 자발적으로 외재적 평가를 주기를 굳이 바라지 않아도 수집되는 데이터가 풍부하기 때문. 
    - 웹사이트 자체에 반응하면서 얻어지는 데이터들이기 떄문에 풍부함.
    - ex) 구매정보 기반의 평가는 최상의 결과를 내는것이 조금 힘들지만 누군가 실제로 물건을 구매했다는것은 강력한 관심 표현. 왜냐하면 사용자의 실제 행동이기 때문.

### 5-2.using implicit data

- 외재적 평가를 다뤘던 방식과 동일하게 다룸.
- ex) 사용자가 링크를 눌러보거나 구매한 행위들을 긍정적 평가로 봄. 임의적이지만 일관된 결과들임.

- 주의) 클릭하지 않거나 구매를 하지 않았다고 해서 이를 부정적인 평가로 보지 않음. 
  - 왜냐면 누군가 해당 상품을 구매하지 않았다고 해서 그 사람의 평가가 0점인 것은 아니니깐. 
  - 이건 단순히 데이터가 수집되지 않은 상황인것!

- 내재적 평가 방식에서의 point
  1. 물건링크 클릭, 물건구매를 긍정적 평가로 분류 + 별점 시스템과 같이 계산을 행해야함.
  2. 모든 내재적 평가가 똑같이 나타나지는 않음. 
    - 구매정보 : 좋은 품질의 추천을 만들어내며, 데이터로서 가치 good. 
    - 클릭수 : 클릭수를 기반으로 내재적 평가를 다룬다면  데이터가 난잡해짐. 
      - 반복 수행 프로그램 때문에 트래픽이 많인 걸릴것임. 
      - 그리고 이름 모를 곳에서 유입되는 사람들도 많음. 
      - 누군가 웹사이트 방문했다고 그게 꼭 관심의 표현이라 볼수 없음. 
      - 방문한 대상이 사람이 아닐수도 있음.
  - 즉, 모든 내재적 평가 방식이 구매 기반의 평가 방식과 같지는 않음. 
  - 구매 정보를 기반하는 방식은 사람들이 돈을 쓰고, 이는 높은 품질의 평가 방식임.


## 6.mise en scene (미장센 데이터)

해당 알고리즘의 주요 아이디어는 필름 자체에서 속성을 추출한 다음 권장 사항을 정량화하고 분석하는것.

- 미장센 데이터 : 한 장면에서의 대상의 배치를 의미. 
  - 더 넓게 영화나 영화 예고편에서 장면의 속성을 가리킬 때 사용. 
  - 이 개념은 영화에서 수량화가 가능하고 분석이 될 수 있는 **속성**을 추출하고 장면별로 영화의 내용을 검토하여 더 나은 영화 추천을 제안할수 있음.

  - **어떤 종류의 속성?**
    - 평균장면 길이, 색분산, 각각의 장면에서 움직임의정도,  조명방식등이 포함됨.
    - 영화를 기반으로 하여 해당 영화의 속도감과 분위기에 대한 느낌을 제공해야 함. 
    - 문제는 이 데이터가  이미 각 영화에 사용하고 있는 사람이 만들어낸 장르 분류보다 더 유용한지에 관한 점.

- 특징
  1. 정확성을 선호하지 않지만 다양성을 높인다.
  2. 다양성이 증가하면 무작위 항목 추천으로 이어질수 있다.




---


[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}