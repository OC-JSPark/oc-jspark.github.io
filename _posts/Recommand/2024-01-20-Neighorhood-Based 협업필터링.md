---
title: "Neighorhood-Based 협업필터링"
escerpt: "Neighorhood-Based 협업필터링"

categories:
  - Recommand
tags:
  - [AI, Recommand, framework]

toc: true
toc_sticky: true

breadcrumbs: true

date: 2024-01-20
last_modified_at: 2024-01-20

comments: true
  

---

## 유사성 및 희소성 측정
- 다른사람들의 행동을 활용하는것. 높은수준에서 여러분과 비슷한 사람들을 찾아서 그 사람들이 좋아하는 것을 추천하는게 가능. 또는 여러분이 좋아하는 것과 비슷한 걸 찾는 것일 수도 있음. 즉, 여러분이 좋아한 것을 구매했던 사람들이 구매한 다른 것들을 추천하는것.

- anatomy of a top-N recommender architecture를 생각해보자.
  - 아마존에서 활용한 협업필터링이다.
  - 암시적이든 명시적이든 사용자들의 리뷰 정보를 포함하는 데이터 저장소에서 각 사용자가 좋아하는 항목과 유사한 다른 항목을 검색하여 추천할 항목에 대한 후보를 생성. 그런 다음에 그 후보들의 점수와 순위를 매기고 사용자가 아직 보지 못한 항목들을 걸러내어 최종 상위 N개의 추천 목록을 생성. 이 접근법의 핵심은 항목 유사성 데이터베이스라는것. 다른 접근법은 사용자간의 유사성 데이터베이스를 사용할 수 있는데 어느쪽이든 유사항 항목 또는 유사한 사람의 목록을 생성하는것이 핵심. 

- 근접 기반 협업 필터링의 핵심
  - 당신과 비슷한 사람이나 당신이 좋아하는 것과 비슷한 아이템을 찾는 기능. 따라서 콘텐츠 기반 필터링으로 영화간의 유사성을 측정한 것과 마찬가지로 행동 데이터에 기반한 유사성 측정에도 동일한 기법 적용 가능.

  - 방법 1) cosine similarity
    - 여러분에게 사람이나 항목과 관련된 속성이 많은 경우 각각의 속성을 하나의 차원이라고 생각하고 유사성을 다차원 공간에 플롯될때 서로 다른 사물 사이의 각도라고 생각해라. 
    - cosine 유사도 metric 과 콘텐츠 속성으로 했을때의 차이점은 차원들이 다른것. 사용자가 이것을 좋아했나?  또는 이것이 이 사용자의 마음에 들었던가?  따라서 모든 사용자 또는 모든 것이 그 자체의 차원을 구성할 수 있으며 차원은 콘텐츠 속성 대신 사용자 행동을 기반으로 한다는것.
  - sparse(희소성) : 사용자 행동 기반으로 한 유사성 측정시 가장 큰 문제는 우리가 작업하는 데이터의 희소성이다! 세상엔 영화가 많고 어느 한 사람이 그 어떤 특정 영화를 봤다는 것은 거의 불가능에 가까움. 즉, 작업할 사용자 행동 데이터가 많지 않으면 협업 필터링이 제대로 작동하기가 어려움. 공통점이 없는 두 사람 사이의 의미 있는 코사인 유사도를 또는 공통점이 없는 두 항목간의 의미 있는 코사인 유사도를 계산할 수가 없다는 것.
    - 우리는 일반적으로 항목과 사람, 그리고 그들 사이에 존재하는 등급의 2차원 행렬로 시작. 문제는 실제로는 행렬 대부분이 비어있다는것. 아래처럼 어떤사람은 해당 영화를 본사람도 아예 안본사람도 있기에 데이터가 희소한다고 말하는것임.  그래서 이러한 데이터는 대기업에 잘 작동함. 그들은 수많은 유저가 있으니깐. 데이터가 희소하더라도 의미 있는 관계를 생성하기에 충분한 데이터가 있음.
    |-|항목1|항목2|
    |---|---|---|
    |사람1|4|---|
    |사람2|---|1|
    |사람3|-|-|
    
    - 희소성은 또한 몇가지 계산상의 문제도 불러옴. 누락된 모든 데이터를 저장하고 처리하는 데 시간을 낭비하고 싶지 않으므로 결국 내부적으로는 이 행렬에 빈 공간을 모두 저장하지 않는 sparse arrays(희소 배열) 과 같은 구조를 사용하게 됨. 이는 여러분이 작업해야 하는 데이 터의 양과 품질이 여러분이 선택한 알고리즘보다 훨씬 더 중요한 경우가 많다는 것을 상기시켜줌. 여러분이 유사도를 측정하기 위해 어떤 방법을 사용하는지는 별로 중요하지 않음. 데이터가 제일 중요함!

## 유사도 측정항목 

#### adjusted cosine
![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/5f74475f-85fe-4b72-9452-daecbef5aad1)

  - 이것은 주로 그들의 평가에 기반한 사용자들 사이의 유사성 측정에 적용가능.
  - 서로 다른 사람들은 그들이 가지고 행동하는 기준선이 서로 다를것이라는 생각에 기반함. 그래서 적용된 cosine은 이 차이들을 정상화하려고 시도함. 날것의 평정 값에 기반하여 사람들 사이의 유사도를 측정하는것이 아니라 사용자의 한 항목에 대한 평점과 모든 항목에 대한 그들의 평균 평점 사이의 차이에 기반하여 유사도를 측정.
  - Ri는 사용자 i의 모든 평점의 평균을 의미.
  - Rj는 사용자 j의 모든 평점의 평균을 의미.
  - 일반적인 코사인 유사도와 달라진 점은 단지 날것의 평점 그 자체가 아니라 개별 사용자의 평점의 평균으로부터 분산을 살펴보고 있다는것!
  - adjusted cosine을 살짝 틀어보면 pearson similarity metric이 된다.

    - 단 하나의 차이점은 평점과 사용자의 평균 평점의 차이를 살펴보는 것 대신에 평점과 그 항목에 대한 모든 사용자들의 평점 평균의 차이를 살펴본다는것.
    - x-bar,y-bar 대신 i-bar를 넣는것. 즉 궁금한 항목의 모든 사용자로부터의 평균 평점으로 대체. 그래서 우리는 더는 특정한 평가 점수의 개별적이고 개인적인 정의를 설명하려 하지 않을 것이고 희소 데이터가 있는 현실 세계에서 이것은 더 좋은 결과를 내보낸다.
    - 그러나 pearson similarity는 평균적인 사람들의 행동에서 그들이 얼마나 벗어나 있는지를 가지고 사람들 사이의 유사도를 측정하는 것으로 생각할수 있다. 예를들면 star wars를 싫어하는 사람들은 피어슨 유사도로부터 매우 강한 유사도 점수를 얻게 될것이다. 왜냐하면 그들은 주류가 아닌 의견을 공유하기 때문. 이것과 adjusted cosine의 유일한 차이점은 **사용자냐 또는 항목이냐**!!!
    - surprise library에서는 adjusted cosine을 사용자 기반 pearson similarity라고 나타냄. 왜냐하면 이것은 기본적으로 같은것이니깐!
    - 위에 말한 pearson similarity는 항목 기반 피어슨유사도이다. 즉 우리는 adjusted cosine을 사용함!!

#### spearman rank correlation
  - 피어슨 유사도와 같은 아이디어.
  - 평가 점수를 직접 사용하는 것과 달리 순위를 사용함. 즉, 영화에 대한 평균 평점 값을 사용하는 것 대신에 그들의 평균 평점에 기반한 모든 영화들 사이에서의 순위를 사용할것. 그리고 한 영화에 대한 개별적 평가 대신에 모든 개별적인 평가들 사이에서 그 영화의 순위를 매긴다.
  - spearman의 장점은 순서 데이터를 효율적으로 다룰수 있다는것. 
    - ex) 다른 평점 값들 사이의 평균의 차이가 같지 않은 평가 등급이 있는경우.
  - pearson similarity based on ranks, not ratings.

#### mean squared difference

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/9fde0b48-9334-45db-ac97-30ad7fe1d50b)

  - 유사도 측정방법 다른편이다.
  - 평균 제곱차이 유사도 metric
  - 각각의 사용자가 각각의 항목을 어떻게 평가했는지에 대한 것들 사이의 편차 제곱의 평균을 계산. 단지 이것은 두사람이 같은 것들의 집단을 어떻게 평가했는지 직접 비교한다. 이것은 추천시스템이 정확도를 측정할때 평균 절대 오차를 측정하는 방법과 상당 부분 같은 아이디어이다.
  -  MSD(x,y) 는 두 사용자 x,y 사이의 편차 제곱의 평균 또는 MSD가 여기 뒤에 나와 있는것과 같다. 분자는 사용자 x와 y 둘다 평가한 모든 항목i들을 더하고 있다. 각 사용자들의 평가 사이의 편차는 제곱되었음. 그리고 이것을 평균을 구하기 위해 다 더했던 각 사용자에게 공통적이었던 항목의 수로 나누어줌. 이제 문제는 우리가 사용자 x,y가 어떻게 다른지에 대한 metric을 계산해냈지만 우리는 그들이 얼마나 다른지가 아니라 얼마나 비슷한지를 측정하고 싶다는것!! 그래서 MSD로 1을 나눔으로써 이것의 역수를 취하고 분모에 +1을 붙인다. 이 두 사용자가 똑같은 평가 행동을 취하는 경우일 떄 0으로 나누는 것을 피하기 위해서! 그런데 사용자 대신 항목에다 적용한다면  우리가 말한 모든것을 뒤집을수 있다. 그래서 x,y가 두명의 다른 사람 대신 두 개의 다른 항목을 나타낼수 있고 우리는 사람들이 공통으로 가진 항목 대신 이 항목이 공통으로 가진 사람들로부터의 평가에 대한 편차를 살펴볼수 있다.
  - cosine 유사도 metric보다 이해하기 쉽지만 실제로는 cosine이 더 잘되는 경우도 있음을 알아라.

  - 정리하면 협업필터링을 하는데 2가지 방법있음.
    1. 항목기반
    2. 사용자 기반
    - 대부분의 유사도 metric은 두 접근법에 상관없이 적용가능.

#### jaccard similarity

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/de7ae07f-9b89-4108-b8de-16a77d0f7a37)

  - A,B 두사용자가 있다.
  - 이 두 사용자 사이의 자카드 유사도는 간단하게 이 두 사용자의 평가 사이의 교집합의 크기를 두 사용자의 평가의 합집합으로 나눈것.
  - 그래서 우리는 모든 영화의 수를 세고 예를들어 둘다 어떠한 관심을 보인다고 표시한 것을 둘 중 한 사용자라도 관심이 있다고 표시한 영화들의 총 개수로 나눈다. 우리는 단지 이것들의 수를 세고 있기 떄문에 버리기에는 꽤 중요한 정보라고 생각할수 있는 실제의 평점 값을 여기서 살펴보고 있지는 않다. 하지만 내재 평가를 다루고 있다면 예를들어 단지 어떤 사람이 무언가를 봤거나 샀다는 사실만으로 어떻게든 작업을 할 실제 평점 값을 얻게 되는 것은 아닐 것이다. 여러분은 단지 그들이 항목에 대한 흥미를 표현하기 위해 어떤 것을 했거나 핮 않았다는 사실만을 알뿐! 그런 경우에는 자카드는 합리적인 선택일수 있다. 이것은 계산하기 매우 빠름.

#### 유사도 측정 복습하기
1. cosine 유사도 : 좋은 만능!이것으로 시작하기에 가장 합리적!
2. adjusted cosine과 pearson : 이것은 같은 것에 대한 두자기의 다른 용어. 결국 이것은 평균 중심의 코사인 유사도이다. 그래서 이것은 사용자의 모든 항목 평점에 대한 평균 평점을 다루거나 모든 사용자에 대한 항목의 평균 평점을 다룬다. 여러분이 어느 쪽으로 뒤집느냐에 따라서! 이 아이디어는 평균에서 벗어난 일반적이지 않은 평가 행동을 다루기 위한것. 하지만 현실에서는 좋다기보단 유해함.
3. spearman rank correlation : 날것의 평점 대신 순위를 사용하기에 스피어맨과 같은 아이디어.현실에서는 잘 사용하지 않음.
4. msd : 평균제곱편차. 단지 cosine 유사도보다 더 이해하기 쉬운 유사도 metric. 하지만 실제로 결과값 나쁜경우 많음
5. jaccard :  두 사용자에 대해 얼마나 많은 항목이 공통되어 있는지 또는 두 항목에 대해 얼마나 많은 사용자가 공통되어 있는지를 그 둘사이에 얼마나 많은 항목이나 사용자가 있는지로 나누것을 살펴본다. 이것은 매우 간단한 내재평가이다. 예를들어 어떤것을 구매하는 것이나 보는것과 같이 무언가를 하거나 하지 않는 것, 이 두 항으로 이루어진 행위에 매우 잘 맞는다.  하지만 cosine 유사도를 내재 평가에 적용가능.
6. 결론) cosine 유사도를 default로 자주 쓰는 유사도 metric이다.



## 사용자 기반 협업 필터링 : user-based collaborative filtering
- 여러분 자신과 유사한 다른 사용자들을 그들의 평가 이력을 기반으로 찾는 것으로부터 시작해서 그들이 좋다고 했던 여러분이 아직 보지 못한 것을 추천한다.

- 1단계 : 우리에게 필요한 데이터 수집. 모든 사람의 모든 평점이 있는 표가 필요. 이것을 한축에는 영화를 다른축에는 사용자를 나타내고 각각의 셀에 평점 값이 있는 2D 정렬로 생각할수 있음.

[표]
|-|indian jones|star wars|Empire|Incredibles|Casablanca|
|---|---|---|---|---|---|
|bob|4|5|-|-|-|
|Ted|-|-|-|-|1|
|Ann|-|5|5|5|-|
==>
[cosine similarity]
|-|bob|Ted|Ann|
|bob|1|0|1|
|Ted|0|1|0|
|Ann|1|0|1|

  - cosine similarity를 보면 두 사용자가 100% 유사하다는것이 꼭 그들이 같은 대상을 좋아한다는 것을 의미하지는 않는다! 이것은 또한 그들이 같은 것을 싫어한다는것을 뜻할수도 있다.
  - 만약 bob과 Ann이 둘다 스타워즈를 별점 1점으로 평가했다면 그들은 여전히 100% 유사할것이다.
  - 여기서 bob과 ann은 스타워즈를 별점 5점으로 동일하게 평가했기에 100% 유사도가 나온것이다.
  - 주의) 추천시스템할때는 희소데이터 때문에 사용자들이 공통으로 가진 영화가 몇개 있는지에 대한 최소 한계치를 시행해줘야 한다.

  - 이제 bob을 위한 추천을 생성해보는게 목표이다.
  - 위에 만들어진 cosine similarity를 이용해서 다른 모든사람과 얼마나 유사한지 빠르게 찾아보자. 그리고 그 목록을 유사도 점수에 따라 분류하고 그 목록에서 최고의 이웃들을 뽑아낼수 있다.
    - bob's neighbors : Ann:1.0, Ted: 0    
    - 만약 위 데이터에 다른 사용자들이 추가 되었다면 그들의 평점 또한 해당 데이터에 merge해준다. 
    - 그 후 추천 후보중 어떤 것이 bob에게 제시하기에 가장 좋은것인지 알아내야 한다. 그래서 그것들을 어떠한 방식으로든 점수를 매겨야 한다. 각각의 후보에 그 일부분으로서 배정된 평점을 취하는 것이 타당하다. 우리는 유사한 사용자들이 싫어하는 대상이 아닌 좋아하는 대상을 추천하길 원한다.즉 별점 5점의 평점을 1.0으로 변형할수 있는데 이것을 사용자와의 유사도를 취해줘야 한다. 그래서 우리는 1.0 평가 점수에  역시 1인 ann의 bob에 대한 유사도 점수를 곱할수 있다. 진행하다보면 같은 영화를 한번 넘게 또 볼수있다. 한명이 넘는 유사한 사용자가 그것을 평가했다면말이야. 그러면 그 영화의 최종점수에 다시 더해 넣음으로써 그 영화와의 관계를 강화하고 싶어질것이다.  아마도 평가 점수를 0~1범위로 정상화 하는 대신에 실제로 별점 1점,2점을 받은것을 최종 결과로 내기 위해 음수의 점수를 할당할수도 있다. 여러가지 방법이 있으니 이건 고민해볼것. 일단 우리는 추천후보의 최종점수로 그들을 분류함. 마지막 단계는 bob이 이미 평가한 것을 걸러내는것. 그가 이미 시청한 영화들을 추천하는 것은 의미가 없기 때문.

  - 요약) 사용자기반 협업 필터링에 포함된 단계
    1. user -> item rating matrix
      : 사용자에 대해 그들이 평가한 모든 항목과 그 평점 값을 나타낸 룩업표를 만드는것부터 시작.
    2. user -> user similarity matrix
      : 그리고 모든 사용자 쌍 사이의 유사도 점수에 대한 또다른 2D행렬만들기. 이시점에 연산이 많이 든다. 그리고 아무나를 위한 추천을 빠르게 생성하는데 이 표를 재사용가능.
    3. look up similar users
      : 특정한 사용자를 위해 추천할때 우리는 그 사용자와 가장 유사한 모든 사용자를 찾아볼수 있다.
    4. candidate generation
      : 그 유사한 사용자가 평가했던 모든것을 한데 모아서 추천 후보들을 생성.
    5. candidate scoring
      : 유사한 사용자들이 그것들을 어떻게 평가했는지, 그 사용자가 그것들을 평가한 것이 여러분에게는 얼마나 유사한지, 그리고 여러분이 원하는 다른 어떤 것이라도 살펴보면서 이 모든 후보들의 점수를 매김.
    6. candidate filtering
      : 마지막으로 사용자가 이미 시청한것을 걸러내기.

## 아이템(항목) 기반 협업 필터링

- 협업필터링 하는 또다른 방법은 문제를 완전히 뒤집는것.
- 여러분과 비슷한 다른 사람들을 찾아서 그들이 좋아했던 것을 추천하는 것 대신 여러분이 좋아했던 것들을 살펴보고 그것들과 비슷한것을 추천.
- 사람들 사이의 유사도보다 항목들 사이의 유사도를 사용하는게 낳은 이유
  1. 항목이 사람보다 더욱 영구적인 속성을 가지는 경향이 있음. 즉, 불변하는 대상에 초점을 맞추는게 좋음.
  2. 여러분들에게는 다룰 항목이 사람보다 매우 적게 있다는것. 그래서 2d matrix만들때 간단히 만들수 있고 연산또한 빠르게 될수있음.
  3. 새로운 사용자가 웹사이트 방문해서 어떤 한가지에 관한 관심을 표시하자마자 그들에게 그것과 비슷한 항목추천가능.
- 사용자 기반 협업필터링과의 차이점은 우리가 사용자와 항목의 이용을 뒤바꾼다는것! 그래서 사용자를 행으로, 항목을 열로 갖는 matrix로 시작하는것 대신에 항목을 행으로 갖고 사용자를 열로 갖는 matrix를 사용하면 된다. 그리고 항목들 사이의 유사도를 측정할수 있다.
- 사용자 기반 협업필터링에서는 사용자들이 모든 항목이 차원인 공간에 존재한다고 생각을 했고 이 사용자 벡터들 사이의 cosine 유사도를 찾아냈다. 이젠 뒤집자! 모든 사용자가 차원인 공간에 항목들이 존재한다고 생각하고 이 항목 벡터들 사이의 cosine 유사도를 찾자.
- cosine 유사도는 항목들 사이의 유사도를 측정하는 많은 방법중 하나일뿐이다. 이 항목 짝들의 점수를 매기는 유사도에 전혀 기반하지 않은 다른 방법들이 존재할수도 있다.
[표]
|-|bob|ted|ann|
|---|---|---|---|
|indiana|4|-|-|
|star wars|5|-|5|
|empire|-|-|5|
|incredibles|-|-|5|
|casablanca|-|1|-|
==>
[cosine 유사도]
|-|indiana|star wars|empire|incredibles|casablanca|
|indiana|1|1|0|0|0|
|star wars|1|1|1|1|0|
|empire|1|1|1|1|0|
|incredibles|1|1|1|1|0|
|casablanca|0|0|0|0|1|

  - 이제 각각의 항목이 공통적으로 가진 그것들을 평가한 사용자에 기반하여 모든 가능한 항목 짝 사이의 cosine 유사도 점수를 연산가능.
  - 항목유사도를 통해서 A가 star wars만 보았고 B는 star wars, incredibel, empire 영화를 보았다면 B 기반으로 A에게 A가 안본 2가지 영화를 더 추천해줄수 있다.

  - 사용자 기반 or 항목기반의 협업 필터링으로 정확도를 측정할수는 없다.
  - 왜냐하면 그것들은 평점 예측을 산출하지 않기 떄문. 그러나 적중률을 측정은 가능하다. 왜냐하면 이것은 아직도 단지 순위 추천이니깐!(evaluateUserCF.py보자)


## KNN추천
- 협업필터링이라는 개념은 순위 예측을 하는 추천시스템에 적용되기 떄문에 일반적으로 KNN recommenders라고 불린다.
- workflow
  - 사용자가 아직 평가하지 않은 것들의 순위를 예측해서 추천후보들을 만들어 낸다. 그리고 가장 높은 예측 순위 중에서 상위 k개의 아이템을 선택한다. 그 순간부터 다른 모든것들이 같은 방식으로 작동한다. 이는 효율적인 방법은 아니지만 우리는 순위를 예측하기 때문에 시스템의 오프라인 정확도를 훈련/테스트나 교차 검증을 통해서 측정할수 있다. 이는 조사를 할떄는 유용한 방법이다. 여기서 문제점은 순위를 예측할 때 아이템 데이터나 사용자 유사도를 사용하기 때문에 이것은 여전히 협업 필터링으로 불린다는것! 하나의 해결책은 이 예측을 상위K개 아이템을 기본으로 하거나 가장 높은 유사도를 보이는 사용자를 기본으로 하는것! 이것이 바로 우리가 이를 KNN이라고 하는 이유.
- user-based KNN
  - (ppt로 만들어)
  - find the k most-similar users who rated this item => compute mean sim score weighted by ratings => rating prediction
    - 우리는 사용자나 아이템에 대한 순위를 예측하기 때문에 우리가 관심이 있는 사용자와 비슷한 사용자를 찾는것부터 시작.
    -  하지만 이 사용자는 관심이 있는 아이템을 평가한 사람이어야 한다. 우리는 이를 비슷한 k명의 사용자로 제한한다. 결국 k명의 비슷한 사용자들로부터 아이템에 대한 순위 세트라는 결과를 얻게 된다.이것들이 KNN이고 이 사용자가 우리가 예측해야 하는 사용자와 얼마나 비슷한지를 측정한다.
    - 다음으로 순위 그 자체를 가중해서 관련 순위에 대한 사용자 유사도 스코어를 가중 평균한다. 이 방법을 이용하면 사용자가 어떤 평가를 할지 그럴듯한 예측을 할수 있다. 아이템을 평가했던 비슷한 사용자를 기반으로 말이다! 이 방법이 사용자 기반 협업 필터링과 유사하다는것을 알수 있다. 하지만 작동방식은 완전히 다르다. 이는 사용자 대 사용자 유사도 metric을 핵심으로 하므로 당신과 비슷한 것을 좋아했던 사람에게는 추천하지 않는다. 대신에 데이터에 깊이 파고들어서 가능한 모든 경우의 아이템과 사용자에 대한 순위를 예측한다. 이는 더 복잡한 접근이고 보통은 안좋은 방법이다.

    - user-based knn
    ![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/b63f405d-4cc0-41d3-a6e5-7225fec58b89)

      - 사용자의 u와 아이템의 i 예측 순위는 k명의 비슷한 사용자를 합한값과 같다. 여기서 k명의 비슷한 사용자들을 v라고 한다. 사용자 u와 v의 유사도 스코어를 모두 더한 다음에 사용자 v가 평가한 순위를 곱한다. 그다음에 사용자 유사도 스코어의 합으로 나누어 준다. 가중 평균을 낸 것이고 이는 순위 예측에 사용될수 있다.


  - item-based KNN
    -  find the k most-similar items also rated by this user => compute mean sim score weighted by ratings => rating prediction
      - 아이템 기반 KNN도 정확히 같은 방법으로 작동함.
      - 사용자와 아이템이라는 단어만 바꾸면 됨
      - 그러니 아이템i에 대한 사용자 u의 순위를 예측하려면 k개의 아이템 세트로 시작해야한다. 이틑 아이템 i와 가장 비슷한 사용자에 의해 평가된다. 그 이후는 같다. 순위의 가중 평균을 계산한다면 꽤 신뢰할 만한 순위 예측을 할수 있다.
      - 수식도 같지만 다른점은 사용자 u와 v 대신에 아이템 i,j를 사용한다는것!
      -  예측 순위는 k개의 가장 비슷한 아이템 세트를 기초로 한다. 이 아이템 세트는 문제가 되는 아이템을 사용자가 평가한 것.순위에 따라 가중된 아이템 유사도 스코어를 모두 더한 뒤에 유사도 스코어의 합계로 나누어준다. 이는 협업 필터링이라는 개념을 순위 예측이라는 틀 안에 넣었다는 점에서 안좋아 보일수 있지만 꽤 괜찮은 순위 예측법이다. 만약 목표가 상위 N개의 추천 리스트를 만드는 것이라면 더 단순하고 직관적인 이전에 살펴봤던 접근을 사용하는것이 나을것이다. 다행히도 KNN은 surpiseLib에서 제공하는 알고리즘이다. 실습위해서 코드를 많이 쓸필요 없다.


---


[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}