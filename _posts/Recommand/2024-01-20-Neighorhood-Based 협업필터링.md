---
title: "Neighorhood-Based 협업필터링"
escerpt: "Neighorhood-Based 협업필터링"

categories:
  - Recommand
tags:
  - [AI, Recommand, filtering]

toc: true
toc_sticky: true

breadcrumbs: true

date: 2024-01-20
last_modified_at: 2024-01-20

comments: true
  

---

## 1.유사성 
- 다른사람들의 행동을 활용하는것. 비슷한 사람들을 찾아서 그 사람들이 좋아하는 것을 추천하는게 가능. 
- 즉, 좋아하는 것을 구매했던 사람들이 구매한것을 토대로 다른 것들을 추천하는것.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/d7f3c3d2-8374-4e46-b636-b12ae95a8acf)

  - 아마존에서 활용한 협업필터링.
  - 암시적이든 명시적이든 사용자들의 리뷰 정보를 포함하는 데이터 저장소에서 각 사용자가 좋아하는 항목과 유사한 다른 항목을 검색하여 추천할 항목에 대한 후보 생성. 
  - 그 ,후 그 후보들의 점수와 순위를 매기고 사용자가 아직 보지 못한 항목들을 걸러내어 최종 상위 N개의 추천 목록을 생성. 
  - 이 접근법의 핵심) 항목 유사성 데이터베이스라는것. 다른 접근법은 사용자간의 유사성 데이터베이스를 사용할 수 있는데 어느쪽이든 유사항 항목 또는 유사한 사람의 목록을 생성하는것이 핵심. 

## 2. neighborhood-based filtering 의 핵심
- 나와 비슷한 사람이나 내가 좋아하는 것과 비슷한 아이템을 찾는 기능. 
- 따라서 콘텐츠 기반 필터링으로 영화간의 유사성을 측정한 것과 마찬가지로 행동 데이터에 기반한 유사성 측정에도 동일한 기법 적용 가능.

### 2-1. method : cosine similarity
- 사람이나 항목과 관련된 속성이 많은 경우, 각각의 속성을 하나의 차원이라고 생각하고 유사성을 다차원 공간에 plot될때 서로 다른 사물 사이의 각도라고 생각하면 쉽다. 
- cosine similarity metric 과 콘텐츠 속성으로 했을때의 차이점? 
  - 차원들이 다른것. 
  - 사용자가 이것을 좋아했나?  또는 이것이 이 사용자의 마음에 들었던가?  따라서 모든 사용자 또는 모든 것이 그 자체의 차원을 구성할 수 있으며 차원은 콘텐츠 속성 대신 사용자 행동을 기반으로 한다는것.

## 3. sparse(희소성) 
- 사용자 행동 기반으로, 유사성 측정시 가장 큰 문제는 데이터의 희소성이다! 
- 세상엔 영화가 많고 어느 한 사람이 그 어떤 특정 영화를 봤다는 것은 거의 불가능에 가까움. 
- 즉, **작업할 사용자 행동 데이터가 많지 않으면 협업 필터링이 제대로 작동하기가 어려움**
- 공통점이 없는 두 사람 사이의 의미 있는 코사인 유사도 or 공통점이 없는 두 항목간의 의미 있는 코사인 유사도를 계산할 수가 없다는 것.
    - 우리는 일반적으로 항목과 사람, 그리고 그들 사이에 존재하는 등급의 2차원 행렬을 만든후 문제를 푼다. 
    - 문제는 실제 행렬 대부분이 비어있다는것. 
    - 예시처럼 어떤사람은 해당 영화를 본사람도 아예 안본사람도 있기에 데이터가 희소한다고 표현가능.
    - 그래서 이러한 데이터는 큰 기업에서는 활용도가 높다. 왜냐하면 수많은 유저가 있기때문. 데이터가 희소하더라도 의미 있는 관계를 생성하기에 충분한 데이터가 있기 때문.

|-|항목1|항목2|
|---|---|---|
|사람1|4|---|
|사람2|---|1|
|사람3|-|-|
    
  - 희소성은 또한 몇가지 계산상의 문제도 불러옴. 
  - 누락된 모든 데이터를 저장하고 처리하는 데 시간을 낭비하고 싶지 않으므로 결국 내부적으로는 이 행렬에 빈 공간을 모두 저장하지 않는 sparse arrays(희소 배열) 과 같은 구조를 사용하게 됨. 
  - 이는 작업해야 하는 데이터의 양과 품질이 선택한 알고리즘보다 훨씬 더 중요한 경우가 많다는 것을 상기시켜줌. 
  - 유사도를 측정하기 위해 어떤 방법을 사용하는지는 별로 중요하지 않음. 데이터가 제일 중요함!

## 4.유사도 측정항목 

### 4-1. adjusted cosine
![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/5f74475f-85fe-4b72-9452-daecbef5aad1)

  - 평가에 기반한 사용자들 사이의 유사성 측정에 적용가능.
  - 서로 다른 사람들은 그들이 가지고 행동하는 기준선이 서로 다를것이라는 생각에 기반함. 
  - 그래서 적용된 cosine은 이 차이들을 정상화하려고 시도함. 
  - 날것의 평정 값에 기반하여 사람들 사이의 유사도를 측정하는것이 아니라 사용자의 한 항목에 대한 평점과 모든 항목에 대한 그들의 평균 평점 사이의 차이에 기반하여 유사도를 측정.

  - 일반적인 코사인 유사도와 달라진 점? 
    - 단지 날것의 평점 그 자체가 아니라 **개별 사용자의 평점의 평균으로부터 분산을 살펴보고 있다는것!**
  - adjusted cosine을 살짝 틀어보면 pearson similarity metric이 된다.

    - adjusted cosine과 pearson similarity metric의 차이점? 
      - 평점과 사용자의 평균 평점의 차이를 살펴보는 것 대신에, 평점과 그 항목에 대한 모든 사용자들의 평점 평균의 차이를 살펴본다는것.
      - x-bar,y-bar 대신 i-bar를 넣는것. 즉, 궁금한 항목의 모든 사용자로부터의 평균 평점으로 대체. 
      - 특정한 평가 점수의 개별적이고 개인적인 정의를 설명하려 하지 않을 것이고 희소 데이터가 있는 현실 세계에서 이것은 더 좋은 결과를 내보낸다.
      - 그러나 pearson similarity는 평균적인 사람들의 행동에서 그들이 얼마나 벗어나 있는지를 가지고 사람들 사이의 유사도를 측정하는 것으로 생각할수 있다. 
        - ex) star wars를 싫어하는 사람들은 피어슨 유사도로부터 매우 강한 유사도 점수를 얻게 될것이다. 왜냐하면 그들은 주류가 아닌 의견을 공유하기 때문. 이것과 adjusted cosine의 유일한 차이점은 **사용자냐 또는 항목이냐**!!!
    - surprise library에서는 adjusted cosine을 사용자 기반 pearson similarity라고 나타냄. 왜냐하면 이것은 기본적으로 같은것이니깐!
    - 위에 말한 pearson similarity는 항목 기반 피어슨유사도이다. 즉 우리는 adjusted cosine을 사용함!!

### 4-2. spearman rank correlation
  - 피어슨 유사도와 같은 아이디어.
  - **등급이 아닌 순위를 기반으로 한 pearson similarity**
  - 평가 점수를 직접 사용하는 것과 달리 순위를 사용함. 즉, 영화에 대한 평균 평점 값을 사용하는 것 대신에 그들의 평균 평점에 기반한 모든 영화들 사이에서의 순위를 사용할것. 그리고 한 영화에 대한 개별적 평가 대신에 모든 개별적인 평가들 사이에서 그 영화의 순위를 매긴다.
  - spearman의 장점은 순서 데이터를 효율적으로 다룰수 있다는것. 
    - ex) 다른 평점 값들 사이의 평균의 차이가 같지 않은 평가 등급이 있는경우.

### 4-3. mean squared difference

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/9fde0b48-9334-45db-ac97-30ad7fe1d50b)

  - 유사도 측정방법 다른편이다.
  - 평균 제곱차이 유사도 metric
  - 각각의 사용자가 각각의 항목을 어떻게 평가했는지에 대한 것들 사이의 편차 제곱의 평균을 계산. 단지 이것은 두사람이 같은 것들의 집단을 어떻게 평가했는지 직접 비교한다. 이것은 추천시스템이 정확도를 측정할때 평균 절대 오차를 측정하는 방법과 상당 부분 같은 아이디어이다.
  - MSD(x,y) 는 두 사용자 x,y 사이의 편차 제곱의 평균 또는 MSD가 여기 뒤에 나와 있는것과 같다. 
    - 분자는 사용자 x와 y 둘다 평가한 모든 항목i들을 더하고 있다. 
    - 각 사용자들의 평가 사이의 편차는 제곱되었음. 
    - 그리고 이것을 평균을 구하기 위해 모두 더했던 각각의 사용자에게 공통적이었던 항목의 수로 나누어줌. 
    - 이제 문제는 우리가 사용자 x,y가 어떻게 다른지에 대한 metric을 계산해냈지만 우리는 그들이 얼마나 다른지가 아니라 얼마나 비슷한지를 측정하고 싶다는것!! 
    - 그래서 MSD로 1을 나눔으로써 이것의 역수를 취하고 분모에 +1을 붙인다. 
    - 이 두 사용자가 똑같은 평가 행동을 취하는 경우일 떄 0으로 나누는 것을 피하기 위해서! 
    - 그런데 사용자 대신 항목에다 적용한다면  우리가 말한 모든것을 뒤집을수 있다. 
    - 그래서 x,y가 두명의 다른 사람 대신 두 개의 다른 항목을 나타낼수 있고 우리는 사람들이 공통으로 가진 항목 대신 이 항목이 공통으로 가진 사람들로부터의 평가에 대한 편차를 살펴볼수 있다.
  - cosine 유사도 metric보다 이해하기 쉽지만 실제로는 cosine이 더 잘되는 경우도 있음을 알아라.

- **정리)**
  - **협업필터링 2가지방법)**
    1. 항목기반
    2. 사용자 기반
    - 대부분의 유사도 metric은 두 접근법에 상관없이 적용가능.

### 4-4. jaccard similarity

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/de7ae07f-9b89-4108-b8de-16a77d0f7a37)

  - A,B 두사용자가 있다.
  - 이 두 사용자 사이의 자카드 유사도는 간단하게 이 두 사용자의 평가 사이의 교집합의 크기를 두 사용자의 평가의 합집합으로 나눈것.
  - 계산하기 매우 빠르다.
    - ex) 둘다 어떠한 관심을 보인다고 표시한것 / 둘중 한 사용자라도 관심이 있다고 표시한 영화들의 총 개수 = jaccard similarity
  - 주의할점은 실제의 평점 값을 보는것은 아니다.
  - 단지 그들이 항목에 대한 흥미를 표현하기 위해 어떠한것을 했거나 안했다라는 사실만 안다. 그럴때 jaccard similarity가 합리적인 선택이다.
  - **내재적 평가에 합리적인 측정방법이다.**


## 5. 유사도 측정 요약
### 5-1. cosine 유사도 
- 만능!이것으로 시작하기에 가장 합리적!
### 5-2. adjusted cosine과 pearson
- 같은 의미에 대한 두가지의 다른 용어. 
- 결국 이것은 평균 중심의 코사인 유사도이다. 
- 그래서 사용자의 모든 항목 평점에 대한 평균 평점을 다루거나 모든 사용자에 대한 항목의 평균 평점을 다룬다. (어느쪽으로 뒤집느냐에 따라 다르다.)
- 해당 아이디어는 평균에서 벗어난 일반적이지 않은 평가 행동을 다루기 위한것. 
- 하지만 현실에서는 좋다기보단 유해함.
### 5-3. spearman rank correlation 
- 평점 대신 순위를 사용.
- 현실에서는 잘 사용하지 않음.
### 5-4. MSD
- 평균제곱편차. 
- cosine 유사도보다 더 이해하기 쉬운 유사도 metric. 
- 하지만 실제로 결과값 나쁜경우 많음
### 5-5. jaccard 
- 두 사용자에 대해 많은 항목이 공통부분 인지 or 두 항목에 얼마나 많은 사용자가 공통부분 인지로 나누어서 살펴볼것
- 이것은 매우 간단한 내재평가방식
  - jaccard보다 cosine similarity를 많이 사용.
### 5-6. 결론
- cosine 유사도를 default로!!



## 6.사용자 기반 협업 필터링(user-based collaborative filtering)
- 다른 사용자들의 평가 이력을 기반으로 그들이 추천한것들 중 내가 아직 보지 못한것을 추천하는 필터링기능
- 모든 사람의 모든 평점이 있는 표가 필요.
- 평점을 한축, 영화를 한축으로 사용자를 각각의 cell에 평점 값이 있는 2D matrix 생성가능

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/5ad802ac-05b9-4e6a-b174-216fe1389025)

  - cosine similarity를 보면 두 사용자가 100% 유사하다는것이 꼭 그들이 같은 대상을 좋아한다는 것을 의미하지는 않는다! 이것은 또한 그들이 같은 것을 싫어한다는것을 뜻할수도 있다.
  - ex) cosine similarity 100%의 의미
    - bob과 Ann이 둘다 스타워즈를 별점 1점으로 평가 
    - bob과 ann이 스타워즈를 별점 5점으로 동일하게 평가
  - 주의) 추천시스템할때는 희소데이터 때문에 사용자들이 공통으로 가진 영화가 몇개 있는지에 대해서 최소 한계치를 정해줘야 한다.

### 6-1.process추천시스템 생성(예시.bob을 위한 추천시스템 생성)

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/28a30625-a808-444f-aef0-b4d681489dfd)

  1. user -> item rating matrix
    : 사용자에 대해 그들이 평가한 모든 항목과 그 평점 값을 나타낸 룩업표를 만드는것부터 시작.(cosine similarity 이용하여 다른 유저들과 얼마나 유사한지 계산)
  2. user -> user similarity matrix
    : 그리고 모든 사용자 쌍 사이의 유사도 점수에 대한 또다른 2D행렬만들기. 이시점에 연산이 많이 든다. 그리고 아무나를 위한 추천을 빠르게 생성하는데 이 표를 재사용가능.
  3. look up similar users
    : 특정한 사용자를 위해 추천할때 우리는 그 사용자와 가장 유사한 모든 사용자를 찾아볼수 있다.
  4. candidate generation
    : 그 유사한 사용자가 평가했던 모든것을 한데 모아서 추천 후보들을 생성.
  5. candidate scoring
    : 유사한 사용자들이 그것들을 어떻게 평가했는지, 그 사용자가 그것들을 평가한 것이 여러분에게는 얼마나 유사한지, 그리고 원하는 다른 어떤 것이라도 살펴보면서 이 모든 후보들의 점수를 매김.
  6. candidate filtering
    : 마지막으로 사용자가 이미 시청한것을 걸러내기.

## 7.아이템(항목) 기반 협업 필터링

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/ac07f2c8-259f-4720-bc9f-d3d34d5ebd8f)

- 사용자 기반이 아닌 아이템 기준으로 filtering 하면 좋은 이유
  1. item은 영구적 속성을 가지는 경향이 있음.즉, 불변하는 대상에 초점을 맞추는게 좋음.
  2. user보다 item의 data가 더 적기에 2D matrix 만들때 간단히 만들수 있으며 연산또한 빠름.
  3. 새로운 사용자가 웹사이트 방문해서 어떤 한가지 item에 관심 표할시, 그들에게 비슷한 item 추천가능

- 사용자 기반 협업필터링과의 차이점은 우리가 사용자와 항목의 이용을 뒤바꾼다는것! 
- 그래서 사용자를 행으로, 항목을 열로 갖는 matrix로 시작하는것 대신에 item을 행으로 갖고 사용자를 열로 갖는 matrix를 사용하면 된다. 그리고 item들 사이의 유사도를 측정할수 있다.
- 사용자 기반 협업필터링에서는 사용자들이 모든 항목이 차원인 공간에 존재한다고 생각을 했고 이 사용자 벡터들 사이의 cosine 유사도를 찾아냈다. 이젠 뒤집자! 
- 모든 사용자가 차원인 공간에 item들이 존재한다고 생각하고 이 item 벡터들 사이의 cosine 유사도를 찾자.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/61124b79-8b90-48f3-baa4-f333574bb726)

  - 항목유사도를 통해서 A가 star wars만 보았고 B는 star wars, incredibel, empire 영화를 보았다면 B 기반으로 A에게 A가 안본 2가지 영화를 더 추천해줄수 있다.
  - 사용자 기반 or 항목기반의 협업 필터링으로 정확도를 측정할수는 없다.
  - 왜냐하면 그것들은 평점 예측을 산출하지 않기 떄문. 그러나 적중률을 측정은 가능하다. 왜냐하면 이것은 아직도 단지 순위 추천이니깐!(evaluateUserCF.py보자)


## 8.KNN Recommenders
- 협업필터링이라는 개념은 순위 예측을 하는 추천시스템에 적용되기 떄문에 일반적으로 KNN recommenders라고 불린다.

### 8-1. workflow
  - 사용자가 아직 평가하지 않은 것들의 순위를 예측해서 추천후보들을 만들어 낸다. 
  - 그리고 가장 높은 예측 순위 중에서 상위 k개의 아이템을 선택. 
  - 그 순간부터 나머지들은 모두 같은 방식으로 작동. 
  - 이는 효율적인 방법은 아니지만 순위를 예측하는 부분이기 때문에 시스템의 오프라인 정확도를 훈련/테스트나 교차 검증을 통해서 측정할수 있다. 
  - 이는 조사를 할떄는 유용한 방법. 
  - 문제점) 순위를 예측할 때 아이템 데이터나 사용자 유사도를 사용하기 때문에 이것은 여전히 협업 필터링으로 불린다는것! 
  - solution) 예측을 상위K개 아이템을 기본으로 하거나 가장 높은 유사도를 보이는 사용자를 기본으로 하는것! 이것이 바로 우리가 이를 KNN이라고 하는 이유.

### 8-2. user-based KNN

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/5d1e2fe2-c62c-4b73-a342-c74dc01b1de2)

  - user, item에 대한 순위예측이 목표이기 때문에 관심이 있는 사용자와 비슷한 사용자를 찾는것부터 시작.
  - 하지만 이 사용자는 관심이 있는 아이템을 평가한 사람이어야 한다. 
  - 이를 비슷한 k명의 사용자로 제한. 
  - 결국 k명의 비슷한 사용자들로부터 아이템에 대한 순위 세트라는 결과를 얻게 된다.
  - 이것들이 KNN이고 이 사용자가 우리가 예측해야 하는 사용자와 얼마나 비슷한지를 측정.
  - 다음으로 순위 그 자체를 가중해서 관련 순위에 대한 사용자 유사도 스코어를 가중 평균한다. 
    - 이 방법을 이용하면 사용자가 어떤 평가를 할지 그럴듯한 예측을 할 수 있다. 
    - 아이템을 평가했던 비슷한 사용자를 기반으로 말이다! 
    - 이 방법은 사용자 기반 협업 필터링과 유사. 하지만 작동방식은 완전히 다르다. 
    - 이는 사용자 대 사용자 유사도 metric을 핵심으로 하므로 비슷한 것을 좋아했던 사람에게는 추천하지 않는다. 
    - 대신에 데이터에 깊이 파고들어서 가능한 모든 경우의 아이템과 사용자에 대한 순위를 예측한다. 이는 더 복잡한 접근이고 보통은 안좋은 방법이다.

    - user-based knn

    ![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/b63f405d-4cc0-41d3-a6e5-7225fec58b89)

      - u : 사용자
      - i : 아이템
      - v : k명의 비슷한 사용자들
      - 사용자의 u와 아이템의 i 예측 순위는 k명의 비슷한 사용자를 합한값과 같다. 
      - 사용자 u와 k명의 비슷한 사용자들 v의 유사도 스코어를 모두 더한 다음에 사용자 v가 평가한 순위를 곱한다. 
      - 그 다음에 사용자 유사도 스코어의 합으로 나누어 준다. 가중 평균을 낸 것이고 이는 순위 예측에 사용될수 있다.


### 8-3. item-based KNN

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/ed5c356f-b9bc-40e9-bbb7-1fa94b2b69e7)

  - 아이템 기반 KNN도 정확히 같은 방법으로 작동함.
  - 사용자와 아이템이라는 단어만 바꾸면 됨
    - 아이템i에 대한 사용자 u의 순위를 예측하려면 k개의 아이템 세트로 시작해야한다. 
    - 이를 아이템 i와 가장 비슷한 사용자에 의해 평가됨. 그 이후는 같다. 순위의 가중 평균을 계산한다면 꽤 신뢰할 만한 순위 예측 가능.
  - 수식도 같지만 다른점은 사용자 u와 v 대신에 아이템 i,j를 사용한다는것!
  - 예측 순위는 k개의 가장 비슷한 아이템 세트를 기초로 한다. 
  - 이 아이템 세트는 문제가 되는 아이템을 사용자가 평가한 것.
  - 순위에 따라 가중된 아이템 유사도 스코어를 모두 더한 뒤에 유사도 스코어의 합계로 나누어준다. 
  - 이는 협업 필터링이라는 개념을 순위 예측이라는 틀 안에 넣었다는 점에서 안좋아 보일수 있지만 꽤 괜찮은 순위 예측법이다.
  - 만약 목표가 상위 N개의 추천 리스트를 만드는 것이라면 더 단순하고 직관적인 이전에 살펴봤던 접근을 사용하는것이 나을것. 
  - 다행히도 KNN은 surpiseLib에서 제공하는 알고리즘이다. 실습위해서 코드를 많이 쓸필요 없다.

ㅣ
---


[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}