---
title: "TFRS : TensorFlow Recommenders"
escerpt: "TFRS : TensorFlow Recommenders"

categories:
  - Recommand
tags:
  - [AI, Recommand, TFRS]

toc: true
toc_sticky: true

breadcrumbs: true

date: 2024-02-02
last_modified_at: 2024-02-02

comments: true
  

---

## 1. TensorFlow Recoomenders(TFRS) : 검색 단계 소개 및 구축
keras로 만들었으며, keras의 도구들 그대로 추천시스템 적용가능.

- TFRS는 두 단계를 통한 추천이라는 아이디어에 기반하고 있음.
- 검색 단계에선 추천 후보를 선정하는데 주어진 사용자가 어떤 항목을 좋아할 것인가 하는 문제로 검색 단계에서 선택되는 후보가 아주 많을 수 있어서 다 살펴보기 무척 힘들 수 있다.
- 문제점은 거대한 규모의 검색 단계를 간단하게 만들 필요가 있고 별개의 랭킹 단계에선 검색 단계에서 얻은 후보들에 대해 순위를 매겨 그중 최고를 알려준다
- 랭킹 단계는 더 작은 데이터 세트에서 작동하기에 우리는 유연성을 갖고 최고의 추천 후보들을 뽑기 위한 다양한 시도를 할 수 있는데 더 깊은 신경망이나 세련된 알고리즘 등을 활용할 수 있다.

## 2. Retrieval : the two towers(검색단계) 
![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/cedd4f08-11a2-4df5-800e-b7e7d6fd4c98)

  - 쿼리 모델과 후보 모델 두 부분으로 나뉜다.
  - 톱다운 형식이다.  
  - query model
    - 사용자 ID에 대한 부분
    - ex) movieLens dataset
      - 영화를 추천하기 위해 모든 사용자 ID를 변환하여 정수로 만들고 이를 임베딩 층으로 보낸다.
  - Candidate model(후보 모델)
    - 영화 ID에 대해 같은 작업을 하는데 영화 ID를 정수로 변환해서 이를 임베딩 층으로 보낸다.
  - 아래의 TFRS모델은 쿼리 모델과 후보 모델 양자를 인풋으로 취한다.
  
  - 여기선 쿼리 모델은 사용자 기반이고 후보 모델은 영화 기반인데 이 둘을 곱해서 선호도 점수를 구해낸다.
  - 특정 사용자와 영화의 짝에 부여된 평점으로 훈련하는 동안 임베딩 층은 덧붙이게 되고 사용자와 영화 짝에 대해 선호도 점수가 생성되며, 그걸 활용해 추천 후보들을 일차적으로 살펴볼 수 있다.

### 2-1. 작동방법
- embedding layer는 인코딩이 목적이라고 생각함.
- 범주형 데이터를 신경망에 제공하기 좋은 표준 포맷으로 바꾸는 용도라 생각.
- 그러나 embeddint layer는 추가적으로 각각의 고유한 ID를 하나의 n차원 벡터와 연결하는데 그 차원은 32차원이나 64차원 등 가능하지만 32비트 부동소수점 값의 벡터가 되고 이는 32차원 공간 내의 포지션으로서 사용자 ID 간, 혹은 영화 ID 간의 유사도를 나타내고 있다고 볼 수 있다.
- 임베딩 층을 이렇게 사용함으로써 희소 데이터와 희소 벡터 문제를 우회하는 한편 유사도의 척도도 갖게 되는데 쉽고 단순하게 추천 후보들에 대한 파악을 할 수 있다.

- 결과를 무작정 정리해서 최고의 추천 결과들을 추린 뒤에 검색 단계만으로부터 추천을 완료했다고 할 수도 있음. 
- 그러나 랭킹 단계가 대부분 뒤에 따라오기 때문에 일단 랭킹 단계를 다루기 전에 검색 단계를 좀 더 살펴봐야 한다.

### 2-2. code walkthrough


[TFRS](https://www.tensorflow.org/recommenders?hl=ko)


#### 2-2-1. quickstart 해석
- 필요한 패키지인 numpy, 텐서플로, 몇몇 데이터 구조를 TFDS란 이름으로, tensorflow_datasets를 TFRS란 이름으로 tensorflow_recommenders를 불러오고 설치한다.
- 먼저 데이터 세트를 읽는데 텐서플로 데이터 세트 패키지를 활용해 MovieLens100k 데이터 세트를 로드하고
- 평점과 영화 데이터에 대해 train을 분리하면 이건 평점 데이터 파일에 대응되고 타임 스탬프와 평점 값의 짝이된다.
- 아래는 영화 ID를 영화 이름과 대응시킨 영화 데이터 파일이다.
- 그다음엔 특성들을 선택하고 평점 데이터로부터 필요한 걸 추출하는데 영화 제목과 사용자 ID만 추출하자.
- 평점 자체는 추출하지 않을 건데 여기선 이를 암묵적 추천으로만 다루고 있기 때문.(그게 규모가 클 경우 하기 쉬우니깐!)
- 검색 단계에선 가능한 한 간단하게 진행하자. 엄청난 양의 데이터로 진행되는 단계이기 때문.
- 그런 의미에서 사용자가 평가한 영화는 재밌게 본 영화라고 간주함.

- 시간을 들여 봤다는 건 어느 정도 흥미가 있었단 거다.
- 나쁜 평점은 버리는 것도 가능은 한데 1점짜리 평점 영화를 흥미 있었다고 판단하기 싫다면 단순히 어떤 평점이든 영화에 대한 암묵적 긍정 평가이며 평점이 없는 것은 영화에 대한 암묵적 부정 평가라고 간주하자.
- 이는 너무 단순화됐으며 결과의 퀄리티에도 영향을 줄 수 있지만 랭킹 단계에서 만회할 수 있다.
- 다음엔 영화 데이터로부터 영화 제목을 추출하자. 관심사이기 때문.

- train split은 모델에 제공할 훈련 예시들을 생성한다.
- 데이터가 준비되었고 훈련 준비도 됐습니다


#### 2-2-2. 전처리
- 모든 사용자 ID 들을 가져와 고유의 정수로 변환한다.
- Keras의 stringlookup 전처리 층을 이용해서.  
- 영화 ID에 대해서도 동일하게 하는데
- 즉, user_ids_vocabulary를 StringLookup을 통해 string을 정수로 바꿔주는 Keras 층으로 두고 이에 대해 adapt를 호출해 훈련 데이터로부터 사용자 ID를 제공한다.
- 영화 제목에 대해서도 동일하게 하고 StringLookup 층을 설정하고 영화 제목을 제공한 뒤, 고유한 정수로 변환한다.

#### 2-2-3. 모델 정의
- tfrs.Model 클래스로부터 MovieLens 모델을 이어받을 건데, 상황에 맞도록 몇 가지를 덮어쓰기 해야 하는데 init 메소드는 몇 개의 파라미터를 가져오고 user_model과 movie_model은 두 개의 타워이다. 쿼리 모델은 user_mode이고 후보 모델은 movie_model이다.
- 제출할 task도 가져왔고 user_model과 movie_model을 앞에서 생성한 대로 정해주고 task도 그렇게 해준다.
- 손실함수도 정의하는데 이는 앞에서의 task 함수를 제출한 user_embedding, movie_embedding과 함께 호출한다.
- 사용자 모델과 영화 모델은 슬라이드에서 봤던 각각의 타워에 해당하는데 여기선 사용자 ID와 영화 ID의 임베딩 층들도 각각 포함하게 된다.
- 그래서 user_embedding와 movie_embedding이라고 하는 거다.

#### 2-2-4. the two tower 정의
- Keras의 순차 모델로 user_model을 정의하는데 이는 user_ids_vocabulary를 취하는 쿼리 모델이다.
- 각 사용자 ID를 뜻하는 고유 정수 값들로 구성된 리스트로!
- 임베딩 층은 벡터 사이즈 64로 사용할 건데 모든 사용자 ID를 위한 임베딩 층을 쓰고 각 사용자 ID는 64 부동소수점 벡터로 표현되며 64차원의 공간에서 사용자들의 유사한 정도를 나타낸다.
- movie_model에 대해서도 동일하게 하는데 정수값으로 표기된 영화 ID들을 뜻하는 movie_titles_vocabulary를 모든 영화 ID를 위한 64차원 사이즈의 임베딩 층에 넣어주는데 이 두 숫자는 일치해야 하고 둘의 차원은 같아야 한다.
- 한쪽이 64면 다른 쪽도 64여야 하고 objectives를 설정하고 task 함수를 모델에 제출한다.
- FactorizedTopK를 손실함수 평가지표로 제출하는데 이를 통해 훈련 중이나 후에 얻게 될 두 타워를 곱하여 얻은 선호도 점수를 가져온 뒤 평점을 부여하지 않은 것들의 선호도 점수와 비교하는 거다.
- 즉, FactorizedTopK는 사용자 ID와 항목 짝의 선호도 점수가 다른 것들보다 유의미하게 높은가를 묻는 것. 그렇다면 그게 추천하기 좋다는것이다. FactorizedTopK 평가지표의 역할을 설명하면 이렇다는것!

#### 2-2-5. 모델 실행
- user_model, movie_model로 MovieLensModel을 생성.
- 이들 각각은 모식도에서 봤던 쿼리 모델과 후보 모델이며 task는 손실함수를 정의.
- 이를 경사하강법을 위한 Adagrad 알고리즘을 써서 컴파일하고 배치 사이즈 496으로 3회 에포크를 통해 훈련.
- 값들을 바꾸면 달라지는지 실험 필요.
- 끝나면 factorized_top_k.BruteForce로 brute force 검색해서 주어진 사용자에 대한 최고의 추천들을 가려내줘야 한다.
- 여기선 사용자 ID 42의 추천 결과물을 얻게 될 건데 실행하고 작동하는지 체크필요.

#### 2-2-6. 에포크 과정
- 두 번째 에포크에서는 정확도가 좀 더 높아졌고 계속 올라간다.
- top N 평가지표이기 때문에 숫자가 작을 수 있는데 어떤 영화를 봤는지 아닌지를 예측하기는 매우 어렵다.
- 희소성 때문에 평가했는지도 알기 어렵다.
- 또 하나 짚고 넘어가자면 실제 사례에선 훈련 데이터와 테스트 데이터를 이렇게 나눌 수 없다.
- 여기선 모든 걸 훈련 데이터로 넣었는데 시간을 기준으로 데이터들을 나누면 좋다.
- 과거에 매겨진 평점들을 가져와서 그걸로 미래에 시청한 영화들을 예측할 수 있는지 보고 싶을 경우 여기서는 훈련과 테스트 데이터를 랜덤하게 나누고 있지만 현실에선 그건 바람직하지 못하다. 검색 단계에서 톱 3 추천을 얻었지만 신뢰성이 떨어진다.
- 'Rent-a-Kid', 'Just Cause'에 'Land Before Time 3'은 들어는 봤지만, 42번 사용자가 어떤 영화를 좋아하는지, 90년대 영화들이 어땠는지 모르는 상태로는 이 추천 결과가 좋은지를 평가하긴 어렵다.
- 이게 첫 번째 단계였고, 검색단계였고 이를 랭킹단계에서 다듬을수 있는지 체크해줘야 한다.
    

## 3. 랭킹단계 구축(순위단계 구축)
이 단계는 선택사항이다.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/ec44a83f-812a-4469-8599-75540b1e4587)

  - 랭킹 단계에선 검색 단계에서 생성된 후보들을 사용함.
  - 다루는 데이터 크기도 작아졌으니 더 나은 최종 추천을 얻기 위해 다양한 테크닉을 적용 가능
  - ex) 
    - 사용자와 영화 임베딩 층의 결과들을 함께 연결해서 밀집 층으로 보내고, 이를 점점 더 작고 밀집된 층들을 거치게 해서 주어진 사용자의 영화에 대한 최종 예측 평점을 낼 수 있음.
  - 주목할 것은 텐서플로 웹사이트에서 사용된 예시들의 평점 데이터 자체를 보존할 거란 것!
  - 암시적 평점 데이터로 다루는 대신 실제 평점 데이터를 제공하며 그 결과 실제 평점을 예측할 것이기 떄문.
  - 요점은 랭킹 단계에서는 이론적으로 더 복잡할 걸 할 수 있단 것. 왜냐하면 후보들을 더 촘촘하게 추려낼 수 있으니깐.
  - 텐서플로 사이트의 예제는 그렇게 하지 않고 있는데 무에서 시작해서 임베딩 층을 구성하고 검색 단계를 거친 후에 이를 일종의 랭킹 단계에 제공하고 있음.
  
### 3-1. code walkthrough

- 검색 단계에서는 가능한 단순한 과정을 거친다고 했음.
- 데이터 규모가 클 수 있으니깐.
- 하지만 랭킹에선 검색 단계의 결과물을 쓰는 거니까 데이터 수도 줄었기에, 더 복잡한 걸 할 수 있다.
- 여기서는 사용자 ID를 위한 임베딩 층과 영화 ID를 위한 임베딩 층을 만들것이다.
- 차이점은 이 둘을 연결하여 다층 퍼셉트론에 제공할 거라는 게 달라진 점인데 이를 점점 더 작은 뉴런 층들로 통과시키고 마지막엔 주어진 사용자 ID와 영화 짝에 대해 평점을 예측하는 단일 뉴런을 둔다.
  
#### 3-1-1. basic_ranking 해석
- tensorflow_recommenders를 tfrs로 불러오고 데이터 세트를 불러온다.
- 이번엔 사용자 평점 필드를 추출함을 기억할것.
- 평점 데이터의 영화 제목과 사용자 ID만 불러오는 게 아닌데 이번엔 실제 평점을 사용하기 때문.
- 암시적 데이터로만 다루는 게 아니다. 0에서 5점까지의 실제 평점으로 퍼셉트론을 훈련하고 아웃풋으로서 평점을 예측할 것이다.
- 로드하고 80%는 훈련 세트로, 20%는 테스트 세트로 데이터를 나누고
- 영화 제목과 사용자 ID를 고유한 정수들로 변환.
- 영화 제목과 사용자 ID를 구조로 추출한 다음, 하나로 연결해서 데이터 세트 내의 영화 제목과 사용자 ID의 목록으로 만든다.

#### 3-1-2. 모델구축(Architecture)
- 아키텍처는 사용자와 영화를 위한 각각의 임베딩 층을 만들어주는 건데
- 그 둘을 연결하여 다층 퍼셉트론에 보내서 최종적인 추천 예측을 할 것이다. 즉, 평점을 예측하는 것.
- 층들을 설정하는데 여기는 사용자를 위한 임베딩 층이고 검색 단계에서 설정했던 쿼리 모델과 아주 유사함.
- stringlookup을 사용해서 사용자 ID를 고유한 정수값으로 바꾼 후 이를 32차원의 임베딩 층으로 제공.
- 각 사용자 ID를 32차원 부동소수점 벡터로 변환하는 것.
- 영화도 역시 32차원의 임베딩 값을 갖는 임베딩 층 안으로 변환하고 마지막으로 self.ratings도 설정하는데 이는 다층 퍼셉트론으로서 받아들이고 평점 예측을 학습할 것.
- 먼저 ReLU가 적용된 256 층으로부터 64 층을 거쳐서 최종 아웃풋을 평점 예측을 하게 될 단일 뉴런으로 보내고 call 함수로 모든 걸 종합.
- 사용자 ID와 영화 제목을 인풋으로 두고 각각을 위한 임베딩 층들도 만들고 이들을 하나로 연결해 ratings 다층 퍼셉트론으로 보내고 사용자 임베딩 층과 영화 임베딩 층을 연결한 게 ratings MLP의 인풋이 된다. 운이 좋으면 끝에서부터 평점을 볼수 있다.

- 모델정의
  - 모델엔 특정 사용자 ID와 영화 짝을 제공할 수 있는데, 여기선 사용자 42이며 영화는 'One Flew Over the Cuckoo's Nest'입니다 뭔가 나와야 할 텐데 여기선 예측된 평점은 의미 없슴. 왜냐면 아직 모델 훈련이 안 됐으니깐.
  - 어쨌든 값이 나오고 있으니 작동은 한다는 것.
  - 구성이 됐다는 뜻인데 예측값 0.037은 이해할 만하다. 데이터가 없었으니깐.
  - 지금은 뭐든 0이라고 예측할 것.

#### 3-1-3. loss and metrics
- 모델을 훈련하기전 손실함수 정의
- TFRS에서 제공하는 간편한 ranking task object가 있는데
- 손실함수와 평가지표를 결합할 수 있게 해줌.
- 손실함수는 MeanSquaredError로 최적화할 평가지표는 RootMeanSquaredError로 두고 이는 훈련하면서 측정될 것.

#### 3-1-4. full moel
- TFRS 모델 클래스를 가져온 무비렌즈 모델을 만들고 ranking_model은 위에서 만든 랭킹 모델의 구조로 설정.
- task는 MeanSquaredError의 손실함수와 RootMeanSquaredError의 평가지표로 설정하고 compute_loss 함수도 만드는데 이는 주어진 사용자 ID와 영화 제목에 대한 랭킹 모델을 호출하며, 손실과 평가지표는 앞서 정의한 task가 계산할 것.
- 실행하고, 모델을 컴파일하자.

#### 3-1-5. fitting and evaluating
- 인스턴스를 생성하고, Adagrad 경사하강법을 학습률 0.1로 사용할 것이라고 밝혀주는데 그 값은 바꿔도 된다.
- 마지막으로 훈련과 평가 데이터를 셔플, 배치, 캐시하고, 훈련한다.epoch=3으로.
    
- 에러 평가지표가 점점 줄고 있다. 3번의 에포크 만으로도 수확 체감 단계에 왔음. 빠르게 수렴.
- 위에서 캐시해둔 시험 데이터로 모델 평가 가능.

- evaluation
  - 총 RMSE는 1.11이었기에, 나쁘진 않고 개선여지 충분.


- 정리) 두 임베딩 층을 결합해 다층 퍼셉트론으로 제공했고 최소한의 코드로 이 모든 걸 해냄. 이것이 TFRS의 위력임!
  

## TFRS : 부가 기능 및 심층 검색 통합

## TFRS : 다중작업 추천자 Deep & Cross Network ScanN 및 Serving

## Deep Factorization Machines


---


[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}