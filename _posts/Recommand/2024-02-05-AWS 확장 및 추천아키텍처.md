---
title: "AWS 확장 및 추천아키텍처"
escerpt: "AWS 확장 및 추천아키텍처"

categories:
  - Recommand
tags:
  - [AI, Recommand, SageMaker, Architectdure]

toc: true
toc_sticky: true

breadcrumbs: true

date: 2024-02-05
last_modified_at: 2024-02-05

comments: true
  

---


## 1. AWS SageMaker 및 Factorization Machines

- 아마존의 세이지메이커 서비스
  - 세이지메이커는 아마존 웹 서비스의 구성 요소이고 이걸로 클라우드 내 대규모 모델을 훈련할 수 있는 AWS가 관리하는 노트북을 만들 수 있다.
  - 그리고 클라우드의 모델에서 예측을 팔 수 있는데 이 방법으로 쉽게 꽤 대단한 추천 시스템 뒤의 컴퓨팅 마력을 얻을 수 있다.

### 1-1. AWS SageMaker 3단계

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/07b4ec47-c89d-457f-be19-d96233774b57)

  - tensorflow, apache MXNet 등을 사용하여 model만듬. 


  - train과 test data는 "protobuf"라는 형식이 있어야함. aws는 환경설정을 쉽게하는 utility제공.

  - SageMaker의 특징으로 hyper-parameter tuning을 설정하여 자동으로 교차확인 테스트 가능하며, test는 model에 대한 최상의 parameter로 수렴되고 train이 분배되어 병렬적으로 model train한다.

### 1-2. ex)SageMaker + MovieLens

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/afb6ced6-c9b1-4455-b6d3-54ee2f195acf)

  - MovieLens dataset을 sageMaker로 작업할 수 있는 형식으로 load
  - Factorization Machines은 고차원 dataset으로 작업하길 원해서 각 평가를 one-hot encode하자
    - ex) dataset에 500명의 사용자와 1,000개의 영화가 있다고 가정해보자.
      - 각 평가를 1,500개의 이진값으로 인코딩 
        - 첫 500개의 값이 각 사용자를 나타내고 다음 1,000개의 값은 각 영화를 나타냄.
      - 1,500개의 값에서 두 값을 하나로 설정.
        - 하나는 사용자에, 하나는 평가된 영화에 설정하고 나머지는 모두 0으로 설정
      - 이런 0은 공간을 너무 많이 낭비함.
        - 더 간단한 형식으로 원핫 인코딩된 각 평가를 저장하려고 희소 텐서를 사용
  - 훈련할 레이블 벡터도 필요
    - 주어진 사용자/영화 쌍에 대한 특정 평가가, 사용자가 영화를 좋아하는지 아닌지를 나타냄
    - ex) 4 이상의 평가가 레이블 1을 얻고 3 아래는 0을 얻는다고 해보자.
    - 알고리즘은 이것처럼 이진값과 잘 작동.
  - 희소 평가 벡터와 레이블 벡터가, 훈련과 테스트 데이터 세트를 위해 준비되면 그걸 protobuf 형식으로 바꾸고 sageMaker가 접근할 수 있는 S3로 사용.
  - SageMaker가 Factorization Machines model을 train하는 HW를 몇개를 spin-up하고 trained model을 제작 단계로 deploy한 후 주어진 사용자/영화 조합에 대한 predict가능.


## 2. 작동중인 SageMaker: 클라우드에서 백만등급의 Factorization Machines

```
## 무비렌즈 데이터 세트를 내려받고 압축을 해제
!wget http://files.grouplens.org/datasets/movielens/ml-1m.zip
!unzip -o ml-1m.zip

%cd ml-1m
!head -10 ratings.dat

## 판다스 라이브러리로 데이터 조작
import pandas as pd
ratings = pd.read_csv("ratings.dat", header=None, names=('userID','movieID','rating','timestamp'), sep="::")
ratings.head()

## 데이터에 훈련/테스트를 만들어서 모델을 훈련하고 평가
from sklearnmodel_selection import train_test_split
train, test = train_test_split(ratings, test_size=0.2)

train.head()

## 희소 원핫 행렬 설정(각 열마다 얼마나 많은 특징있는지 체크필요)
## 사용자 ID 당 feature 1개, 영화 ID 당 하나
## 그래서, 최대 사용자 ID와 제품 ID를 갖고 함께 더해서
## 얼마나 많은 특징이 훈련 데이터에 필요한지 알아야 함.
## 총 6,040명의 사용자 / dataset에서 영화는 3,952편.
numUsers = ratings.userID.max()
print(numUsers)
numItems = ratings.movieID.max()
print(numItems)
numFeatures = numUsers + numItems


## feature 만들고, 평가에 대해 tensor 만들어야한다.
## feature data가 거의 없기에, lil_행렬로 불리는 희소 행렬 사용 
## 훈련이나 테스트 데이터 프레임 중 하나를 취하고 feature matrix X와 label matrix Y로 바꾸는 함수
## data frame의 모든 열에 걸쳐 반복하면서, 평가의 사용자ID와 일치하는 feature column내 하나를 설정하고, 또한 평가의 영화ID에 일치하는 column내 하나를 또 설정
## 평점이 4 이상이면, 일치하는 label을 사람들이 이 영화를 좋아했다는걸 표시 / 그렇지 않으면 0
## 레이블을 float32 형식으로 바꾸는건 SageMaker 형식맞춰주기 위해서!
from scipy.sparse import lil_matrix
import numpy as np
def loadDataset(df):
    x = lil_matrix((df.shape[0], numFeatures)).astype('float32')
    y = []
    rowNum = 0
    for index, row in df.iterrows():
        X[rowNum,int(row['userID']) = 1] =1
        X[rowNum, int(numUsers)+int(row['movieID'])-1] = 1
        if int(row['rating']) >= 4:
            Y.append(1)
        else:
            Y.append(0)
        rowNum = rowNum + 1
    Y = np.array(Y).astype('float32')
    return X,Y


X_train, Y_train = loadDataset(train)
X_test, Y_test = loadDataset(test)

## 데이터를 "protobuf" 형식으로 바꾸고 S3에 넣자.
## 그게 writeDatasetToProtobuf 함수가 하는 일
## 나만의 S3 버킷만들기
import sageMaker.amazon.common as smac
import boto3, io
bucket="xxxx"
def writeDatasetToProtobuf(X,Y,name):
  buf = io.BytesIO()
  smac.write_spmatrix_to_sparse_tensor(buf, X, Y)
  buf.seek(0)
  boto3.resource('s3').Bucket(bucket).Object(name).upload_fileobj(buf)
  return 's3://{}/{}'.format(bucket, name)
trainingFile = writeDatasetToProtobuf(X_train,Y_train,"train.protobuf")
testFile = writeDatasetToProtobuf(X_test, Y_test, "test.protobuf")

## SageMaker에서 Factorization Machines 만들기
## AWS영역의 Factorization Machines model을 위한 container를 어디서 찾을지 정하기
## aws S3내에 키설정하기(결과모델 저장위해)
## Factorization Machines model은 Estimator를 만들어서 Factorization Machines container(c4.xlarge)에서 실행
## hyper-parameter설정
## fit 호출하면서 train/test data를 위해 S3 키를 통과
import sagemaker
from sagemaker.amazon.amazon_estimator import get_image_uri
from sageMaker import get_execution_role
container = get_image_uri(boto3.Session().region_name, 'factorization-machines')
outputFile = 's3://{}/output'.format(bucket)
fm = sagemaker.estimator.Estimator(continaer,get_execution_role(), train_instance_count=1, train_instance_type='ml.c4.xlarge',output_path=outputFile, sagemaker_session=sagemaker.Session())
fm.set_hyperparameters(feature_dim=numFeatures, predictor_type='binary_classifier', mini_batch_size=1000, num_factors=64, epochs=100)
fm.fit({'train': trainingFile, 'test': testFile})


## 요청된 하드웨어 할당 후 모델배포
## 해당 모델로 사용자가 영화를 좋아할지 예측가능.
fm_predictor = fmdeploy(instance_type='ml.c4.xlarge', initial_instance_count=1)

## result
## 배포한 predictor에 JSON 포맷 내에 있음을 전달 / JSON 데이터의 직병렬 변환 방법에 대해서도 전달
## 예측함수 호출해 test data의 label과 비교
## 예측과 실제값 비교하면 예측은 어려움
## 하지만, 많은 case에서 SVD보다 더 좋은 결과가 나타났음
from sagemaker.predictor import json_deserializer
import json
def fm_serializer(data):
    js = {'instance': []}
    for row in data:
        js['instances'].append({'feature': row.tolist()})
    return json.dumps(js)
fm_predictor.content_type = 'application/json'
fm_predictor.serializer = fm_serializer
fm_predictor.deserializer = json_deserializer
result = fm_predictor.predict(X_test[1000:1010].toarray())
print(result)
print(Y_test[1000:1010])

sagemaker.Session().delete_endpoint(fm_predictor.endpoint)
```


## 3. 개별화 목적의 추천 시스템

### 3-1. Amazon personalize
![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/e7f71669-bd5d-48c4-b07b-6d2adf1001f9)

  - 개별화된 추천/탐색/알림에도 사용가능
  - 콜드 스타트 issue/ 인기 / 편견 / 다양한 추천 시스템의 risk control 가능.
  - auto AML or auto machine learning 사용
    - 모델을 만든 후 데이터를 제공하여 추천하는 것과 추천하는 사람에 관한 메타데이터를 제공하고 아마존 S3에 upload
    - 개별화된 API에 행동 데이터를 실시간으로 넣어 사람들이 구매하거나 클릭한 명백하고 암묵적인 평가를 수집
    - API를 통해 평가를 아마존 personalize API에 넣어 해당 blockbox로 upload
    - amazon personalize는 수집되는 data를 통해 최적화모델 생성
    - 모든 정보에 기반을 두어 사람들이 어떻게 할지 예측하는 모델
    - 시스템에서 추천을 얻고자 개별화 API로 말하면 배치와 실시간 API를 제공해서 많은 사람에게 한 번에 추천을 주라고 말할 수 있거나, 사이트에 있는 이것에 대한 실시간 추천이 최신 정보로 필요하다고 하면 그것도 가능
    - 주의) API가 순위를 매긴 리스트를 준다는 점입니다
      - 그래서 시스템에 순위 매기는 걸 자세하게 배우는 겁니다
      - 평가를 예측하는 게 아니라 Top End 추천을 반환하는 겁니다
      - Top End 추천은 하루의 끝에 사람들을 위해 최적화하는 겁니다

### 3-2. recombee

- 강력한 추천엔진
- RESTful API로 상호작용한다는 점이 특징!
- activaity data를 보내면 recommendation을 받는다. 
- 비용 : $99~1499/month
- 개념적으로 아마존 personalize와 아주 유사하나 아키텍처에서 좀 더 단순
  
### 3-3. predictionIO
- 오픈소스 기계학습서버(추천시스템용은 아님)
- 이용하여 apache spark보다 높은 수준의 추천시스템 만들수 있음
- 새로 만든 추천시스템을 시스템안으로 플러그인 할수 있음.
- aws SageMaker와 유사
- 이미 훈련한 host model로 web service를 간단히 deploy 가능
- low cost 이며, 오픈소스

### 3-4. richrelevance
- Xen AI 제공
- 개별화 클라우드 제공
- 개별화된 추천이 아니지만 개별화된 탐색/내용/검색/값 매기기 등 제공
 
### 3-5. 그외 상업용과 오픈소스 해결책의 혼합

- peerius
- Strands
- SLI Systems
- ParallelDots
- Azure ML
- Gravity R&D
- Dressipi
- Sajari
- IBM Watson
- Segmentify
- Mr.Dlib
- Raccoon
- Universal Recommender
- HapiGER
- Mahout
- RecDB
- Oryx
- Crab
- LightFM
- Rexy
- QMF
- Spotlight
- tensorrec
- hermes
- CaseRecommender
- ProbQA
- Microsoft Recommenders
- Gorse
- Cornac
- Devooght
- LIBMF
- RankSys
- LibRec
- Easyrec
- Lenskit
- Apache giraph
    - 페이스북에서 추천용으로 사용

## 4.추천시스템 아키텍처

"어떻게 추천 시스템을 real world에 배치할 수 있을까?"

"어떻게 실시간 정보를 앱에 팔 수 있을까?"

### 4-1. recommendations in the real world:pre-computed recs

모든 사용자에 대한 추천을 미리 만들어서 해당 model을 활용하는 버전.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/96f1a990-6169-4565-a4ce-7b722a32c111)

  - idea) 사용자가 이용하는 시간보다 먼저 모든 추천을 미리 계산
    - 사용자 데이터와 카탈로그가 자주 바뀌지 않는다면, 데이터가 적다면 해당 방법이 합리적
  - user behavior data : user behavior data 저장소가 있으면 그 정보를 추천 모델(협력필터링, SVD, 신경망 등등)에 train

  - pre-generated recs : 미리 만든 추천세트를 배포한것을 이용하여 실제 데이터를 이용
  - rec service(fleet) : web 사이의 중개인 역할
    - 몇가지 형태의 RestFul 서비스로 제공가능.



### 4-2. recommendations in the real world:real-time collaborative filtering

모든 제품에 대한 유사도를 미리 만드는 model.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/b1261aae-40b0-402c-9c53-f6b50ff2c2c8)

  - 제품보다 사용자가 더 많다면 더 scalable 접근 가능. 왜냐하면 제품 속성은 안변하지만 사용자는 변하기 때문에.


  - 신규 사용자 행동 데이터의 영향에 대해 사용자 추천시스템을 만들고 싶다면?
    - 사용자의 구매나 클릭에 대한 사실을 활용하기 위해 대기할필요 없이 제품간의 유사도 기반으로 추천하여 바로 확인가능.
    - 왜냐하면 유사도는 사용자 행동 데이터에 기반을 하기 때문.

  - "pre-computed recs" 에서의 추천서비스는 site/app과 시스템 내 각 사용자에 관해 미리 만든 추천시스템간의 중개인역할을 했다.
  - 하지만 해당 경우는 더 많은 작업이 필요.
    1. 추천 서비스가 추천받고 싶은 사용자 ID를 얻도록 진행
    2. 사용자 기록과 사용자 행동 데이터를 return해주고 미리 만든 유사도 database와 hit한 결과를 사용자가 과거에 좋아한 제품과 유사한지 결과값 도출.
    3. 해당 결과값을 보고 이미 본것이면, 사용자에 대한 추천set으로서 site/app으로 return한걸 filtering진행.

  - 목적은 spread하게 퍼진 database를 보고 사용자가 과거에 좋아한 물건을 찾는것.
    - 해당물건의 유사한것을 찾아낸 후 모든 사용자가 분류하고 반환하기 전에 결과를 filter하기에 scalable하게 사용자의 행동에 따라 변할수 있다.

### 4-3. recommendations in the real world : deploy a trained model

현대적인 접근방식으로서, 모델을 주기적으로 사용자 행동에 기반을 둔 후, 훈련하고 모델 자체를 일부 서비스에 배포하는 방식.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/cb5530e3-7d85-47d9-af40-dbda6d57c342)

  - SageMaker에서 진행하는 모델 배포방식.
  - 실행시간에 사용자ID에 대한 추천을 return하는 모델이 작동한다.
  - 사용자 행동에서 지속적으로 작은 부분을 train하여 model update 후 실행시간에 서비스로 deploy된다.
  - 훈련된 신경망이 있다면 이미 모든 가중치와 편향 등을 fit하게 설정하였기에 지속적으로 train가능
  - 해당 아키텍처는 사용자의 속성(과거에 사용자가 좋아한것, 클릭한것 등)을 보내는 구조이다.

  
---


[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}