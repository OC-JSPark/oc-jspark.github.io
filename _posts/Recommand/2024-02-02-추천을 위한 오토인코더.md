---
title: "추천을 위한 오토인코더"
escerpt: "추천을 위한 오토인코더"

categories:
  - Recommand
tags:
  - [AI, Recommand, Rec]

toc: true
toc_sticky: true

breadcrumbs: true

date: 2024-02-02
last_modified_at: 2024-02-02

comments: true
  

---

## 1. deep neural network for recommendations

제한된 볼츠만 머신(RBM)은 굉장히 초기 형태의 신경망이다. 심층신경망을 써서 추천시스템에 활용해보자.하지만 극복할문제가 하나있음을 알자.

## 2. autoencoders for recommendations(autorec) 

[논문 : AutoRec : Auto-encoders Meet Collaborative Filtering](https://dl.acm.org/doi/10.1145/2740908.2742726)

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/1a12fa19-0a99-4125-bb3c-f7f730b35c71)

  - 세 가지 계층이 있는데 아래쪽 입력층에는 항목별 평점이 있고
  - 은닉층과 출력층은 예측 평점을 낸다.
  - 계층 사이의 가중치 행렬이 은닉층과 출력층의 편향 노드는 물론 신경망의 모든 인스턴스에 걸쳐 형성되어 있고
  - 논문에서 연구진은 신경망을 항목별로 한 번씩 학습시킴
  - 각 사용자가 항목들에 매긴 평점을 입력층에 값으로 넣었는데
  - 활성 함수로는 시그모이드 함수를 사용.
  - RBM을 사용했을 때보다 좀 더 나은 결과를 얻음
  - 하지만 두 구조의 구현 방식은 약간 다름
### 2-1. RBM vs AutoRec
- RBM : 경로마다 편향만 따로 있음
- AutoRec : 계산해야 할 가중치가 한 세트 더 있음.
  - 장점 ) 이런 신경망 구조는 텐서플로나 케라스 같은 현대적 프레임워크에서 구현하기 훨씬 쉽다
  - 단점 ) 다루고 있는 데이터의 희소성
- 논문에서는 실제 관측된 평점만 입력값으로 사용함.
- 즉 이 신경망의 각 경로를 따라 값을 연산할 때 신중히 접근해 학습 데이터에 실제 들어있는  평점 정보만 전달하고
- 미평가된 사용자-항목 쌍이 있을 때 결측 자료에 해당하는 입력 노드 값은 제외
- 이는, 텐서플로로 하기 어려운 작업으로 텐서플로에 희소 텐서가 있긴 하지만 신경망을 구현할 때 거쳐야 하는 여러 행렬 곱셈과 덧셈 연산을 실제 데이터가 입력된 노드에만 수행하게 하려면 아주 복잡한 방법을 거쳐야함.
- 어떻게 구현하든지 텐서플로나 케라스는 이 문제를 무시하고 **결측된 평점을 0점으로 취급**한다.
- 이는 추천 시스템에 딥러닝을 적용할 때 생기는 아주 근본적인 문제로 이런 신경망 구조를 **'오토인코더'**라고 한다.

### 2-2. 오토인코더 
- 입력층과 은닉층 사이의 가중치와 편향을 연산하는 작업을 입력 인코딩이라고 하는데 입력값에 나타난 패턴을 인코딩해 가중치의 형태로 은닉층에 보내는 것.
- 이어 은닉층과 출력층 사이의 가중치를 거쳐 출력값을 재구성하는 과정은 디코딩이라고 하고
- 가중치를 일차로 연산하는 단계는 인코딩 
- 이차로 연산하는 단계는 디코딩인 것.
- 이는 큰 틀에서 보면 RBM 방식과 다를 바 없는데
- RBM으로 따지면 순방향 처리는 인코딩이고 역방향 처리는 디코딩입니다

### 2-3. 데이터 희소성 문제 해결법**

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/74b1a000-f0cc-4f18-950b-c26b06b14e46)

  - deeper networks with keras
    - 은닉층 수를 늘린 더 깊은 심층 신경망을 사용하고 원핫 인코딩을 거쳐 사용자와 항목 데이터를 하나의 입력층에 넣는 방법이 있다.
    - 항목은 왼쪽 칸에 사용자는 오른쪽 칸에 기재되어 있는데 양쪽 모두 차원을 축소하고 드롭아웃 계층을 적용해 과적합을 방지
    - 도중에 둘이 결합해 하나의 심층 신경망을 이룬다.
    - 그러나 이 역시 **결측된 평점과 0점을 구분하지 못한다는 한계**가 있음
    - 기본적으로 이 구조는 결측된 평점을 보면 사용자가 그 항목을 극도로 불호한다는 신호로 받아들여 현실을 제대로 반영하지 못하고 왜곡함.
  - 결국 이 신경망 구조는 무비렌즈 데이터로 실험한 결과 행렬 분해 기법의 성능을 넘어서지 못했는데
  - 데이터 희소성 때문이기도 하지만 평점 십만 건으로는 이토록 복잡한 신경망을 학습시키기에 데이터 양이 턱없이 모자랐기 때문.

주의) 딥러닝을 추천시스템에 적용시, 결측된 평점을 0점 취급하는 오토인코더나 텐서플로를 구현하게 될 수도 있으니 주의할것!

## RNN을 사용한 클릭스트림 권장 사항

## 추천을 위한 Generative Adversarial Networks

## TensorFlow Recoomenders(TFRS) : 검색 단계 소개 및 구축

## TensorFlow Recoomenders(TFRS) : 순위 단계 구축

## TFRS : 부가 기능 및 심층 검색 통합

## TFRS : 다중작업 추천자 Deep & Cross Network ScanN 및 Serving

## Deep Factorization Machines


---


[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}