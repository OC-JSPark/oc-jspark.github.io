---
title: "딥러닝개론1: 지도,비지도,선형회귀"
escerpt: "지도학습,비지도학습,선형회귀"

categories:
  - DeepLearning
tags:
  - [AI, DeepLearning, supervised, unsupervised, linear regression]

toc: true
toc_sticky: true

breadcrumbs: true

date: 2023-09-25
last_modified_at: 2023-09-25

comments: true


---

# 1. 인공지능,머신러닝,딥러닝
![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/15578eeb-5f22-4e6a-bf23-51e0276acda2)

## 1-1. 인공지능 
: 기계가 기능적인 행동을 하는것.(학습을 하지 않음!)

## 1-2. 머신러닝 
: 기계가 코드로 구현이 아닌, 데이터로부터 학습!! 
    
- tree계열 : 의사결정(Decision tree)
  ![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/430d97b7-2ce8-4ea7-9118-cd7011fe1d06)
    

    - ex) 내일 비가 오는가? 에 대해서 첫번째 특징인 습도에 대해 50%이상이면 왼쪽, 이하면 오른쪽 이런식으로 tree따라 간다
    - gradient boosting, random forest 등이 있다.
    ![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/c8f85344-ed17-47cf-8cb0-ffe00949ddf5)

- SVM(Support Vector Machine) : 2가지 task를 나누는 직선을 찾는것. 어떤 직선을 만들때 가장 직선에서 수직거리가 가까운 포인트가 바로 Support Vector이다. 2가지 Support Vector 사이의 거리를 margin이라 한다. margin을 최대화하는 직선을 찾는 task이다. 가장 빠르게 작동하기때문에 간단한 모델에 적용하기 좋다.
  ![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/db8b4a89-e92f-41e6-926a-329dd9442627)

- 성능,예측력은 부족하지만 모델의 해석력이 좋다.
     
## 1-3. 딥러닝 
: 깊은 신경망 구조의 머신러닝

- 신경망 : hidden layer 수가 많은 깊은 신경망을 딥러닝이라 한다.
  - end-to-end 구조(종단간 구조)이다. 즉, 프로세스가 통합되어 있고 신경망구조이므로 해석하기가 힘들어 블랙박스이다.
    ![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/a2cf195a-22ea-40a7-abd3-9bbeca2165e9)

  - 성능(예측력)이 높다.
  - 해석하기 힘들다 (node 간의 연결을 해석하기 힘들다.) 
  - ex) MLP(Multi-layer-perceptron), CNN(Convolution neural network), RNN, Transformer
    - CNN은 input이 이미지로 들어온다. 이게 filter를 통해 local 영역을 하나의 특성으로 이끌어내서 featrue extraction을 진행한다.
      ![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/6439a99c-f506-45e8-91b7-de35741a4698)

    - perceptron : input 이 있으면, output이 있는 구조이다.
      ![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/66d3c74a-2bf2-4d10-9778-b38097e67f3a)

    - RNN은 어떤 노드가 다시 본인에게 회귀하는 경우.이떄는 timestamp가 중요하다.NLP쪽에서 많이 사용된다. 예를 들어 문장을 읽을때 이 정보가 앞에 등장하는지, 뒤에 등장하는지가 큰 의미를 가진다. 이런정보를 활용할떄 RNN사용한다. 
    - Transformer은 ViT라고 해서 vision쪽에서도 Tranformer를 활용한다. self-attention이라는 구조를 사용하는 딥러닝이다.

# 2. 학습(learning)의 개념과 원리
![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/0bbd91cf-98e8-4e34-b85c-e5ea55b558be)

- command 
: if/else 형태인것.

- learning(=trainig) 
: 모델은 데이터를 받아서 예측을 하는 역할을 한다.

  - 딥러닝에서 모델이 계속 바뀐다. 다만 예측력이 높은것으로 바뀐다.
  - 이러면 개발자가 예측되지 않은 데이터가 오더라도 예측이 가능할 수 있다.

## 2-1. 깊은신경망 
: 가중치를 곱해서 새로운 feature를 만들어낸다. 즉 모든 feature의미가 모두 다르다.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/2b5b6a25-8775-40a3-98b4-d1f2374a8d78)

  - 출력은 결과이며 예측값이다. 
  - 은닉층의 수가 많으면 깊어진다. 즉 딥하다. 
  - 복잡한 특성을 추출하고 학습할 수 있다.
  - 다양한 조합을 통해서 새로운 feature를 뽑아낼수 있다.
  - node가 만약 더 많이 생긴다면 복잡한 특성을 예측할수 있다.

## 2-2. 머신러닝에서의 학습 
: 데이터가 들어오면 모델에 학습시켜 예측을 한다.

## 2-3. 데이터셋 분할(split)
- train set / test set 으로 나눠서 한다. 
- 모델평가를 위해 test set을 사용한다. 
- test set을 random 으로 분류할수도 있다.  
- 그러나 만약 **분류문제** 라고 한다면 class imbalanced 문제가 발생할수 있다. 그럴때는 **stratified sampling(층화추출)** 이라고 하여 클래스별로 test set을 일정한 비율만큼 추출하는 방법활용하는것도 방법이다.
  ![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/3cfbb458-b834-4199-8757-b85deed8f3a5)


- 우리는 그래서 train : val : test으로 나눈다.
  - 왜? train에서 따로 val을 뽑아낸다. 
  - 학습은 train으로만 이루어지고, val은 같이 실시간으로 평가를 이루어 낸다. 
  - 학습이 이루어 지다가 train성능이 떨어지는 구간이 있는데 이때가 overfitting이 일어난 때이다. 
  - 즉 validation 성능은 학습하는 중에 일반화 성능을 측정하기 위해서이다.  
  - hyperparameter(learning rate, 모델의 layer수, 등) 다양한것들을 바꿔가면서 실험해야 높은 validation이 나오는지를 알고 그 지표를 찾아야 한다.

- 학습을 하는 목표? 더 나은 예측모델을 찾기 위해서! 
- 모델은 신경망모델을 말한다. 
- 일반화 성능(범용적인모델)을 높이는게 중요하다. 단순하게 train dataset에 대한 성능을 높이는게 아니라 전혀 별개의 새로운 dataset에서도 높은 성능을 낼수 있는 일반화 성능을 목표로 한다. 그것이 바로 더 나은 예측모델의 정의다!!
  


# 4. 지도학습(supervised learning), 비지도학습(unsupervised learning)

## 4-1. segmentation
: 영역을 기준으로 한다.각각의 pixel이 어떤 class 해당하는지에 대한 정보가 담겨있다. 즉 pixel별로 classification을 한다.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/443a0f97-cb6c-4ada-8314-f008436d4a18)

## 4-2. object detection
: bbox를 찾는것이다.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/92f99fe6-bf51-4aa5-aedc-41f7b94116b5)

  - 하나의 label = pt1(x,y), pt2(x',y'), cls
  : 좌측상단좌표, 우측하단좌표, 해당 bbox안의 분류클래스 number

## 4-3. Groud-truth vs label
: label은 답지!! 이를 기반으로 model학습을 한다. 
- groud-truth는 완벽한모델이 예측할수 있는 이상적인 결과를 말하며,
일반적으로 label과 유사한 의미이다.

## 4-4. 지도학습(supervised learning)
: label이 data에 존재하는 경우.

## 4-5. 비지도학습(unsupervised learning)
: label이 없는데도 학습하는경우
- label은 비용이 많이 든다.

- ex) K-means Clustering
: 군집화(clustering) 하는것. 

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/e79696ef-b813-47dc-b202-0acb44b03e93)
k의 숫자에 따라 군집화의 수를 정함.

  - [K-Means Clustering Algorithm](https://www.javatpoint.com/k-means-clustering-algorithm-in-machine-learning)

  ![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/899e6997-8d7d-40b6-bc8c-c253b25e7981)

## 4-6. 반지도학습(semi-supervised learning)
: 지도학습 + 비지도학습

- ex) Psudo-labeling
: confidence를 기준으로 하여 높은것만 선별하여 학습데이터로 활용

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/92b583ce-ef9b-4dcd-9d6e-a00bf6cb71c4)


# 5. 선형회귀 (linear regression)
: 선을 그어 값을 예측한다.
- **cost를 가장 적게하는 model(직선)을 찾는게 목표이다.**
- **하나의 feature를 생성하는 가중치의 조합** 이라는거에 point를 맞추어 생각하면 딥러닝에 접근이 쉽다.

- regression vs classification 

|비고|regression|classification|
|---|---|---|
|task|집값 예측|개/고양이 분류|
|기계학습category|회귀|분류|
|설명|regression은 input이 들어오면 model이 숫자를 예측한다.|classification은 0,1로 되어있다면 input 들어온걸 model이 0 or 1로 클래스를 예측한다.|

- 선형회귀 방법
  - 1) 데이터를 일반화하는 선을 찾는다.
  - 2) 그 선을 이용해 새로운 데이터를 예측한다.

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/1a4d8676-d71b-4a76-91af-640605a44253)

  - y= ax + b
  ![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/5a2ed830-d622-46dd-b9f4-7bb550fdf1d2)

  - 정도를 맞추기 위해 **scaling 기법**을 사용한다.
  - cv에서는 전반적으로 전체 pixel에서 value를 scaling하든가, normalization하든가 한다.

- 편향(bias)이 필요한 이유
: 효율적인 학습을 위해서

- 회귀직선

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/beb747e9-3ddd-40c5-9b07-c9d777e51517)

  - H(Hypothesis) = 예측값(Prediction)
  - W : 기울기
  - y : 실제값(=label)

- 비용함수(Cost function)
: error들의 합

![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/834b8530-b13c-4446-90d5-a8d4e7d01e62)
  - model이 다양하게 나올때 cost를 기준으로 cost가 적은 model을 선택하기 위해 비교가 필요한데 예측값-실제값=error 값이 +,-가 상쇄 되는경우가 생기기에, 제곱을 하여 비교를 한다.



---


[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}