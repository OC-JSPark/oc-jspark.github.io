---
title: "운영체제"
escerpt: "운영체제"

categories:
  - System
tags:
  - [System]

toc: true
toc_sticky: true

breadcrumbs: true

date: 2025-03-26
last_modified_at: 2025-03-26

comments: true
 

---

## 1. 운영체제 역할 및 동작 원리


컴퓨터 구조 파트에서 학습한 다양한컴퓨터부품들(= 리소스 들)은 누가 움직이게 만들까? 운영체제가 한다(ex.windows, macOS, Linux, android, iOS 등)

> (시스템)리소스 ? <br>
: 자원, 실행에 마땅히 필요한 요소

> 프로세스 ? <br>
: 현재 실행중인 프로그램

운영체제는 자원을 관리하고 할당하는 특별한 프로그램

<img width="418" alt="Image" src="https://github.com/user-attachments/assets/d99f8f4c-7ac6-4b4b-89e1-22cc859ea552" />



  - 모든 프로그램들은 실행이 되기위해선 메모리라는 하드웨어에 적재가 되어야 한다.

  - 그러나 운영체제는 메모리에 적재되는 특별한 영역이 존재한다 -> **커널영역**

  - 그래서 운영체제는 커널영역에 할당되어 있는 특별한 프로그램으로서, 사용자 영역에 할당되어 있는 많은 프로그램들에게 메모리할당해주고, 실행끝나면 메모리 반환하도록하는 메모리 자원을 관리하며, 모든 프로세스가 실행되기 위해선 CPU가 필요한데, 이런프로세스들에게 CPU를 할당 및 반환을 해주고, 응용프로그램들에게 어떤 보조기억장치의 어디에 저장하라는 할당/반환역할도 해준다.

<img width="327" alt="Image" src="https://github.com/user-attachments/assets/bcd05181-2797-47b2-b40e-8b78e583aef5" />

  - 운영체제는 하드웨어와 우리가 개발하고 실행할 응용프로그램 사이에 위치해 있는 프로그램이라고 부를수 있다.  

운영체제의 핵심부, 커널(kernel)
  <img width="329" alt="Image" src="https://github.com/user-attachments/assets/d0386092-b672-4e08-9e4d-f06114d5193a" />

  <img width="713" alt="Image" src="https://github.com/user-attachments/assets/10519982-0db9-4c29-be4f-e8ab5f767bc1" />

  - `https://kernel.org` 가보면 리눅스 운영체제의 커널 소스코드를 볼수 있다. 즉 운영체제 = 커널

커널이 아닌것? 사용자 인터페이스 부분이 있다.  

응용프로그램(사용자 프로그램)의 자원 임의 접근 가능? 반드시 운영체제 거쳐서 (문지기 역할) 가야한다.
  - 이중모드
    - 커널모드 : 운영체제 서비스를 제공받을 수 있는 모드(입출력 가능) = 커널 영역의 코드를 실행할 수 있는 모드
    - 사용자 모드 : 운영체제 서비스를 제공받을 수 없는 모드 (입출력 불가능) = 커널 영역의 코드를 실행할 수 없는 모드

시스템 콜 : 운영체제 서비스를 제공받기 위해 커널 모드로 전환하는 것 (=**소프트웨어 인터럽트**)

<img width="359" alt="Image" src="https://github.com/user-attachments/assets/8815f668-12f0-48d0-b412-a1a7e55c87bc" />


  - 사용자 영역에 적재된 응용프로그램이 자원에 접근하려면 운영체제의 도움을 받아서 커널모드로 전환된 후 실행이 되어야 한다. 이를 `시스템 콜` 이라 한다

  - 응용프로그램이 시스템 콜 = 시스템 호출을 하게 되면 운영체제의 특정 코드로 jump를 하게 되고, 내가 원하는 자원에 접근하는 코드를 실행할수 있게 되고 다시 원래 응용프로그램의 소스코드로 돌아오게 된다.

  - 즉, 시스템콜은 인터럽트 일종이라고 볼수 있다.

ex) "hello world!"출력 프로그램 과정에서 몇 번의 시스템 호출이 발생할까?

```C
$ cat hello.c
#include <stdio.h>

int main()
{
  printf("hello world\n");
  return 0;
}
$ gcc -o hello hello.c
$ ./hello
hello world

$ strace ./hello
$ strace python3 hello.py
```
  - 하나하나가 "hello world!"라는 프로그램이 실행하기 위해서 운영체제에 부탁한 시스템콜의 일종임을 알수있다.

정리) 일반적인 프로그램 입장에서 볼때 운영체제는 자원에 접근하기 위한 인터페이스를 제공해주는 특별한 프로그램이라고 볼수 있다.

운영체제의 서비스에는 어떤것이 있을까?
  1. 프로세스 관리 : 실행중인 프로그램을 프로세스라고 한다.
  2. 자원 관리 접근 및 할당 : CPU, 메모리, 보조기억장치 & 입출력 장치를 자원이라고 한다.
  3. 파일 시스템 관리 : 파일시스템이란 파일과 디렉토리를 관리해주는 운영체제 내부의 프로그램이다. 윈도우에서는 폴더라고 부른다.

### 1-1. 운영체제 정의


### 1-2. 운영체제 특징

### 1-3. strace

시스템 콜을 추적하기 위한 도구

```shell
$ man strace

# 설치 
$ apt-get install strace

#기본 사용법
$ strace [COMMAND] # ex)  strace ls
$ strace -p [PID]

# 시스템 호출 결과를 콘솔에 출력하지 않고 파일로 저장
$ strace -o output.txt ls 

# 시간과 시스템 호출 결과 출력
$ strace -t ls  # 타임스탬프
$ strace -tt ls # 밀리세컨드 타임스탬프
$ starce -T ls  # 각 시스템 호출 소요 시간

# 시스템 호출 요약 결과 출력
$ strace -c ls  # average microseconds spend on each call

# 실행 파일의 시스템 호출 결과 필터링(조회하고싶은것만 필터링하기)
$ strace -e trace=open, read ls # ls명령어 실행할때 read, open이라는 시스템콜이 있는것만 조회하기

```
  - man : manual의 약자이다
  - ls :  /bin/ls 에 있는 프로그램이다.
  - 모든 실행중인 프로그램에는 PID라는게 고유적으로 할당되어 있다.

프로그램일 실행되는 과정에서 시스템콜은 굉장히 빈번하게 호출되기 때문에 시스템콜을 불필요하게 많이 호출된다면 성능이슈에 문제가 생길것이다. 이러한 부분을 컨트롤 할줄알기 위해선 strace를 많이 사용하게 될것이다.

```shell
$ torch a.txt # 빈 a.txt생성하기
$ rm a. txt # a.txt 삭제하기
```

### 1-4. 시스템콜 종류

[참고자료 : linux man pages](https://man7.org/linux/man-pages/)
[참고자료 : chromium 프로젝트 사이트](https://www.chromium.org/chromium-projects/)

| 시스템 콜 | 의미 |
| --- | --- |
| open | 파일을 여는 시스템콜. 파일 디스크립터 반환 |
| close | 파일을 닫는 시스템콜 (파일 관련 자원 해제) |
| read/write | - |
| fork | 프로세스 복제하여 자식 프로세스 생성 <br> 복제된 프로세스를 자식프로세스로 생성하는 시스템콜이다. <br> 프로세스들이 계층적으로 구성되는 원리 <br> 계층구조의 원리는 부모와 자식 프로세스로 구성되어 있기 때문이다.|
| 
| exec | 현재 프로세스의 주소 공간을 새로운 프로세스로 덮어쓰기 <br> 자식 프로세스로 하여금 다른 코드를 실행토록 하기 <br> 자식 프로세스의 메모리 공간을 다른 프로그램이 이루고 있는 소스코드로 바꿔치기 하는 시스템콜 |
| getpid/getppid | PID를 반환하는 시스템콜 <br> 부모 프로세스 PID를 반환하는 시스템 콜 |
| syslog | 시스템 로그 메세지 남기기기 |
| exit | 실행중인 프로그램 종료 | 



> 파일디스크립터(file descripter) <br>
: 파일을 가리키는 고유한 값

파일의미?
  -  파일이란 말은 장치또한 포함되며,socket, ICP도구들 등 다양한 것들을 파일들로 간주한다.



```shell
# open/close
## 무언가 쓰여져 있는 source.txt가 있으니 만들어보자.
## cat syscallex1.c
$ echo "A" > source.txt
$ gcc syscallex1.c -o syscallex1
$ ./syscallex1
$ cat destination.txt # destinatation.txt가 생성되어 있기 때문.

# fork/exec
# path = "C:\Users\jspar\Downloads\persornal\study\250305-230502_[패캠] 현실 세상의 컴퓨터공학 지식 with 30가지 실무 시나리오 초격차 패키지 Online\자료\computer-science-main\운영체제"
## cat syscallex2.c
$ pstree  # 계층구조 확인 가능
$ gcc syscallex2.c -o syscallex2
$ ./syscallex2

$ gcc -o syscallex3.c -o syscallex3
$ ./syscallex3  # 프로세스 메모리영역을 특정프로그램으로 실행할수 있게끔 특정프로그램의 덮어쓰기 하는 기능

# getpid/getppid
## cat syscallex4.c
$ gcc -o syscallex4.c syscallex4
$ ./syscallex4
$ ps  # parent process ID는 현재 명령어를 치고있는 bash shell을 의미하게 된다. 즉, bash shell의 자식 프로세스로서 process ID가 실행되어있음을 알수 있다.

# syslog
$ cat /var/log/syslog # 시스템상에서 발생한 로그확인가능.
# 프로세스 단에서 임의로 남겨줄수도 있다.
## cat syscallex5.c
$ gcc -o syscallex5.c syscallex5
$ ./syscallex5  # 즉 로그를 남기는것도 시스템콜을 통해 할수 있다.

# exit
## cat syscallex6.c # exit(0)은 정상적인 종료를 의미함. 이것 뒤에코드는 당연히 실행되지 않음.
## return 0; 의 의미는 exit(0)을 내포한다. 즉, main loop가 끝나면 exit함수에게 0번인자를 전달해주겠다는 C언어의 의미이다.

```

## 2. 프로세스와 스레드
커널영역과 사용자 영역의 프로세스

프로세스란 ? 실행중인 프로그램

* 같은 프로그램도 별도의 프로세스가 될수 있다.

```shell
$ ps -ef
$ ps
$ man ps
```
 
### 2-1. 프로세스 종류
포그라운드 프로세스
  - 현재 사용자가 직접 실행하고 있는 프로세스
백그라운드 프로세스
  - 현재 사용자가 직접 실행하고 있지 않은 프로세스
  - 서비스, 데몬이란것도 있다.
    - 서비스 : 백그라운드 프로세스의 일종으로서 사용자와 상호작용하지 않으면서 실행되는 프로세스

```shell
# 현재 어떤 백그라운드 프로세스, 서비스가 실행되고 있는지 볼수 있다.
$ systemctl list-units --type service
```

프로세스 제어블록(PCB)
  <img width="439" alt="Image" src="https://github.com/user-attachments/assets/9ad05e36-bc85-454f-904d-8bb7ec7f842c" />

- 운영체제는 많은 프로세스를 어떻게 관리할까?
    - PCB라는 자료구조(데이터덩어리)가 필요하다.
    - PCB란, 동시다발적으로 실행되는 수많은 프로세스들을 효율적으로 관리하기 위해서 프로세스마다 만든 꼬리표같은거다. 운영체제는 PCB를 통해서 프로세스를 식별하고, 상태를 확인할수 있게 된다. 즉, 모든 프로세스마다 PCB라는 데이터덩어리가 할당되어 있고, 운영체제는 이를 식별할수 있다.

  - 같은 프로그램이라도 여러번 실행시 별도의 프로세스가 될수 있다. 그렇다면 이런경우 PCB가 각각할당되었을까? 아님 하나의 PCB를 공유할까? 당연히 각각 PCB가 할당되어 있다. 왜냐하면 운영체제는 PCB를 통해서 식별하기 때문이다. 또한 별도의 프로세스이므로 각각의 PID를 갖고있게 된다.

  - PCB는 운영체제의 커널영역 내에서 할당되어 있다.
  (커널영역 ? 메모리내의 운영체제가 적재되어 있는 아주 특별한 공간을 의미함)
    - 여기서 새로운 프로세스가 실행되면 PCB가 생성되고 실행종료되면 PCB가 폐기된다.

  - PCB에 적혀있는 내용은 무엇이 있는가?
    1. PID(PPID)  = process ID
      - 학교의 학번처럼 프로세스에 할당되어 있는 고유번호.
      - PPID는 프로세스를 생성해낸 부모프로세스의 PID도 명시된 경우도 있다.
      - 프로세스가 새로운 프로세스를 만들어낼수도 있다.  이때 기존 프로세스를 부모프로세스, 새롭게 만들어진 프로세스를 자식프로세스라고 부른다. 이때 자식프로세스 입장에서 나를 만들어준 프로세스가 무엇인지 알아야 하므로 PPID가 필요할때가 있다.
    2. 레지스터 
    3. 스케줄링 정보
      - 해당 프로세스가 얼마나 자주 할당되어야 할지 빨리 실행되어야 할지 등도 명시가 되어 있어야 효율적으로 실행할수 있을것이다.
    4. 메모리 정보
      - 프로세스가  메모리에 어떤부위에 적재되어 있는지 알아야 관리할수 있으므로.
    5. 사용한 파일 정보
    6. 입출력장치 정보

```C
$ cat pidex.c
# include <stdio.h>
# include <unistd.h>

int main() {
  pid_t pid, ppid;
  pid = getpid();   // Get the process ID
  ppid = getppid(); // Get the parent process ID

  printf("Process ID: %d\n", pid);
  printf("Parent Process ID: %d\n", ppid);

  return 0;
}

$ gcc -o pidex.c pidex
$ ./pidex
Process ID: 4460
Parent Process ID: 3254
$ ps
3204 : bash   //즉, 부모프로세스는 bash임을 알수 있다.
```
  - 현재 명령어를 치고있는 bash shell이 3204이고, bash가 새롭게 생성한 명령어가 pidex.c파일을 컴파일한 pidex가 된다.

```shell
# 프로세스 확인 명령어
## 사용한 파일 정보 
$ ps aux | grep 3254

## 입출력 장치 정보
$ pgrep -l bash

## PID를 기준으로 어떤 프로세스인지 조회하는 명령어
$ pidof [프로세스 이름]
$ pidof bash // bash 프로세스의 pid를 조회할수 있다.
```

실제로는 이보다 복잡하다
  - [linux kernel -task_struct](https://web.git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/tree/include/linux/sched.h?h=v6.3.13#n737)
    - 리눅스 커널에는 PCB로서 task_struct라는 구조체가 있다.
    - [리눅스 커널 git](https://web.git.kernel.org/)
   
문맥교환

  - 문맥(context): 실행을 재개하기 위해 기억해야 할 정보
  - 문맥교환(context switch) : 여러 프로세스들이 번갈아가며 실행되는 원리

  * 일반적으로 자원의 개수보다 일반적으로 실행되는 프로세스의 개수가 훨씬 많다. 그래서 다양한 프로세스들은 번갈아 가면서 한정된 자원을 이용하게 된다.이때 활용되는 개념이 **문맥교환** 이란 개념이다.

<img width="421" alt="Image" src="https://github.com/user-attachments/assets/c1f11f01-32f3-49de-8350-3db956a5230b" />
  
  - 프로세스 A와 프로세스 B가 번갈아가면서 실행된다고 가정해보자.
  - 프로세스 A가 실행될때는 CPU내 레지스터등에 프로세스A정보가 저장되어 있을것이다. 그러나 하나의 프로세스가 CPU를 독점할수 없기 때문에 이후 프로세스B가 실행될때는 CPU내 레지스터등에 프로세스 B정보가 저장되게 될것이다. 이렇게 실행을 재개하기 위한 정보들을 교환하는것을 문맥교환이라고 한다.
    - 프로세스A가 끝나갈때쯤 프로세스B에게 바통을 넘겨주기 전에 지금까지 내가 어디에 어떤정보를 실행했는지에 대한 정보를 스택에 `백업`을 한다. 그리고 프로세스B가 현재 어디까지 실행되었는지에 대한정보를 `복구`하게 된다. 즉, 백업하고 복구하고 이러한 과정이 반복되면서 여러 프로세스들이 번갈아 가며 실행되는 원리이다.

    <img width="469" alt="Image" src="https://github.com/user-attachments/assets/ce73d5ea-909e-4d5a-bf14-75e265c8c4a5" />

    - 시간축으로 표현한것.
 
문맥교환이 빠르게 일어나면 여러 프로세스가 동시에 일어나는것처럼 보이게 할수 있지만 문맥교환시 발생하는 비용도 중요한 문제이다.

커널영역에서는 PCB. 그렇다면 사용자 영역에서는?

  <img width="481" alt="Image" src="https://github.com/user-attachments/assets/c990b423-8066-487d-9ed5-e6beae3bb5b7" />

    - 프로세스는 사용자영역에서 크게 4가지 영역으로 나뉜다.
      1. 코드영역(텍스트 영역)
        - 실행가능한 코드 : 기계어로 이루어진 명령어들이 저장되어 있는 곳
        - Read-only
          - CPU는 기계어로 이루어진 명령어를 해석해서 실행한다.그때 어떤 프로세스가 기계어로 이루어진 명령어가 바로 코드영역에 적재되어 있는것이다.
          - CPU입장에서는 정해진 프로세스를 그대로 읽어서 실행하면 된다. 그래서 Read-only영역으로 지정되어 있다.
      2. 데이터영역
        - 프로그램이 실행되는 동안 유지할 데이터(ex.전역변수)
        - BSS영역 : 프로그램 실행 동안 유지할 데이터 중 초기값 없는 데이터를 BSS영역이라 하는데 이걸 BSS에 넣고 초기값 있는 데이터는 데이터영역에 넣는다라고 구분해서 서술하기도 한다.

        ```C
        $ cat hello.c
        #include <stdio.h>

        int main()
        {
          printf("hello world\n");
          return 0;
        }
        $ gcc -o hello hello.c
        $ size hello
        ```
          - text,data,bss,10진수,16진수,filename등이 크기즉 size로 얼마나 차지하고 있는지를 나타낸다.

        ```shell
        // resource monitoring할때 많이 이용한다.
        $ top > f 를 누르면 표시할거 지정하여 조회할수 있다.
        ```
      3. 힙영역
        - 사용자(개발자)가 직접 할당 가능한 공간
        - 메모리 영역을 할당 했다면 해제하자(직접 해제하기, 자동으로 해제하기(가비지컬렉션))
          - 메모리누수 : 메모리영역을 할당했다가 해제 안했을때 발생할수있는 이슈를 메모리누수라고 한다.
      4. 스택영역
      
  <img width="462" alt="Image" src="https://github.com/user-attachments/assets/2c0200cb-8a56-4cab-8407-7fa3935edee8" />

        - 임시로 저장되는 여역(Ex.매개변수, 지역변수)
        - 힙영역은 낮은 주소에서 높은 주소로 할당
        - 스택영역은 높은 주소에서 낮은 주소로 할당(주소중복방지)

        - 코드영역과 데이터영역은 크기가 변하지 않는다. 그래서 정적할당영역이라고 한다. 

### 2-2. 프로세스 상태

<img width="455" alt="Image" src="https://github.com/user-attachments/assets/3317d569-bd55-4196-b020-85e0e44e6042" />

1. 생성상태(new) : 이제 막 할당받아서 생성된 상태
2. 준비상태(ready) : 지금당장이라도 CPU자원을 할당받아서 실행될수 있지만 아직 내차례가 오지 안아서 실행이 안되고 있는 상태, 즉 지금 바로 실행할수 있는 상태 
3. 실행상태(running) : CPU자원을 할당받아서 실행중인 상태
4. 대기상태(blocked) : 주로 입출력장치를 요청했을때 대기상태이다. 즉, 지금 바로 실행할수 없는 상태이다. = 어떤 이벤트를 기다리고 있는 상태
5. 종료상태(terminated)

리눅스 프로세스(task) 상태 확인
```
$ top 에서 S라고 표시되어 있는곳.
```
  1. R : Running, 실행상태
  2. S : Sleeping, 대기상태
  3. W : Waiting, 준비상태
  4. S : Stopped, 종료상태
  5. Z : Zombie, 프로세스 종료 후 자원이 반환되었지만 커널 영역에 프로세스가 남아있는 상태

프로세스가 어떻게 관리되는지 살펴보자.
  프로세스의 계층적 구조로 관리된다.
    <img width="347" alt="Image" src="https://github.com/user-attachments/assets/a8b03ce6-b757-422d-a498-c1d224ffb1d9" />

  <img width="356" alt="Image" src="https://github.com/user-attachments/assets/cb22b31f-8b91-42a4-b89b-adcb5ff4ce8d" />

```shell
# 계층적구조 확인 명령어
$ pstree
```

프로세스가 계층적구조로 관리될수 있는 원리
  - fork - exec (모두 시스템콜일종이다)

  <img width="604" alt="Image" src="https://github.com/user-attachments/assets/90a7d973-6e75-49af-ba3c-b4e83fef46a9" />
  
    - 계층적 구조로 프로세스가 생성되는 원리
    - fork : 자신의 복사본 만드는 시스템콜
      - 동일한 코드,데이터로 이루어진 새로운 프로세스(PID값이 다르다)가 자식프로세스로서 생성되는것.
    - exec : 새로운 코드로 대체(덮어쓰기)하는 시스템콜
      - PID값은 유지가 된체 새로운 데이터,코드영역이 생성되는것.
    - 쉽게 복사하고(fork)-옷갈아입기(exec)라고 생각하면 쉽다.

  - ex) bash라는 프로그램이 생성되었다.
    - fork : fork가 호출되면 자식bash가 생성된다. 그리고 새로운 메모리 영역할당이 된다. 별개의 PID값을 가지게 된다.
    - exec : exec가 호출해서 ls라는 프로그램으로 자기자신을 덮어쓰기 한다면, 즉, bash process의 자식process로서 ls프로그램이 실행되게 된다. 

### 2-3. 스레드

프로세스를 구성하는 실행 흐름의 단위(프로그램단위의 스레드이다)



<img width="457" alt="Image" src="https://github.com/user-attachments/assets/4cdf3f24-b2ad-4c26-9079-9c4e367cd621" />

- 현재메모리에 웹브라우저, 게임, 워드프로세스가 1개씩 적재되어 있다고 가정해보자.
- 만약 여기서 웹브라우저 프로세스의 실행흐름을 하나더 추가한다면, 웹브라우저 프로세스는 한번에 2개의 코드영역을 동시에 실행할수 있을것이다.
- 즉 실행흐름이 여러개일수록 동시에 실행할수 있을것이다. 이 실행흐름이 스레드이다.

스레드의 구성 요소
  - 각기 다른 스레드ID, 프로그램 카운터, 레지스터, 스택

<img width="386" alt="Image" src="https://github.com/user-attachments/assets/fd59dbea-c7fc-4cef-bcea-2f26c4bc048b" />

  - 각각의 스레드가 각각의 프로그램 카운터, 레지스터, 스택, 등을 갖고있다.
  - 즉, 각각의 프로그램 카운터는 다음 실행할 주소를 갖고 있는데 각기 다른 주소를 갖고있는단 소리다. 그래서 각기 다른 코드를 실행할수 있게 된다.
  - 스레드마다 각기 다른 스택을 갖고있다면 각 스레드마다 임시로 저장할수 있는 공간도 확보할수 있다.

참고로 linux에서는 프로세스와 스레드를 구분하진 않는다.

**멀티프로세스와 멀티스레드 차이점**
  - 세개의 별도 프로세스 vs 스레드 세개
  <img width="371" alt="Image" src="https://github.com/user-attachments/assets/6947721b-a648-4c95-ac1b-0f7f23d2f081" />

    - 멀티프로세스 : 동일한 작업을 수행하는 별도의 프로세스 실행하는 것, hello.os 출력프로세스를 fork x 3번 한것이다.
    - 멀티스레드 : 하나의 프로세스 내에 각기 다른 실행흐름을 갖는 여러가지 스레드를 만드는것

    가장 주된 차이점은 **자원 공유 여부**
      - 프로세스 간에는 **기본적으로** 자원을 공유하지 않음
      - 스레드 간에는 프로세스의 자원을 공유 

      <img width="452" alt="Image" src="https://github.com/user-attachments/assets/a383e916-82ce-4dcc-be3d-8399ab8fd218" />

        - 예를들어 같은작업을 수행하는 별도의 프로세스 2개가 있다고 해보자. 그러므로 PCB도 별도로 있을것이고,PID도 다를것이다.
        - 이렇게 각각의 프로세스를 실행할때 자원을 필요로 할것이다.  이렇게 각각의 프로세스는 각기 다른 자원을 사용한다.

        <img width="406" alt="Image" src="https://github.com/user-attachments/assets/3c44b496-c410-483a-a179-0bc5fcbab437" />

          - 스레드는 같은 프로세스를 구성하는 실행흐름의 단위이므로 프로세스를 구성하는 자원을 공유한다.
          - 그래서 스레드가 공유하는 자원에서 문제발생시, 모든 스레드가 모두 문제가 생길수 있다.

이것의 문제점을 가장 잘 보여주는 예시가 `웹브라우저의 탭` 이다.
각각의 탭을 별도의 프로세스로 만든 브라우저는 하나의 탭에서 문제가 생겨서 강제종료시 해당 탭만 문제가 생긴다.
그러나 각각의 스레드로 만든 브라우저는 하나의 탭이 문제생기면 브라우저 자체가 문제가 생겨서 강제종료가 된다.

멀티 프로세스는 자원을 공유하지 않기 때문에 메모리 소요가 크다!

그러나 프로세스끼리도 자원을 공유할수는 있다.
<img width="208" alt="Image" src="https://github.com/user-attachments/assets/ecf46fe6-7d42-468c-89a4-4ef05f84025a" />
  - 프로세스간 통신 (IPC, Inter-Process Communication) 을 사용해서 프로세스끼리 자원 공유가능.
    - 공유 메모리를 통한 통신
    - 파이프를 통한 통신
    - 네트워크 소켓을 통한 통신
 

프로세스 다루기!!

프로세스 실행 코드
```C
// C:\Users\jspar\Downloads\persornal\study\250305-230502_[패캠] 현실 세상의 컴퓨터공학 지식 with 30가지 실무 시나리오 초격차 패키지 Online\자료\computer-science-main\운영체제\mulp1.c
#include <stdio.h>
#include <unistd.h>

int main()
{
   printf("hello, os\n");
   printf("my pid is %d", getpid());
   return 0;
}

$ gcc -o mulp1 mulp1.c
$ ./mulp1 //실행할때마다 PID값이 다르게 나온다.

```

자식프로세스를 만드는 코드
  - 자식프로세스인 경우 fork 호출반환값이 0이 된다.
```C
// C:\Users\jspar\Downloads\persornal\study\250305-230502_[패캠] 현실 세상의 컴퓨터공학 지식 with 30가지 실무 시나리오 초격차 패키지 Online\자료\computer-science-main\운영체제\mulp2.c
#include <stdio.h>
#include <unistd.h>

int main()
{
   printf("parent pid is %d\n", getpid());

   if (fork() == 0) {
       printf("child pid is %d\n", getpid());
   }

   return 0;
}

$ gcc -o mulp2 mulp2.c
$ ./mulp2 //부모프로세스와 자식프로세스의 PID값이 다르게 나옴을 확인 가능

```



```C
// C:\Users\jspar\Downloads\persornal\study\250305-230502_[패캠] 현실 세상의 컴퓨터공학 지식 with 30가지 실무 시나리오 초격차 패키지 Online\자료\computer-science-main\운영체제\mulp3.c
#include <stdio.h>
#include <unistd.h>

int main()
{
   printf("parent pid is %d\n", getpid());

   if (fork() == 0) {
       printf("child pid is %d\n", getpid());
   }

   printf("executed!\n");

   return 0;
}
$ gcc -o mulp3 mulp3.c
$ ./mulp3 //executed는 2번실행될것이다. 왜냐하면 부모,자식프로세스 모두 실행시키니깐.

```


```C
// C:\Users\jspar\Downloads\persornal\study\250305-230502_[패캠] 현실 세상의 컴퓨터공학 지식 with 30가지 실무 시나리오 초격차 패키지 Online\자료\computer-science-main\운영체제\mulp4.c

#include <stdio.h>
#include <unistd.h>

void foo() {
   printf("execute foo\n");
}

int main()
{
   if (fork() == 0) {
    // 여기밑에는 자식프로세스가 실행함
      if (fork() == 0) {
        // 자식프로세스 밑의 자식프로세스가 실행함
         printf("child of child pid is %d\n", getpid());
         foo();
      }
      else {
         printf("child pid is %d\n", getpid());
         foo();
      }
   }
   else {
    // 여기는 부모프로세스가 실행함  
      if(fork() == 0) {
        // 부모프로세스가 만든 자식프로세스가 실행함
         printf("child pid is %d\n", getpid());
         foo();
      }
      else {
        // 부모프로세스가 실행함.
         printf("parent pid is %d\n", getpid());
         foo();
      }
   }

   return 0;
}
$ gcc -o mulp4 mulp4.c
$ ./mulp4  // PID값이 모두 다 다르게 나온다.
```


스레드 다루기
```C
// C:\Users\jspar\Downloads\persornal\study\250305-230502_[패캠] 현실 세상의 컴퓨터공학 지식 with 30가지 실무 시나리오 초격차 패키지 Online\자료\computer-science-main\운영체제\mult1.c

#include <stdio.h>
#include <unistd.h>
#include <pthread.h>

void *foo() {
   printf("process id is %d\n", getpid());
   return NULL;
}

int main() {
   pthread_t thread1;
   pthread_create(&thread1, NULL, foo, NULL); // C언어에서 thread를 만드는 함수. 여기서 thread1이란 스레드를 만들것이고, 이 스레드가 실행할 대상은 foo를 선언할것이다.
   pthread_join(thread1, NULL); // 스레드가 끝나고 해당 자원을 처리하고 종료하는 코드

   return 0;
}

$ gcc -pthread -o mult1 mult1.c // pthread.h를 library로 받을때는 -pthread명령어가 들어가줘야 한다.
$ ./mult1
```

```C
// C:\Users\jspar\Downloads\persornal\study\250305-230502_[패캠] 현실 세상의 컴퓨터공학 지식 with 30가지 실무 시나리오 초격차 패키지 Online\자료\computer-science-main\운영체제\mult2.c
#include <stdio.h>
#include <unistd.h>
#include <pthread.h>

void *foo() {
   long thread_id = (long int)pthread_self();
   printf("process id is %d\n", getpid());
   printf("this is thread %ld\n", thread_id);
   return NULL;
}

int main() {
   pthread_t thread1;
   pthread_create(&thread1, NULL, foo, NULL);
   pthread_join(thread1, NULL);

   return 0;
}

$ man pthread_self
$ gcc -pthread -o mult2 mult2.c 
$ ./mult2
```



```C
// C:\Users\jspar\Downloads\persornal\study\250305-230502_[패캠] 현실 세상의 컴퓨터공학 지식 with 30가지 실무 시나리오 초격차 패키지 Online\자료\computer-science-main\운영체제\mult3.c
#include <stdio.h>
#include <unistd.h>
#include <pthread.h>

void *foo() {
   long thread_id = (long int)pthread_self();
   printf("process id is %d\n", getpid());
   printf("this is thread %ld\n", thread_id);
   return NULL;
}

int main() {
   pthread_t thread1;
   pthread_t thread2;
   pthread_t thread3;

   pthread_create(&thread1, NULL, foo, NULL);
   pthread_create(&thread2, NULL, foo, NULL);
   pthread_create(&thread3, NULL, foo, NULL);

   pthread_join(thread1, NULL);
   pthread_join(thread2, NULL);
   pthread_join(thread3, NULL);

   return 0;
}

//스레드 3개 만든거.
$ gcc -pthread -o mult3 mult3.c 
$ ./mult3 // PID값은 모두 동일하고, thread 값은 모두 다르다.
```


## 3. CPU 스케줄링
프로세스에 CPU자원을 할당하는 방법 학습하기

모든 프로세스 및 스레드는 실행되기 위해 **자원**을 필요로 한다.

스케줄링?  운영체제가 공정하고 합리적으로 **자원(여기선 CPU라고 하자)** 를 배분하는 방법

CPU자원은 한정되어 있고 실행중인 프로세스는 여러 개 => 여러 프로세스들이 CPU를 나눠 사용하는 방법은?
  - 정해진 시간 동안 돌아가면서 CPU를 사용하는 것이 가장 좋지 않을까? NO!! 프로세스마다 우선순위가 다르다(우선순위는 PCB에 명시되어 있음). 그러므로 우선순위에 따라 자원을 할당하는게 가장 합리적이다.

```shell
$ ps -el
$ top
```
  - PRI, NI : 낮을수록 높은 우선순위
    - PRI : 운영체제가 바라보는 우선순위
    - NI : 사용자가 조정가능한 우선순위
      ```shell
      $ nice
      ```


우선순위의 차이를 보이는 대표적인 프로세스 유형
  - 일부 백그라운드 프로세스 : 사용자활용이 적기 때문.
  - I/O bound process : 입출력장치를 이용하는 시간이 많은 프로세스, I/O burst가 많은 프로세스
  - CPU bound process : 입출력장치보다 CPU를 이용하는 시간이 많은 프로세스, CPU burst가 많은 프로세스 (ex.컴파일작업)
  - I/O bound 가 CPU bound보다 일반적으로 우선순위는 높다.

  <img width="625" alt="Image" src="https://github.com/user-attachments/assets/bff5b0fb-c185-4eba-8160-06b1e3535193" />

    - 일반적으로 어떠한 프로세스가 실행되는 과정은 CPU사용후, I/O(입출력)사용하는 순으로 반복된다.
    - Ex) 워드프로세스가 있다면, 사용자로부터 입력값을 받아들이고, 화면에 출력하고, 또 입력값 받아들이고 화면에 출력하는 순으로 반복된다.
    - CPU사용하는 구간 = CPU burst라고 한다.
    - 입출력 장치 사용하는 구간 = I/O burst라고 한다.
    - 왜 I/O bound process가 CPU bound process보다 우선순위가 높을까?
      - 입출력장치를 사용하는 프로세스같은 경우엔 조금만 실행해도 곧바로 대기상태에 접어든다. 굳이 실행을 연기할필요가 없다.  즉, 빨리 실행시키고 대기상태로 보내면 한동안 볼일이 없다. 왜냐하면 입출력장치는 CPU보다 연산속도가 일반적으로 느리기 때문이다.

프로세스 우선순위를 토대로 CPU할당 받는 방법 = CPU스케줄링 알고리즘

### 3-1. 스케줄링 큐(=line,줄 이라고 생각해라)

자원은 한정되어 있고 실행 중인 프로세스는 여러 개 존재한다. 이러한 상태에서 프로세스들의 요구사항을 일목요연하게 관리하는 방법이 스케줄링 큐이다.

<img width="302" alt="Image" src="https://github.com/user-attachments/assets/acdb6bdf-30f4-4b5e-9766-27fac663f8b6" />
  - 만약 CPU 쓰고 싶은 프로세스가 있다면 거기에 자신의 PCB를 스케줄링 큐에 삽입하면 우선순위에 맞게 운영체제가 스케줄링을 보고 CPU를 할당해준다.

스케줄링 큐의 종류
1. 준비 큐 : CPU이용을 기다리는 프로세스들의 큐
2. 대기 큐 : 대기 상태 프로세스들의 큐 (입출력 요청)

<img width="461" alt="Image" src="https://github.com/user-attachments/assets/be614156-7f98-44f6-a8b8-305036d20be7" />

  - 실행을 하다가, 자신에게 할당된 시간이 끝나면 (타이머 인터럽트 or 타임아웃 발생) 해당 프로세스는 준비큐에 삽입되고 준비상태가 된다.
  - 만약 실행중에 입출력문을 받게되어서 입출력작업이 완료될때까지 기다려야 한다면 대기큐에 삽입되어 대기상태가 된다. 대기상태 있다가 입출력완료되면 다시 준비큐로 삽입된다.

<img width="632" alt="Image" src="https://github.com/user-attachments/assets/f6816e15-6da6-4173-b89a-cbb8ff0e229c" />

  - 입출력장치가 여러개이듯, 대기상태도 여러개 존재한다.

우선순위 낮은 프로세스가 먼저 큐에 삽입되었어도 우선순위 높은 프로세스가 먼저 처리될수 있다.

스케줄링 큐까지 반영한 프로세스 상태 다이어그램

  <img width="533" alt="Image" src="https://github.com/user-attachments/assets/811029f6-8f25-46bf-8fc0-26a1d5906e46" />

    - 생성상태에서 PCB를 할당받아서 실행이 되면, 당장실행할수 없는, 내차례를 기다려야 하는 준비상태가 된다. 이는 준비큐에 삽입이 된다. CPU에 할당받아서 실행되는 즉, 디스패치 되면 실행상태가 되고 실행이 진행된다. 이게 끝나서 타이머 인터럽트나 타임아웃이 발생하면 해당 프로세스는 준비상태로 접어들고, 만약 그 중간에 입출력 요청이 들어왔다면 대기큐에 삽입되어서 대기상태가 된다.

선점형 스케줄링과 비선점형 스케줄링
  
  - 한 프로세스 실행 도중 다른 급한 프로세스가 실행되어야 한다면?

  <img width="533" alt="Image" src="https://github.com/user-attachments/assets/a5c1321e-ce0f-4905-91c9-b4b65e01e575" />

    1. 현재 실행중인 프로세스의 **자원을 빼앗아** 해당 프로세스에게 할당 = 선점형 스케줄링(타임아웃 기반 문맥교환)
      - 프로세스에 자원을 고루 할당 가능 (장점)
      - 문맥 교환 과정의 오버헤드 발생 (단점)
    2. 현재 실행중인 프로세스 실행이 끝날 때까지 해당 프로세스 대기 = 비선점형 스케줄링
      - 문맥 교환 과정에서의 오버헤드 적음 (장점)
      - 고르지 않은 자원 분배 (단점)


큐(Queue)
  
  <img width="277" alt="Image" src="https://github.com/user-attachments/assets/3c47558b-206c-4e94-8651-22d8a015b528" />

  - 자료구조 측면에서 큐는 먼저 삽입된게 먼저 나오는 FIFO 구조형태의 자료구조이다.
  - 운영체제에서의 스케줄링 큐는 이러한 형태는 아니다.

### 3-2. CPU 스케줄링 알고리즘

1. 선입 선처리 스케줄링(FIFO 스케줄링)
  - CPU를 먼저 요청한 프로세스부터 CPU할당
  - 준비 큐에 삽입된 순서대로 실행되는 비선점형 스케줄링

  <img width="332" alt="Image" src="https://github.com/user-attachments/assets/d4c79d59-8b8f-4493-bebf-8c8004bf7ac2" />

    - 부작용 : 호위효과(convoy effect), 실행시간이 큰 프로세스 때문에 뒤에 있는 짧은 프로세스의 대기시간이 길어지는효과를 말한다.

2. 최단 작업 우선 스케줄링(SJF 스케줄링)
  - 준비 큐 프로세스 중 CPU 이용 시간이 짧은 프로세스부터 실행
  - 호위효과 방지

3. 라운드 로빈 스케줄링(Round Robin 스케줄링)
  - 선입 선처리 스케줄링 + 타임 슬라이스(정해진 시간만큼만 실행)
  - 준비 큐에 삽입된 순서로 실행하되, 타임 슬라이스만큼 실행
  - 선점형 스케줄링

  <img width="215" alt="Image" src="https://github.com/user-attachments/assets/72c68051-af13-40b5-bf66-d4346db45411" />

4. 최소 잔여 시간 우선 스케줄링(SRT 스케줄링)
  - 최단 작업 우선 스케줄링 + 라운드 로빈 스케줄링
  - 작업 시간 짧은 프로세스부터 처리하되, 타임 슬라이스만큼 돌아가며.

5. 우선순위 스케줄링
  - 프로세스마다 우선순위 부여, 우선순위 높은 순으로 스케줄링
  - 최단 작업 우선 스케줄링 : 작업 시간 짧은 순으로 우선순위 부여
  - 최소 잔여 시간 스케줄링 : 남은 시간 짧은 순으로 우선순위 부여

  - **아사(starvation)현상**
    - 모든 우선순위 스케줄링 알고리즘의 근본적인 문제
    - 우선순위 낮은 프로세스의 실행이 계속 연기되는 현상
    - 우선순위 높은 프로세스 실행하느라 우선순위 낮은 프로세스 실행을 못한다.
    - solution : aging(에이징)
      - 대기 시간이 길어지면 점차 우선순위를 높이는 방식

6. 다단계 큐 스케줄링
  - 우선순위별로 준비 큐를 여러 개 사용하는 스케줄링
    - 우선순위가 높은 프로세스 처리
    - 다음으로 우선순위 높은 프로세스 처리
    - 다음으로 우선순위 높은 프로세스 처리

  <img width="293" alt="Image" src="https://github.com/user-attachments/assets/6a8b9c27-32ca-484b-b521-66ce96dd5c60" />

    - 빨리 실행할 것들은 우선순위0에 두고 그다음은 우선순위 1에 두는 방식
    - 장점
      - 프로세스 유형별로 큐 구분 가능
        - ex) CPU바운드, I/O바운드, 백그라운드, 포그라운드, 실시간 프로세스 등
      - 큐 별로 다른 스케줄링 알고리즘 적용 가능
        - ex) 선입 선처리 큐, 라운드 로빈 큐...
      - 큐 별로 다른 타임 슬라이스 적용 가능
    - 단점
      - 기본적으로 프로세스는 큐 간의 이동 불가능. 즉, 우선순위0에 들어간건 우선순위1로 이동못한다.
      - 아사현상 발생

7. 다단계 피드백 큐 스케줄링 
  - 프로세스가 큐 간의 이동 가능
  - 높은 우선순위 큐에 삽입, 실행이 끝나지 않을 경우 낮은 우선순위 큐에 삽입
  - 에이징 적용
  - CPU bound, I/O bound 프로세스 구분 가능
  <img width="311" alt="Image" src="https://github.com/user-attachments/assets/f23cbbfd-a570-4851-a433-8f4f0126a3bf" />

### 3-3. 리눅스의 스케줄링 정책

1. 실시간 정책 스케줄링 (우선순위 높음)
  : deadline이 정해져 있는 스케줄링이다.
  - SCHED_FIFO
  - SCHED_RR

2. 일반 정책 스케줄링 (우선순위 낮음)
  - SCHED_OTHER/SCHED_NORMAL
  - SCHED_BATCH
  - SCHED_IDLE

![Image](https://github.com/user-attachments/assets/959425a5-034d-489f-8bde-0be080000764)


(https://web.git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/include/uapi/linux/sched.h?h=v6.5-rc3#n112)

CFS(Completely Fair Scheduler) : 비실시간 프로세스를 대상으로 하는 스케줄링 방식(linux kernel 2.6.23~ )
- 현재 사용하는 스케줄링방식식
1. vruntime (virtual runtime, 가상 실행시간)
  - 프로세스가 그 동안 실행한 시간을 정규화한 정보
  - vruntime이 작은 프로세스를 다음 실행할 프로세스로 삼음
  - (vruntime 별 태스크를 고르는 과정에서 RB tree 사용)
  
  ```shell
  $ pgrep bash  // bash라는 process의 PID값을 확인할수 있다.
  $ cat /proc/[PID]/sched
  ```
2. 타임 슬라이스 
  - nice값에 비례해 가중치 할당, 가중치를 바탕으로 타임 슬라이스 할당
  - 즉, nice값을 토대로 타임슬라이스값이 할당됨.

> nice : 사용자 영역에서 설정한 프로세스 우선순위 <br>
- 사용자 영역에서의 값은 -20 ~19
- 커널 영역에서의 값은 0 ~ 139
  - 실시간 스케줄링되는 프로세스 : 0 ~ 99 ( 해당값이 작을수록 우선순위가 높은거다!)
  - CFS프로세스 : 100 ~ 139

nice명령어
  - 새 프로세스를 실행할 때 해당 프로세스의 우선순위 부여
  - 기본적으로 설정된 nice값은 0

```shell
$ nice -n [우선순위] [program]]
$ nice -n 19 uptime
```

renice 명령어
  - 이미 실행 중인 프로세스의 우선순위 부여

```shell
$ renice [우선순위] [PID]
$ renice +5 1234
```


## 4. 동기화와 교착 상채
멀티프로세스/멀티스레드 환경에서 문제 해결하기

프로세스는 여러 프로세스가 동시다발적으로 진행되고 자원은 한정되어 있기 때문에, 운영체제는 효율적으로 배분해줘야 한다.

동시다발적으로 실행되는 프로세스(&스레드)는 실행순서와 자원의 일관성을 보장해야 한다.

**운영체제가 제공하는 동기화의 의미**
  1. 실행순서제어 : 프로세스를 올바른 순서로 실행하기
    - ex) 동시에 실행되는 프로세스 2개가 있다면?
      - 가) book.txt가 없다면 파일을 만들고 값을 쓰고 저장하는 프로세스
      - 나) book.txt를 읽어들이는 프로세스
      - 위 2개의 프로세스를 동시다발적으로 실행해야 한다.
      - 위 경우는 반드시 가->나 순으로 진행되야 한다.
      - 나는 조건문이기에 무조건 뒤에 진행되야 한다.  즉, 이것이 실행순서제어를 통한 동기화이다.

  2. 상호배제(mutual exclusion) : 동시에 접근해서는 안되는 자원에 하나만 접근하기

공유자원과 임계구역
  - 공유자원 : 공동의 자원(ex.파일, 전역변수, 입출력장치 등)
  - **임계구역(critical section)** : 동시에 접근하면 문제가 발생할 수 있는 공유 자원에 접근하는 코드(일관성을 지켜야 되는 코드)

![system_os_공유자원.png](/assets/images/system_os_공유자원.png)

> 레이스 컨디션(race condition) <br>
: 임계 구역을 동시에 실행하여 자원의 일관성이 깨지는 현상

정리) 동기화는 크게 2가지를 의미한다. 첫번째는 실행의 순서가 있을때 실행의 순서를 지키면서 실행하는것. 두번째는 자원의 일관성이 깨질수 있는 공유자원에 접근할수 있는 임계구역에 여러개의 프로세스가 한번에 접근하는 문제를 발생시키지 않는것. 즉, 레이스컨디션을 방지하면서 상호배제를 하면서 동기화를 하는것.

동기화가 이루어지지 않았을경우 발생할수 있는 문제를 보여주는 고전적 문제가
  - producer : 생산을 하는 프로세스(혹은 스레드)
  - consumer : 소비를 하는 프로세스(혹은 스레드)

```c
// C:\Users\jspar\Downloads\persornal\[study]\250305-230502_[패캠] 현실 세상의 컴퓨터공학 지식 with 30가지 실무 시나리오 초격차 패키지 Online\자료\computer-science-main\운영체제\producerconsumer.c 
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>

void* produce(void* arg);
void* consume(void* arg);

int sum = 0;

int main() {
    printf("초기 합계: %d\n", sum);

    pthread_t producer_thread, consumer_thread;
    pthread_create(&producer_thread, NULL, produce, NULL);
    pthread_create(&consumer_thread, NULL, consume, NULL);

    pthread_join(producer_thread, NULL);
    pthread_join(consumer_thread, NULL);

    printf("실행 이후 합계: %d\n", sum);

    return 0;
}

void* produce(void* arg) {
    for (int i = 0; i < 100000; i++) {
        sum++;
    }
}

void* consume(void* arg) {
    for (int i = 0; i < 100000; i++) {
        sum--;
    }
}

// produce와 consume을 동시에 실행시켜서 sum의 값을 확인해보자.
// 생각하기에 sum이 10만으로 증가하고 다시 sum이 10만에서 0으로 감소할것이기에
// sum=0 이 나올것으로 생각된다.
// 그러나 각각의 프로세스는 동기화 안해줬기에 예상치 못한 결과가 나온다.
$ gcc -pthread -o producerconsumer producerconsumer.c
$ ./producerconsumer
// 실행때마다 sum값이 변동한다.
// 이유는 각각의 스레드가 동기화되지 않았기 때문이다.
```

```java
// ProducerConsumer.java
public class ProducerConsumer {

    private static int sum = 0;

    public static void main(String[] args) {
        System.out.println("초기 합계: " + sum);

        Thread producerThread = new Thread(new Producer());
        Thread consumerThread = new Thread(new Consumer());

        producerThread.start();
        consumerThread.start();

        try {
            producerThread.join();
            consumerThread.join();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        System.out.println("실행 이후 합계: " + sum);
    }

    static class Producer implements Runnable {
        @Override
        public void run() {
            for (int i = 0; i < 100000; i++) {
                sum++;
            }
        }
    }

    static class Consumer implements Runnable {
        @Override
        public void run() {
            for (int i = 0; i < 100000; i++) {
                sum--;
            }
        }
    }
}

$ javac ProducerConsumer.java //해당파일 컴파일
$ java ProducerConsumer //실행
// 동일하게 이상한값이 나온다.
// 즉 프로세스 & 스레드의 동기화는 프로그램언어에 국한된게 아니라 멀티프로세스,멀티스레드를 작성할때는 반드시 고려해야할 대상이다!
```

### 4-1. 동기화 해결의 세가지 원칙
1. 상호배제 : 한 프로세스가 임계 구역에 진입했다면 다른 프로세스는 대기해야 함
2. 진행 : 어떤 프로세스도 임계 구역에 진입하지 않았다면 진입이 가능해야 함
3. 유한대기 : 한 프로세스가 임계 구역 진입을 위해 대기하고 있다면 언젠간 진입이 가능해야 함

이러면서 위 세가지 원칙을 지키면서 동기화를 해주는 툴은?
1. 뮤렉스 락 : 상호 배제를 위한 동기화 도구  
  
[뮤렉스 락 cpp reference](https://en.cppreference.com/w/cpp/thread/mutex)
[뮤렉스 락 python reference](https://docs.python.org/3/library/asyncio-sync.html#asyncio.Lock)

  - 한마디로 자물쇠(lock)
  - (뮤렉스 락락 구현)
    - 자물쇠 역할 : 프로세스들이 공유하는 전역변수 lock
    - 자물쇠 잠그기 : acquire 함수, 임계구역 진입 전에 설정필요.
    - 자물쇠 열기 : release 함수

  ```
  acquire() {
    while (lock == true)    /* 만약 임계 구역이 잠겨있다면 */
        ;                   /* 임계구역이 잠겨있는지를 반복적으로 확인 */
    lock = true             /* 만약 임계 구역이 잠겨있지 않다면 임계구역 잠금, 어딘가에서 lcok=false의 명령어가 들어왔다면, */
  }

  release() {
    lock = flase;           /* 임계구역 작업이 끝났으니 잠금 해제 */
  }
  ```

    - 임계구역 진입 전에 acquire함수 호출해서 lock 이 되어있는지 아닌지를 확인 후(만약 다른 스레드가 작업중이면 lock이 true였을것이다), 임계구역을 나갔다면 release를 호출하도록 한다.  
    - **busy waiting** : 계속 임계구역이 잠겨있는지를 확인하는작업

2. 세마포 : 상호배제 & 실행 순서 제어를 위한 동기화 도구(Ex.철도신호기)

[세마포 cpp reference](https://en.cppreference.com/w/cpp/thread/counting_semaphore)
[세마포 python reference]()

  - 카운팅 세마포 / 바이너리 세마포 2가지 종류가 있다.
  - 뮤텍스 락은 기본적으로 공유 자원이 하나일 경우 상징
  - 세마포는 공유 자원이 여러 개 있을 경우도 동기화 가능
> 동기화 ? 실행 순서 제어, 상호 배제 동기화

  - 가라는 신호를 받으면(임계구역에) 진입해도 좋다
  - 멈추라는 신호를 받으면(임계 구역에) 진입해서는 안된다

  - 세마포는 프로세스 상태 전이 활용한다.
  
  - (세마포 구현)
    - 변수 S : 임계 구역에 진입할 수 있는 프로세스의 개수(사용 가능한 공유 자원의 개수)
    - wait함수 : 임계구역에 들어가도 좋은지, 기다려야 할지를 알려주는 함수
    - signal함수 : 임계구역 앞에서 기다리는 프로세스에게 '이제 가도 좋다' 라고 신호를 주는 함수
      ```
      wait()
      //임계구역
      signal()

      wait () {
        while (S <= 0)  /* 만일 임계구역에 진입할 수 있는 프로세스가 개수가 0이하라면 */
      ;                 /* 사용할 수 있는 자원이 있는지 반복적으로 확인 */
        S --;           /* 임계구역에 진입할 수 있는 프로세스가 개수가 하나 이상이면 S를 1 감소시키고 임계구역 진입 */
      }

      signal () {
        S++             /* 임계구역에서의 작업을 마친 뒤 S 1 증가 */
      }
      ```


### 4-2. 조건변수와 모니터

기존 동기화 도구의 문제점

  ![system_os_기존동기화_도구의_문제점.png](/assets/images/system_os_기존동기화_도구의_문제점.png)

사용이 간편한 동기화 도구, 모니터

  - 공유 자원에 접근하기 위한 인터페이스를 따로 둔다. 
  - 인터페이스를 통해서만 접근(상호 배제)
  - 실행 순서 제어를 위한 동기화를 위해 조건 변수(conditional variable) 사용
    - 프로세스 상태 전이가 가능한 특별한 변수가 있어 이를 이용한다.
      - wait() : 호출한 프로세스를 대기상태로 전환
      - signal() : 호출한 프로세스를 깨움

  ![system_os_기존동기화_도구의_문제점_해결.png](/assets/images/system_os_기존동기화_도구의_문제점_해결.png)

    - 공유자원에 접근하고자 하는 프로세스가 여러개있을때 반드시 정해진 인터페이스 통해서만 공유자원 접근가능함.

  [조건변수와 모니터 python refference](https://docs.python.org/3/library/threading.html#condition-objects)

  - 모니터는 조건 변수를 활용한 실행 순서 제어 가능
    1. 아직 실행될 조건이 되지 않았을 때에는 wait을 통해 실행 중단
    2. 실행될 조건이 충족되었을 때에는 signal을 통해 실행 재개

    ![system_os_실행순서제어.png](/assets/images/system_os_실행순서제어.png)

      - 어떤 프로세스가 자기가 실행될 차례가 됬는데 아직이라 판단되서 x.wait() 을 호출한 상황이다. 
      - 즉, book.txt읽는 프로세스인데 아직 book.txt가 없다. 그래서 조건변수 x에 대한 큐에 삽입이 되서
      - 대기상태로 접어 든 상태이다. 이게 대기상태가 되면 모니터안에는 비게 된다. 즉, 다른 프로세스가 모니터에 접근해서 공유자원 사용가능해짐.
      - 다음 프로세스가 그래서 접근하여 완료후, x.signal() 을 호출해서 그 다음 프로세스를 실행하도록 함.
      - 즉, x.signal()이 인터페이스에서 실행되어야 큐의 프로세스가 실행이 되는 구조가 된다.

모니터를 활용하는 대표적인 프로그래밍 언어: java
  - [synchronized 키워드](https://docs.oracle.com/javase/tutorial/essential/concurrency/locksync.html)

  ```java
  public void addName(String name) {
    synchronized(this) {
      lastName = name;
      nameCount++;
    }
    nameList.add(name);
  }
  ```

(실습)
기존생산자-소비자문제 : 동기화적용하기

뮤텍스락 활용예제
```c
// mutexexample.c
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>

void* produce(void* arg);
void* consume(void* arg);

int sum = 0;            // 공유할 변수이다.
pthread_mutex_t mutex;  // mutex객체 선언
                        // mutex객체에 대해 lock, unlock할수 있음.

int main() {
    printf("초기 합계: %d\n", sum);

    pthread_t producer_thread, consumer_thread;
    pthread_mutex_init(&mutex, NULL);   // mutex객체 초기화

    pthread_create(&producer_thread, NULL, produce, NULL);
    pthread_create(&consumer_thread, NULL, consume, NULL);

    pthread_join(producer_thread, NULL);
    pthread_join(consumer_thread, NULL);
    pthread_mutex_destroy(&mutex);    // mutex객체 사라지게 해줘야함.

    printf("실행 이후 합계: %d\n", sum);
    return 0;
}

void* produce(void* arg) {
    for (int i = 0; i < 100000; i++) {
        pthread_mutex_lock(&mutex); // mutex객체 잠금 및 잠금확인.
        sum++;
	      pthread_mutex_unlock(&mutex); // sum이라는 공유변수에 접근허용위해.
    }
}

void* consume(void* arg) {
    for (int i = 0; i < 100000; i++) {
        pthread_mutex_lock(&mutex);
	sum--;
	pthread_mutex_unlock(&mutex);
    }
}

$ gcc -pthread -o mutexexample mutexexample.c
$ ./mutexexample 
```

세마포어 활용예제제

```C
// semexample.c
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>
#include <semaphore.h>

void* produce(void* arg);
void* consume(void* arg);

int sum = 0;
sem_t semaphore;    // semaphore객체 선언

int main() {
    printf("초기 합계: %d\n", sum);

    // 세마포어 초기화. 세마포어 값은 1로 설정(자원의 개수를 넣어준다. 여기선 sum이란 변수1개라서 1을 넣어줌)
    if (sem_init(&semaphore, 0, 1) != 0) {
        perror("세마포어 초기화 에러");
        exit(EXIT_FAILURE);
    }

    pthread_t producer_thread, consumer_thread;
    pthread_create(&producer_thread, NULL, produce, NULL);
    pthread_create(&consumer_thread, NULL, consume, NULL);

    pthread_join(producer_thread, NULL);
    pthread_join(consumer_thread, NULL);

    sem_destroy(&semaphore);

    printf("실행 이후 합계: %d\n", sum);

    return 0;
}

void* produce(void* arg) {
    for (int i = 0; i < 100000; i++) {
        sem_wait(&semaphore);
        sum++;
        sem_post(&semaphore);
    }
    return NULL;
}

void* consume(void* arg) {
    for (int i = 0; i < 100000; i++) {
        sem_wait(&semaphore);
        sum--;
        sem_post(&semaphore);
    }
    return NULL;
}


$ gcc -pthread -o semexample semexample.C
$ ./ semexample
```

### 4-3. 교착상태(deadlock)와 해결방법

교착상태(deadlock)
: 일어나지 않을 사건(필요한 자원의 할당)을 기다리며 무한히 대기하는 현상

교착상태 발생조건은 아래 4가지를 모두 만족하면 교착상태가 발생할 수 있다. 

  1. 상호 배제 : 동시에 자원 사용이 불가능한 경우
  2. 점유와 대기 : 자원을 할당받은 채 다른 자원의 할당을 기다리는 경우
  3. 비선점 : 강제로 자원을 뺴앗을 수 없는 경우
  4. 원형대기 : 자원을 원형으로 대기할 경우

교착상태 해결방법
  1. 교착상태 예방
    - 교착 상태 발생 조건 4 가지 중 하나를 없애는 것
        - 상호 배제  조건 없애기
          - 자원을 공유가능하도록 변경 
        - 점유와 대기 조건 없애기
          - 특정 프로세스에 자원을 모두 할당, 아예 할당하지 않기
          - 자원의 활용률 저하  
        - 비선점 조건 없애기
          - 선점하여 사용 가능한 자원에 대해서는 효과적(Ex.CPU)
          - 모든 자원에 대해 적용 가능한 것은 아님(ex. 프린터기)
        - 원형대기 조건 없애기
          - 자원에 번호 매기기
          - 오름차순으로 자원 할당

    - 교착 상태가 발생 배경 원천 차단
    - 교착 상태가 발생하지 않음을 보장할 수 있지만, 여러 부작용이 따르는 방식
     
  2. 교착상태 회피
    - 교착 상태가 발생하는 이유를 자원의 무분별한 할당으로 간주
      - 포크가 무한한 상황에서 한 두개의 자원만을 요구했다면? 교착상태 발생 X
      - 포크가 두 개 있는 상황에서 여러 개의 자원을 요구했다면? 교착상태 발생 O
    - 교착 상태가 발생하지 않을 정도로만 조금씩 자원을 할당하는 방법
    - 교착상태 회피 판단하는 알고리즘 == 은행원 알고리즘(banker's algorithm)
    - banker's algorithm : 아래 3개의 행렬과 1개의 벡터를 사용
      - Allocation: 현재 각 프로세스에 할당된 자원의 양

      - Maximum: 각 프로세스가 필요로 하는 최대 자원의 양

      - Available: 시스템에 현재 남아 있는 자원의 양

      - Need: 각 프로세스가 앞으로 필요로 하는 자원의 양 (Need = Maximum - Allocation)

      ```python
      def is_safe_state(available, max_demand, allocation):
        n_processes = len(max_demand)
        n_resources = len(available)

        # Need 계산
        need = [[max_demand[i][j] - allocation[i][j] for j in range(n_resources)] for i in range(n_processes)]

        # 초기 설정
        work = available[:]
        finish = [False] * n_processes
        safe_sequence = []

        while len(safe_sequence) < n_processes:
            allocated_in_this_round = False

            for i in range(n_processes):
                if not finish[i]:
                    if all(need[i][j] <= work[j] for j in range(n_resources)):
                        # 자원을 할당해줄 수 있는 경우
                        for j in range(n_resources):
                            work[j] += allocation[i][j]
                        finish[i] = True
                        safe_sequence.append(i)
                        allocated_in_this_round = True

            if not allocated_in_this_round:
                # 모든 프로세스가 자원을 기다리고 있다면 비정상 상태
                return False, []

        return True, safe_sequence

      available = [3, 3, 2]  # 현재 시스템에 남아있는 자원
      max_demand = [
          [7, 5, 3],   # P0의 최대 요청
          [3, 2, 2],   # P1
          [9, 0, 2],   # P2
          [2, 2, 2],   # P3
          [4, 3, 3],   # P4
      ]
      allocation = [
          [0, 1, 0],   # P0에 현재 할당된 자원
          [2, 0, 0],   # P1
          [3, 0, 2],   # P2
          [2, 1, 1],   # P3
          [0, 0, 2],   # P4
      ]

      is_safe, sequence = is_safe_state(available, max_demand, allocation)

      if is_safe:
          print("✅ 시스템은 안전 상태입니다.")
          print("안전 실행 순서:", sequence)
      else:
          print("❌ 시스템은 비안전 상태입니다. 데드락 가능성 있음.")

      ```

  3. 교착상태 검출 후 회복
    - 교착 상태가 발생하면 그때 회복하는 방식
      - 선점을 통한 회복
      - 프로세스 강제 종료를 통한 회복

* 교착상태를 무시할수 있다 == 타조 알고리즘

## 5. 가상 메모리 관리
현대 운영체제의 메모리 관리 기법 학습하기

### 5-1. 스와핑

- 스와핑(swapping)
  - 프로세스를 보조기억장치의 일부 영역(swap area)으로 쫓아내고 당장 필요한 프로세스를 적재하는 메모리 관리 기법
- 스왑 아웃(swap-out)
  - 프로세스를 보조기억장치의 일부 영역으로 쫓아내는것
- 스왑 인(swap-in)
  - 스왑 아웃된 프로세스를 메모리에 적재하는것
- 스왑영역(swap area)
  - 스왑아웃된 프로세스가 적재되는 보조기억장치 영역

```shell
$ top
$ free -h
```
  ![system_os_swap_area.png](/assets/images/system_os_swap_area.png)

    - 보조기억장치의 일부 영역으로서 활용되는 스와핑 영역의 크기 확인 가능



![system_os_swap_process.png](/assets/images/system_os_swap_process.png)
  
  - 장점) 현재 메모리 크기보다 더 큰 메모리를 적재할수 있다

운영체제의 메모리 관리방식

  ![system_os_연속메모리할당.png](/assets/images/system_os_연속메모리할당.png)

  - 연속메모리할당 : 프로세스를 메모리에 연속적으로 배치하는 방식  
  - 부작용 : **외부단편화(External Fragmentation)** 라는 용량낭비의 문제를 야기함.
  - 프로세스B,D가 종료되서 50MB의 여유가 생기더라도 새로운 프로세스B를 적재하기 어렵다. 왜냐하면 메모리가 파편화되어 있기 때문이다.
  - 즉, 프로세스들이 실행되고 종료되길 반복하며 빈 공간이 생기는 메모리 낭비 현상

### 5-2. 페이지(Paging)

이러한 외부 단편화 해결방식은?
  - 페이징?
    1. 물리 메모리를 프레임(frame)이라는 일정한 크기로 나누고
    2. 프로세스를 페이지(page)라는 일정한 크기로 나눈 뒤
    3. 페이지를 프레임에 매핑하는 메모리 관리 방식


  * 당연하게도, frame=page size는 일반적으로 같게 된다.

> huge page <br>
: 일반적인 page보다 더 큰 page가 필요할때 사용함


  ![system_os_연속메모리할당_해결법.png](/assets/images/system_os_연속메모리할당_해결법.png)

  ![system_os_페이징.png](/assets/images/system_os_페이징.png)

    - 하나의 메모리에는 여러개의 번지가 할당될수 있다.

페이지 아웃, 페이지 인

  - 페이징에도 스왑인(=페이지 인),스왑아웃(페이지 아웃) 사용 가능

  ![system_os_페이지아웃_페이지인.png](/assets/images/system_os_페이지아웃_페이지인.png)


페이징은 가상 메모리 관리 기법의 일종이다.
> 가상메모리(virtual memory)
  - 프로세스의 일부만을 적재하여(나머지는 보조기억장치에 둔다) 실제 물리 메모리보다 큰 프로세스를 실행하는 기술
  - 페이징은 현대 운영체제에서 가장 대중적으로 사용되는 가상 메모리 관리 기법
  

  ![system_os_가상메모리.png](/assets/images/system_os_가상메모리.png)

  - 세그멘테이션기법도 있다. 페이징은 동일한 크기로 자르는기법이고, 세그멘테이션기법은 프로세스를 의미 있는 단위로 자르는 기법이다.
  세그먼트라는 함수영역이나, 데이터 영역의 크기로 자른다. 즉, 유의미한 크기로 나누는것이 세그먼테이션 기법이다. 즉, 세그먼테이션기법이용시 외부단편화 발생할수 있다.

페이징 사용시 단편화 문제에서 자유로운가? NO. 외부단편화는 발생하지 않지만 내부 단편화가 발생할수 있다.
> 내부 단편화 <br>
: 프로세스 내부에서 일어나는 메모리 낭비, 내부단편화란, 프로세스를 이루는 메모리가 페이지 크기와 딱 떨어지지 않고 남을수 있다. 이것이 내부단편화다.

### 5-3. 페이지 테이블
: 프레임과 페이지의 매핑 정보를 담고 있는 표 형태의 데이터

어떤 페이지가 어떤 프레임에 매핑되었는지 어떻게 알수 있을까?

  - CPU 입장에서는 메모리에 적재되어 있는 코드들을 순차적으로 읽어와서 실행한다. PC(프로그램카운터 레지스터)에는 다음으로 실행할 명령어의 주소가 담긴다. 그런데, 메모리의 프로세스가 연속적으로 배치가 되어 있으면 계속 다음번지 주소만 가리키기에 순차적으로 실행만하면 된다.
  - 그런데 페이징을 쓰면 메모리 내에서 실행해야 되는 프로그램이 연속적으로 배치되어 있기 때문에 CPU입장에서는 다음으로 실행해야 될 명령어가 어디에 있는지 모를수 있다.
  - 그래서 CPU입장에서는 메모리가 어디에 할당되어있는지 알아야 한다. 그를 위해 사용하는게 페이지 테이블이다.

  ![system_os_페이지테이블.png](/assets/images/system_os_페이지테이블.png)

    - 페이지 테이블을 이용해서 물리메모리내에 불연속적으로 배치되어 있는 페이지에도 CPU가 접근할수 있게 된다.

  ![system_os_페이지테이블2.png](/assets/images/system_os_페이지테이블2.png)

    - 프로세스마다 페이지 테이블을 가지고 있다. 즉, 프로세스마다 각자의 페이지 테이블을 가지고 있다.

페이지 테이블 베이스 레지스터(PTBR)
  - 각 프로세스의 페이지 테이블 위치를 가리키는 레지스터

  ![system_os_페이지테이블3.png](/assets/images/system_os_페이지테이블3.png)

    - CPU입장에서는 이 프로세스 페이지테이블이 어디있는지도 알아야 한다. 그래야 프로세스A의 몇번 페이지가 몇번 프레임에 적재되어 있는지 알수 있다.
    - 그래서 PTBR이라는 특별한 레지스터에 특정 프로세스의 페이지 테이블 위치정보가 담긴다.
    - 즉, PCB에 메모리 관련정보가 담기는데 그중 하나가 PTBR이다.
    - 즉, PTBR을 알면 이 프로세스의 페이지 테이블이 현재 어디에 적재되어 있는지를 알수 있고, 이걸알면 페이지테이블이 어디에 적재되어 있는지를 알게되면 현재 이프로세스의 몇 번 페이지가 몇번 프레임에 적재되어 있는지 알수 있다.

페이지테이블은 어디에 있는게 좋을까? 메모리에 있으면 메모리 접근 시간 2배 소요. 왜냐하면 CPU에서 메모리에 접근시 페이지 테이블접근, 프레임접근 이렇게 2번해야되거든.
메모리에 접근하는 시간은 캐시메모리, 레지스터에 접근하는 시간보다 압도적으로 느리다.
 
  ![system_os_페이지테이블4.png](/assets/images/system_os_페이지테이블4.png)

이렇게 페이지테이블이 메모리에 적재되어 있다면 느리다는 성능이슈가 있기에 

TLB(Translation Look-aside Buffer)
  - 페이지 테이블의 캐시메모리

  ![system_os_페이지테이블5.png](/assets/images/system_os_페이지테이블5.png)

    - 페이지 테이블에 캐시메모리를 따로 두는경우가 많다.
    - 만약, 캐시메모리에 원하는 데이터가 있을때 (캐시hit) 없을때(캐시 miss) 라고 하기에 내가 접근하고자 하는 페이지가 현재 TLB라고 하는 캐시메모리에 있을경우 TLB hit, 없으면 TLB miss라고 한다.
    - TLB miss가 나면 메모리 접근 시간이 2배로 늘어나게 된다.

#### 5-3-1. 페이지 테이블 내 정보는?

페이지 테이블 내 정보: 유효비트(valid bit)
  - 접근하려는 페이지가 보조기억장치에 있는가? 메모리에 있는가?를 나타내주는 bit이다.

  ![system_os_페이지테이블6.png](/assets/images/system_os_페이지테이블6.png)

    - 만약 valid bit가 0인, 현재 메모리에 적재되지 않은 페이지에 접근하려면 어떻게 되나? = page fault, 페이지폴트라는 특별한 인터럽트 발생됨.
      - 즉, 접근하려는 페이지가 보조기억장치에 있을경우(=page fault)
        1. 작업 내역 백업
        2. 페이지 폴트 루틴 실행 -> 접근하려는 페이지 적재
        3. 유효비트 1로 변경
        4. 접근하려는 페이지 접근


페이지 테이블 내 정보 : 보호비트(protection bit)
  - 접근하려는 페이지의 권한설정 

    ![system_os_페이지테이블7.png](/assets/images/system_os_페이지테이블7.png)

      - ex.메모리의 코드영역은 read only영역인데, 이 페이지를 write하면 안되잖아. 그러므로 이럴땐 보호비트가 read가 1로 되어있고 나머진 0으로 되어있어야 한다.
      
페이지 테이블 내 정보 : 참조비트(reference bit)
  - 접근한적있는 페이지인가?
    - 접근한적있는 페이지 : 1
    - 접근한 적 없는 페이지 : 0
  - 페이지가 적재된 이후에 CPU에 의해서 한번이라도 접근된적이 있는가를 나타내는 정보

수정비트(modify bit / dirty bit)
  - 쓰기 작업을 한적 있는 페이지인가?
    - 수정된 적 있는 페이지 : 1
    - 수정된 적 없는 페이지 : 0
  - 수정비트가 존재하는 이유는 CPU - momory - 보조기억장치가 있을때, 메모리에 A라는 프로그램이 작동하고 있을때, A라는 프로그램의 특정 페이지가 원래는 X라고 쓰여있었다.
  - 메모리는 휘발성 저장장치이기 때문에 메모리에 적재된 모든 정보는 전원이 꺼져도 저장된 내용을 잃지 않기 위해 보조기억장치에도 저장되어 있어야 한다.
  - 근데, CPU는 메모리에 있는 내용을 읽기를 할뿐만 아니라 쓰기 작업도 한다. 
  - 근데 만약에 CPU가 A라고 하는 프로그램을 X -> X' 로 바꿨다고 하면, 메모리는 보조기억장치로부터 갖고온 A라고 하는 프로그램안에 있는 X는 아직 반영이 안됨.
  - 즉, 쓰기 작업이 수행되었지만 보조기억장치에 있는 A라고 하는 프로그램 정보는 여전히X이다. 
  - 수정된 내용이 있다면 보조기억장치에도 반영해야했다.  그래서 존재하는게 수정비트이다.
  - 보조기억장치에 쓰기작업을 해야되느냐 말아야되느냐. 
  - 이거 실행이 끝나거나 중간중간에 변경된 페이지가 있다면 디스크에 반영을 해줘야한다. 그 판단척도 삼기위해서 수정비트가 존재함.

> dirty <br>
: 컴퓨터에서 dirty라고 하면 쓰기 작업 or 조작이 이루어진 작업을 표현한다.  

계층적 페이징 : 페이지 테이블 크기 줄이기
  - 페이지 테이블을 페이징하는게 계층적 페이징이다.

  ![system_os_페이지테이블8.png](/assets/images/system_os_페이지테이블8.png)

    - 프로세스의 메모리크기가 너무 크면 페이지 테이블도 그에 비례해서 너무 크다.
    - 그럼 이놈들 전체를 다 메모리에 통째로 다 적재하는건 아까우니깐
    - 페이지 테이블을 페이징해서 각각의 페이지 테이블을 가리키는 또 다른 페이지 테이블을 이용하는게 계층적 페이징이다.
    - 그러면 CPU입장에서는 Outer 페이지 테이블만 알고있으면 그놈을 통해 해당 페이지테이블에 접근가능함.
    - 계층적페이지는 계속 다른 페이징을 계층적으로 가르키게 할수 있다.
    - 다만, outer페이지 테이블은 항상 메모리에 적재되어 있어야 한다.
    - 만약 outer페이지 테이블은 있는데 페이지테이블이 메모리에 없다면 CPU는 그냥 보조기억장치로부터 가져와서 사용할수있다.

### 5-4. 요구페이징, 스래싱

요구페이징  
  - 처음부터 모든 페이지를 적재하지 않고 페이지 폴트가 발생하면 그 때 페이지를 적재한다.

순수 요구 페이징
  - 아무 페이지도 적재하지 않고 실행하는것.
  - 첫 명령어 실행부터 페이지 폴트 발생. 그러한 필요한 페이지만 보조기억 장치로부터 적재하게 됨.
  - 적당한 페이지가 적재된 이후부터 페이지 폴트 감소

> 페이지폴트 <br>
: 메모리에 적재되어 있지 않은 페이지에 접근할때 발생하는 특별한 인터럽트

페이지폴트는 적게 발생할수록 좋다. 왜? 페이지 폴트 발생시, 기존작업내역 백업하고, 보조기억장치로부터 내가 필요한 페이지를 적재하고 다시 vaild bit를 1로 바꾸고, 다시 접근해야되니깐.
페이지 폴트를 적게 발생시키려면? 사실 물리 메모리가 크면 근본적 해결 된다.(즉, frame이 무한하면 해결됨)
  - 프레임이 무한히 많은 메모리의 경우 <- 무한히 많은 페이지 적재 가능
  - 프레임이 한 개 있는 메모리의 경우 <- 페이지 접근할 때마다 페이지 폴트

스래싱  
  - 프로세스 실행 시간보다 페이징에 더 많은 시간이 소요되는 문제가
  - 지나친 페이지 폴트로 인해 페이지 교체에 너무 많은 시간을 소요하여 성능이 저하되는 문제
  
    ![system_os_스래싱.png](/assets/images/system_os_스래싱.png)

      - 가로축을 멀티프로그래밍의 정도라고 본다.즉, 동시에 실행되는 프로세스 수를 의미한다.
      - 세로축은 CPU이용률을 나타낸다. 
      - 즉, 동시 실행되는 프로세스 수를 늘린다고 해서 반드시 CPU이용률이 비례하여 높아지는 것은 아니다. 왜? 스래싱이 발생할수 있으니깐!

많은 물리 메모리(프레임)을 확보할 수 없다면 페이지 폴트 횟수를 줄일 수 없는 걸까?
  - 페이지교체알고리즘으로 해결가능.

> 페이지교체알고리즘 <br> 
: 보조기억장치로 내보낼 페이지, 메모리에 적재할 페이지를 잘 선별하는 알고리즘


### 5-4-1. 메모리상태 관찰할수 있는 다양한 방법들

```shell
// 메모리에 관련된 자세한 정보 확인
$ cat /proc/meminfo

// 페이지폴트를 관찰할수 있는 명령어 및 시스템관련 관찰가능
$ top // + f 눌르면 된다다

// 가용공간, 총공간, swap 메모리 크기
$ free -h

// 현재 메모리 통계정보를 확인해볼수 있음
$ vmstat
$ vmstat -h
$ vmstat -a
$ vmsta 1 2 // 1초당 2번 조회함을 나타냄.(실시간 변화량 체크가능)
```
  - $ cat /proc/meminfo
    - memtotal : 현재 설치되어 있는 물리적인 메모리 양
    - memFree : 현재 남아있는양
    - memAvailable : 현재 사용가능한 양
    - buffers, cached : 메모리에 빨리 접근하게끔 하기 위해 커널이 만들어 놓은 방법 혹은 cached량
    - active : 최근에 자주 사용되고 있는 페이지 양, 자주 접근하고 있는 페이지 양
    - inactive : 최근에 사용되지 않은 페이지들 , 접근하고 있지 않은 페이지들의 양
    - dirty : 한번이라도 쓰기 작업을 했던 페이지를 의미
    - mapped : 파일에 맵핑된 메모리의 양을 의미
    - shmem : 공유된 메모리의 총량
    - kernelStack : 커널이 관리하는 스택의 양
    - pageTables : 페이지 테이블의 크기
    - hugePages : 일반적인 페이지가아니라 그것보다 크기가 훨씬 더 큰 특별한 페이지를 의미.(일반적으로 페이지의 크기는 균일하다)

  - $ top // + f
    - nMaj, nMin, nDRT, vMj, vMn  클릭시 Major Page Faults를 볼수 있다.

  - $ vmstat
    - r : 실행시간을 기다리는 프로세스 수
    - b : 블록된 프로세스 수
    - si, so : swap in, swap out을 의미
    - bi, bo : block in, block out을 의미 / 블럭에서 읽어들이는 양, 블럭에서 내보내는 즉, 쓰는 양.
    - in : 초당 인터럽트 수
    - cs : 문맥교환(컨텍스트 스위칭이 얼마나 이루어졌는지에 해당하는 값)
    - us : 사용자 프로세스 시간, 즉. 유저스페이스에서 사용되는 시간
    - sy : 커널영역에서 사용되는 시간
    - wa : 입출력을 대기하기 위해서 대기상태로 접어든 시간을 의미


### 5-5. 페이지 교체 알고리즘

메모리에 적재된 페이지 중 페이지-아웃시킬 페이지를 선정하는 방법

좋은 페이지 교체 알고리즘은 페이지 폴트를 적게 일으키는 알고리즘

페이지 폴트를 적게 일으킨다는 것은 어떻게 알 수 있을까?
  - 페이지 참조열 : CPU가 참조하는 페이지 중 연속된 페이지를 생략한 페이지열
    - 참조한 페이지 : 2 2 2 3 5 5 5 3 3 7
    - 페이지 참조열 : 2 3 5 3 7
    - ex. CPU가 2,2,2,3,..의 페이지를 참조했다면 연속된 페이지를 없애서 2 2 2 는 2 하나로 되고..이렇게 페이지 참조열이 되게 된다.
    - 왜 연속된 페이지를 생략할까?  우리의 관심사는 페이지폴트의 발생횟수이다. 
      - 연속된 페이지를 참조하면 당연히 페이지폴트가 발생하지 않는다. 왜?2.2.3.5를 참조할때 2번이 적재되어 있지 않다면 여기서 페이지 폴트발생하고, 그다음부터의 2는 페이지가 당연히 있다.

### 5-5-1. 페이지 교체 알고리즘 종류
- FIFO 페이지 교체 알고리즘

  ![system_os_FIFO페이지교체알고리즘.png](/assets/images/system_os_FIFO페이지교체알고리즘.png)
    
    - 가장 먼저 메모리에 적재된 페이지부터 페이지-아웃
    - 2번 페이지 참조하는데 프레임이 비어있기에 프레임에 2번을 적재한다.
    - 5번 페이지에 접근하려는데 프레임이 차있으니깐 가장먼저 적재된 2번 페이지를 아웃시킨다.
  
  - 당연히 문제가 있다. 초기에 적재된 페이지 중 프로그램 실행 내내 유지할 데이터가 있을 수 있다. 그래서 2차 기회 FIFO페이지 교체알고리즘이 나옴.

- 2차 기회 FIFO페이지 교체 알고리즘

  - FIFO 페이지 교체 알고리즘의 변형
  - 기본적으로 가장 오래 메모리에 머물렀던 페이지부터 페이지-아웃
  - 다만 참조 비트가 1일 경우, 이를 0으로 변경 후 한번 더 기회 부여
  - 참조 비트가 0일 경우 페이지-아웃
    - 참조비트 : CPU가 적재된 이후 페이지에 한번이라도 접근한적 있는 페이지는 참조비트가 1이다.
     
     ![system_os_2차FIFO페이지교체알고리즘.png](/assets/images/system_os_2차FIFO페이지교체알고리즘.png)

- 최적 페이지 교체 알고리즘

  ![system_os_최적페이지교체알고리즘.png](/assets/images/system_os_최적페이지교체알고리즘.png)

    - 단순하게 생각했을 때, 메모리에서 페이지-아웃되어야 할 페이지는 **앞으로 쓸 일이 잘 없는 페이지**
    - 앞으로의 사용 빈도가 가장 낮은 페이지부터 교체하는 알고리즘

    - 가장 낮은 페이지 폴트 빈도율을 보장하는 알고리즘
    - 하지만 앞으로 CPU가 어떤 페이지를 얼마나 참조할지 예측하기란 매우 어려움
    - 이론적으로 페이지 교체 알고리즘의 성능을 평가할 때 주로 사용되는 알고리즘

- LRU 페이지 교체 알고리즘

  ![system_os_LRU페이지교체알고리즘.png](/assets/images/system_os_LRU페이지교체알고리즘.png)

    - 가장 적게 참조할 페이지는 예측하기 어려워도 가장 적게 참조한 페이지는 계산하기 쉽다.(timestamp찍어서 언제적재 되었는지만 알아도 된다.)
    - 최근에 사용되지 않은 페이지를 페이지-아웃
    

### 5-6. copy-on-write(쓰기 시 복사)

페이징기법을 사용하면 얻을 수 있는 이점 중 하나이다.

copy-on-write를 통해서 여러개의 독립적인 프로세스가 메모리 낭비를 많이 방지할 수 있다.

fork :프로세스를 복제하는 시스템콜.
프로세스가 복제되면 별도의 PID와 메모리 공간을 할당받아서 독립적인 프로세스 2개가 메모리에 적재된다. 그 이유는 프로세스끼리는 기본적으로 자원을 공유하지 않기 때문.

그런데, 사실, 프로세스끼리 자원을 공유하지 않으면서, 별도의 메모리 공간에 중복 적재하지 않을수 있는 방법이 있다. 이게 바로 copy-on-write이다.


프로세스를 fork하면 동일한 프로세스 2개가 메모리에 복제된다. 
  ![system_os_쓰기시복사.png](/assets/images/system_os_쓰기시복사.png)
    
    - 부모프로세스 페이지 테이블이 있을때 fork를 하면 자식프로세스 생성되고 그것과 동일한 페이지가 별도의 메모리 공간에 할당이 된다.
    - 즉, 5,4,6번 프레임에 적재됬다면 자식은 9,8,7번 프레임에 적재가 될것이다. 
    - 이렇게 될시 불필요한 메모리 공간이 2배로 늘어났기 때문에 메모리낭비라고 볼수 있다.

    * 메모리 공간 낭비
    * 프로세스 생성 시간 낭비

쓰기시 복사 이용시
  - 복제 프로세스를 생성할 경우 이를 중복 저장하지 않고 동시에 프로세스 간의 자원을 공유하지 않게끔 하는 방법

  ![system_os_쓰기시복사2.png](/assets/images/system_os_쓰기시복사2.png)

    - 부모 프로세스가 Fork를 하면 자식프로세스를 자신의 복제로 생성함. 그럴때 처음 생성시엔 부모 프로세스와 동일한 번호를 가리키게끔 생성하게 된다.
    - 만약 부모프로세스도 자식프로세스도 뭔가 쓰기 작업이 없고 읽기작업만 있다면 굳이 별도의 메모리 공간을 할당할 필요가 있을까?없다.
    - 그런데 부모 or 자식프로세스 둘중하나라도 쓰기 작업을 하게 되면 프로세스끼리는 기본적으로 자원을 공유하지 않기 때문에, 별도의 프로세스로서 실행되기 때문에, 둘중 (부모or 자식)하나의 프로세스라도 쓰기작업을 수행하면 해당 프로세스의 페이지에 해당하는 복제본이 새로운 프레임에 할당이 된다.
    - Ex. 그냥 포크(복제)를 한 직후에는 자식프로세스나 부모프로세스나 동일한 프레임의 페이지를 가리키고 있는데
    - 예를들어 자식프로세스가 페이지 2번에 어떤 새로운 쓰기 작업을 하고 싶다면 페이지 2에 대한 복사본이 새로운 프레임에 적재가 되고 여기에 쓰기 작업을 수행하게 된다.
    - 그러면 부모 프로세스의 2번페이지는 변경이 있나? 없다. 자식프로세스의 2번페이지는 변경이 있음. 즉 자원공유하지 않음.
    - 그렇지만 쓰기작업이 수행되지 않은 동일한 페이지는 공유할수가 있었다. 즉, 메모리 낭비를 최소화할수 있다.

    - 정리) 부모or 자식 프로세스 둘중에 하나라도 쓰기를 하면은 그때 복사를 하겠다. 그 전까지는 그냥 동일한 페이지를 가리키겠다는 방법.


## 6. 파일 시스템
운영체제가 팡리과 디렉토리를 관리하는 방법 학습하기

파일시스템이란?
  - 파일과 디렉토리(폴더)를 관리하는 커널의 한 부분
  - 다양한 파일 시스템이 있고, 여러 파일 시스템을 동시에 사용할 수 있음

파일(file)?
  - 보조기억장치의 의미있는 정보의 집합
  - 구성 요소
    - 이름
    - 실행하기 위한 정보
    - 부가정보(= 속성, 메타데이터, attribute)
      - 유형(확장자) : 운영체제에게 전달해주는 정보. 
      - 크기
      - 생성날짜
      - 마지막 접근 날짜
      - 마지막 수정 날짜
      - 생성자
      - 소유자
      - 위치

```shell
$ stat [filename]
```

파일에는 응용프로그램이 직접 접근못한다.파일접근및조작하기 위한 시스템콜들이 존재함.
운영체제게 파일에 접근할때는 **블록단위** 로 읽고 쓰게 된다.

  - 파일(+디렉토리) 접근 단위 : 블록(block)
    - 섹터 단위로 접근하지 않음.

  - 하드디스크에서 가장 작은 단위는 sector단위 아닌가? 맞다. 그러나 운영체제가 파일 읽고 쓸땐 블록단위로 접근한다.

디렉토리
  - 경로 : 특정 파일의 위치를 식별할수 있는 정보
  - 루트 디렉터리 : / 최상위 폴더
  - 절대 경로와 상대 경로
    - 절대경로 : 루트디렉터리에서 시작해서 전체 경로를 절대 경로라고 부른다.
    - 상대경로 : 현재 경로를 기반으로 한 파일의 경로를 말한다.

  - **많은 운영체제는 디렉터리를 파일과 동일하게 간주한다.**
  - 디렉터리 구성 정보
    - 파일 이름
    - 위치를 유추할 수 있는 정보
    - 파일속성
    - 즉 보조기억장치에 디렉터리 테이블 형태로 저장되어 있다
      |파일이름 | 위치를 유추할 수 있는 정보|생성시간 | 수정된 시간 | 크기 | ... |
      | --- | --- | --- | --- | --- | --- |
      | - | - | - | - | - | - |
  
  - 정리) 디렉터리라는것은 위의 표같은 정보를 담고있는 특별한 형태의 파일로 운영체제는 간주한다.

### 6-1 파일시스템이 만들어지는 과정

파일시스템
  - 파일과 디렉터리(폴더)를 관리하는 커널의 한 부분
  - 다양한 파일 시스템이 있고, 여러 파일 시스템을 동시에 사용할 수 있음.

```shell
$ blkid -o list
```
    - fs_type : 파일시스템 타입을 알려준다.
    - 다양한 물리 device에 어떠한 파일시스템 타입이 할당되어 있는지 보여준다.

    - 보조기억장치(block device) 사용할때, 다양한 파일 시스템을 사용할 수 있도록 블록 디바이스의 영역을 나눌수도 있다.

    - 보조기억장치 하나에 단일한 파일 시스템이 사용되는 것이 아니다.
    - 파티셔닝(partitioning) : 보조기억장치의 영역을 구획하는 작업
      - 파티션(partition) : 보조기억장치에서 구획된 영역

      ```shell
      $ df -h
      ```
    
    - 포매핑(format + ing) : 파일 시스템을 만드는 작업(초기화 작업)

    ```shell
    # mkfs -t ext3 /dev/sdb1
    ```
      - make file system, ext3라는 파일시스템을 만들것이다, /dev/sdb1에 초기화를 할것이다.
      - 즉,/dev/sdb1라는 device에다가 ext3라고 하는 파일시스템으로 초기화할것이다란 의미.

    - 파일시스템이 달라지면 어떤식으로 보조기억장치에 있는 데이터 덩어리를 파일로 할당할건지, 어떻게 이 보조기억장치에 있는 정보를 파일로서 읽어드릴지가 결정이 된다.
    - 즉, 파일시스템을 어떤것을 사용하냐에 따라 저장되는 구조도 달라진다.

마운트(mount)
  - 파일시스템에 접근할 경로 설정
  - 파일 시스템을 다른 파일 시스템에 편입

### 6-2. 파일시스템 종류와 특성

운영체제가 보조기억장치에 있는 정보에 접근할때는 블록 단위로 접근.

접근시 0번블록, 1번블록..등 번호기준으로 접근할것이다. 그럼 어떻게 파일을 할당할수 있을까?

  - 그냥 연속적으로 할당할까? No.외부단편화 발생할수 있음.

불연속적으로 파일이 할당됨(어떻게 불연속적으로 파일할당하는지에 따라 FAT or UNIX 파일시스템으로 나뉨)

  

FAT 기반 파일 시스템 
  - FAT(File Allocation Talbe)를 활용하는 파일 시스템
  - 저용량 보조기억장치용 파일 시스템으로 이용
    - USB메모리
    - SD카드
  - 많은 운영체제는 디렉터리를 파일과 동일하게 간주한다.
  - 디렉터리 구성정보
    - 파일이름
    - 위치를 유추할 수 있는 정보
    - (파일속성)
  - FAT는 메모리에 캐시되어 있다. 즉, FAT접근위해 보조기억장치에 2번씩 접근할 필요가 없다. 그래서 메모리에 있는 FAT를 참조하면 보조기억장치에 있는 정보에 좀더 빠르게 접근가능.

  ![system_os_파일시스템_불연속적.png](/assets/images/system_os_파일시스템_불연속적.png)

    - 운영체제는 이 파일이 FAT상에서 어디서부터 시작되는지 첫번째 블록 주소를 알고 있다.
    - 즉, 운영체제는 파일a의 첫번째 블록주소는 4번이다. 라는것만 알고있고, FAT의 table을 통해 다음블록주소는 8번, 그리고 연계해서 다음다음 주소를 알수 있게 된다.
    - 즉 파일a에 접근하기 위해서 4 > 8 > 3 > 5 > -1(종료) 순으로 접근하는걸 운영체제는 알게된다.

  - FAT파일시스템의 파티션
    - 보조기억장치가 있을때 이를 파티션으로 나누어서 이중 하나를 FAT파일시스템으로 나눈다면 아래 그림의 형태로 구성된다.
    
    ![system_os_파일시스템_불연속적2.png](/assets/images/system_os_파일시스템_불연속적2.png)

      - FAT영역 : FAT가 저장되는곳
      - 루트 디렉터리 영역 : 가장 최상단 폴더가 어디인지를 알아내기 위한 영역
      - 데이터 영역 : 파일에 해당하는 정보,디렉터리에 해당하는 정보가 저장
        - 데이터 영역에는 파일과 폴더가 저장되어있다(루트디렉터리 제외됨)
        - 일반적으로 운영체제는 파일과 디렉터리(=폴더)를 구분짓지 않는다. 디렉터리는 그냥 특별한 형태의 파일이라고만 간주함.

        - 파일은 특정 디렉터리에 소속되어 있을것이다. 즉 특정파일에 접근하기 위한 정보가 디렉터리에 명시되어 있다.
        - 즉, FAT파일 시스템에 접근하기 위해 파일a의 첫번째 블록주소를 운영체제가 기억하고 있다 했는데, 이게 디렉터리의 첫번째 블록주소에 저장되어 있는것이다.
          - 디렉터리에는 어떤파일이름이 어디 블록주소를 가리킨지 저장되어 있다.
        - FAT파일시스템의 특징 ) 디렉터리 테이블, 즉 디렉터리만 쓱 읽어도 FAT파일 시스템 상에서는 이 파일이 언제 생성되었는지 수정되었는지 크기가 어떻게 되는지 등의 속성까지 알수 있게 된다.
          - entry에 파일의 속성이 같이 명시된다.

    - 디렉터리 엔트리에 파일 속성 표현
      
      ![system_os_파일시스템_디렉터리엔트리.png](/assets/images/system_os_파일시스템_디렉터리엔트리.png)

        - 위 정보가 쌓여서 표와 같은 모양으로 보조기억장치에 저장이 되게 된다.

UNIX 기반 파일 시스템
  - 불연속적으로 할당하는데 아이노드(i-node)라는 색인 블록을 활용한 파일 시스템

  ![system_os_파일시스템_UNIX.png](/assets/images/system_os_파일시스템_UNIX.png)

> 색인블록(=index block = i-node) <br>
: 이파일이 현재 어떤 블록에 할당되어 있는지에 대한 정보를 전부 모아놓은 특별한 블록을 말함

  - 아이노드는 사실상 파일의 모든 것을 담고 있다.

    ![system_os_파일시스템_UNIX2.png](/assets/images/system_os_파일시스템_UNIX2.png)

      - 이 파일에 접근하기 위한 블록주소뿐 아니라 이파일의 속성까지도 iNode에 저장되어 있다.
      - 즉, iNode는 파일의 이름빼고 모두 저장하고 있다.
      - iNode만 알면 파일의속성,어디에 저장되어있는지 전부다 알고있다. FAT파일시스템에선 시작블록이 따로 있어서 파일이 어디있는지 저장하고 있었다.

  
  - 파티션 내 아이노드 영역
    
    ![system_os_파일시스템_UNIX3.png](/assets/images/system_os_파일시스템_UNIX3.png)

      - iNode기반의 파일시스템으로 특정 파티션을 초기화한다면 위와같은 형태로 초기화가 된다.
      - i-node영역 : iNode가 모든걸 저장하고 있기 때문에 iNode가 저장되어 있는 영역이 특별히 할당되어야 한다.
      - 데이터 영역 : iNode가 가리키고 있는 파일 혹은 디렉터리의 정보에 해당하는 모든 영역이 데이터영역에 저장되어 있다.

  - 아이노드 기반 파일시스템에서 아이노드 조회하기
  
  ```shell
  $ ls -i
  $ stat [파일명]
  ```
    - $ ls -i
      - 특정 파일에 몇번 iNode가 할당되어 있는지 조회 가능.
    - $ stat [파일명]
      - 파일속성안에 Inode에 대한 정보확인가능
  
  - 아이노드를 사용량이 100% 찼을 경우 : 데이터 용량이 남아 있어도 파일 생성 불가능

  ```shell
  $ df -ih
  ```
    - iNode 영역의 사용량 확인가능함.


기타 파일 시스템 특성 정리
  - NTFS 
    - 윈도우 운영체제에서 주로 사용하는 파일 시스템
  - APFS
    - macOS, iOS, watchOS, tvOS에서 주로 사용되는 파일 시스템
  - ext2, ext3, ext4, xfs
    - 리눅스 운영체제에서 주로 사용되는 파일 시스템

> 저널링<br>
: 파일을 얼마나 안전하게 활용할수 있는지, 파일을 잘 복구할수 있는지에 대한 기능

저널링 파일 시스템(journaling file system)
  - 파일 시스템에 크래쉬가 발생했을 때 빠르게 복구하기 위한 방법
    step1. 작업 직전 파티션의 로그 영역에 로그를 남긴다.
    step2. 로그를 남긴 후 작업을 수행한다.
    step3. 작업이 끝났다면 로그를 삭제한다.

    ![system_os_파일시스템_UNIX4.png](/assets/images/system_os_파일시스템_UNIX4.png)
    

---


[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}